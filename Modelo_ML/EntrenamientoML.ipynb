{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from scipy.stats import norm, truncnorm\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatos=pd.read_csv(\"./Base_de_datos/metadata_normal.csv\")\n",
    "ciudades=pd.read_csv(\"./Base_de_datos/ciudades_normal.csv\")\n",
    "reviews_gm=pd.read_csv(\"./Base_de_datos/reviews_gm_normal.csv\")\n",
    "categorias=pd.read_csv('./Base_de_datos/categories_normalized.csv')\n",
    "business=pd.read_csv('./Base_de_datos/business_normal.csv')  \n",
    "reviews_yelp=pd.read_csv('./Base_de_datos/reviews_normal.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatos.drop(columns=metadatos.columns[11:],inplace=True)\n",
    "business.drop(columns=business.columns[11:],inplace=True)\n",
    "metadatos_business=pd.concat([metadatos,business],axis=0,ignore_index=True)\n",
    "metadatos_business.drop_duplicates(subset=\"id\",ignore_index=True)\n",
    "\n",
    "reviews=pd.concat([reviews_gm,reviews_yelp],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26715 entries, 0 to 26714\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              26715 non-null  object \n",
      " 1   name            26715 non-null  object \n",
      " 2   street_address  15567 non-null  object \n",
      " 3   postal_code     26712 non-null  float64\n",
      " 4   latitude        26715 non-null  float64\n",
      " 5   longitude       26715 non-null  float64\n",
      " 6   city_id         26715 non-null  int64  \n",
      " 7   category_id     26715 non-null  object \n",
      " 8   stars           26715 non-null  float64\n",
      " 9   review_count    26715 non-null  int64  \n",
      " 10  is_open         26715 non-null  int64  \n",
      " 11  address         10807 non-null  object \n",
      "dtypes: float64(4), int64(3), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "metadatos_business.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjf1JREFUeJzs3XlYlXX+//EXoCwuoIaAjKikpuKaWEhTLsV4VGqizFHTUnNJByyh1KExXBvKcitRstwadVz6lZUaSuTSN1ETJXcyw3BGUSmBRAWF+/dHF7ceUUTDcxSfj+u6r/Hcn/e5z/vcMMNnXuc+n9vBMAxDAAAAAAAAgA052rsBAAAAAAAA3H0IpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKWAO1iDBg00YMAAe7dxV7pTz/2d2jcAANfD3zj7qYjn3sHBQREREdetW7hwoRwcHHTkyJEbfo1OnTqpRYsWN9EdUHEQSgG3ieI/aDt27LjqeHn90Vq7dq3Gjx//h48DAABwqzAvurvNnj1bCxcuvOWvs2XLFo0fP17Z2dm3/LUAXB2hFHAHS0tL0wcffHBDz1m7dq0mTJhwizoCAACwD+ZFFYctQ6kJEyYQSgF2RCgF3MFcXFxUuXJle7dxQ/Ly8uzdAsrJxYsXVVBQYO82ysQwDJ07d87ebQAAbiHmRYD9MNfCzSKUAu5gV35//8KFC5owYYIaN24sV1dX3XPPPXr44YeVmJgoSRowYIDi4uIk/f49+eKtWF5enl555RX5+fnJxcVFTZo00TvvvCPDMKxe99y5c3rppZfk6emp6tWr669//av+97//ycHBweoS+PHjx8vBwUH79+/Xs88+q5o1a+rhhx+WJO3evVsDBgzQvffeK1dXV/n4+OiFF17QL7/8YvVaxcf44Ycf1K9fP3l4eKh27dp6/fXXZRiGjh49qieffFLu7u7y8fHR1KlTrZ5fUFCgmJgYBQYGysPDQ1WrVtUjjzyiDRs2lOkcG4ahyZMnq27duqpSpYo6d+6sffv2XbU2OztbI0eONM9fo0aN9NZbb6moqKjU13j88cd17733XnUsODhY7dq1Mx8vWLBAjz76qLy8vOTi4qKAgADNmTPnlvd95MgROTg46J133tGMGTPUsGFDubi4aP/+/aW+t2I7duyQxWKRp6en3Nzc5O/vrxdeeMGqpqioSDNnzlTLli3l6uqq2rVrq2vXrlZf3bh48aImTZpkvn6DBg302muvKT8/3+pYDRo00OOPP65169apXbt2cnNz0/vvv1/m9wsAuPMwL6oY86IGDRpo37592rRpk/kz6dSpU5mPaxiGOnfurNq1a+vkyZNW771ly5Zq2LCh8vLyNH78eI0aNUqS5O/vb77WlWtDLVmyRE2aNJGrq6sCAwO1efPmMp2r2bNnq3nz5nJxcZGvr6/Cw8OveUVWSkqKHnroIXOOFB8fX6bXuBxzLdypKtm7AQDWcnJylJWVVWL/hQsXrvvc8ePHKzY2VoMHD9aDDz6o3Nxc7dixQzt37tRf/vIXvfjiizp27JgSExP173//2+q5hmHor3/9qzZs2KBBgwapTZs2WrdunUaNGqX//e9/mj59ulk7YMAArVixQs8995zat2+vTZs2KTQ09Jp99ezZU40bN9a//vUvcyKXmJion376SQMHDpSPj4/27dunuXPnat++fdq6davVpFCSevXqpWbNmunNN9/UmjVrNHnyZNWqVUvvv/++Hn30Ub311ltasmSJXn31VT3wwAPq0KGDJCk3N1cffvih+vTpoyFDhui3337TvHnzZLFYtH37drVp06bUcxoTE6PJkyere/fu6t69u3bu3KkuXbqUuELo7Nmz6tixo/73v//pxRdfVL169bRlyxZFR0fr+PHjmjFjxjVfo1evXnr++ef13Xff6YEHHjD3//zzz9q6davefvttc9+cOXPUvHlz/fWvf1WlSpX0xRdf6O9//7uKiooUHh5+y/tesGCBzp8/r6FDh8rFxUW1atUq9fxJ0smTJ9WlSxfVrl1b//jHP1SjRg0dOXJEn3zyiVXdoEGDtHDhQnXr1k2DBw/WxYsX9c0332jr1q1mMDd48GAtWrRIzzzzjF555RVt27ZNsbGxOnDggD799FOr46WlpalPnz568cUXNWTIEDVp0uQP/ZwAALbHvOjumxfNmDFDI0aMULVq1fTPf/5TkuTt7V3m4zo4OGj+/Plq1aqVhg0bZs43xo0bp3379mnjxo2qWrWqnn76af3www/6z3/+o+nTp8vT01OSVLt2bbOXTZs2afny5XrppZfk4uKi2bNnq2vXrtq+fXupa5qNHz9eEyZMUEhIiIYPH660tDTNmTNH3333nb799lurK/pOnz6t7t27629/+5v69OmjFStWaPjw4XJ2di4RKl0Lcy3c0QwAt4UFCxYYkkrdmjdvbvWc+vXrG/379zcft27d2ggNDS31dcLDw42r/Vd/1apVhiRj8uTJVvufeeYZw8HBwfjxxx8NwzCMlJQUQ5IxcuRIq7oBAwYYkoxx48aZ+8aNG2dIMvr06VPi9c6ePVti33/+8x9DkrF58+YSxxg6dKi57+LFi0bdunUNBwcH48033zT3nz592nBzc7M6JxcvXjTy8/OtXuf06dOGt7e38cILL5To4XInT540nJ2djdDQUKOoqMjc/9prrxmSrF5n0qRJRtWqVY0ffvjB6hj/+Mc/DCcnJyMjI+Oar5OTk2O4uLgYr7zyitX+KVOmGA4ODsbPP/9s7rvaebNYLMa99957S/tOT083JBnu7u7GyZMnr/lerubTTz81JBnffffdNWu+/vprQ5Lx0ksvlRgrfg+pqamGJGPw4MFW46+++qohyfj666/NffXr1zckGQkJCVa1f+TnBACwHeZFd++8yDAMo3nz5kbHjh1L7L+R477//vuGJGPx4sXG1q1bDScnpxI/p7ffftuQZKSnp5d4reLfsx07dpj7fv75Z8PV1dV46qmnzH3Fv6vFxyg+T126dDEKCwvNulmzZhmSjPnz55v7OnbsaEgypk6dau7Lz8832rRpY3h5eRkFBQWlnqdizLVwJ+Pre8BtJi4uTomJiSW2Vq1aXfe5NWrU0L59+3To0KEbft21a9fKyclJL730ktX+V155RYZh6Msvv5QkJSQkSJL+/ve/W9WNGDHimsceNmxYiX1ubm7mv8+fP6+srCy1b99ekrRz584S9YMHDzb/7eTkpHbt2skwDA0aNMjcX6NGDTVp0kQ//fSTVa2zs7Ok3y9Z/vXXX3Xx4kW1a9fuqq9zua+++koFBQUaMWKE1SeUI0eOLFG7cuVKPfLII6pZs6aysrLMLSQkRIWFhaVe6u3u7q5u3bppxYoVVl8JWL58udq3b6969eqZ+y4/b8WfHnfs2FE//fSTcnJybnnfPXr0sPoEsSxq1KghSVq9evU1P9n+f//v/8nBwUHjxo0rMVb8HtauXStJioqKshp/5ZVXJElr1qyx2u/v7y+LxWK174/8nAAAtse86O6bF5XmRo47dOhQWSwWjRgxQs8995waNmyof/3rXzf0esHBwQoMDDQf16tXT08++aTWrVunwsLCqz6n+DyNHDlSjo6X/u/2kCFD5O7uXmK+UqlSJb344ovmY2dnZ7344os6efKkUlJSytQncy3cyfj6HnCbefDBB63WECpW/D/spZk4caKefPJJ3XfffWrRooW6du2q5557rkwTt59//lm+vr6qXr261f5mzZqZ48X/6ejoKH9/f6u6Ro0aXfPYV9ZK0q+//qoJEyZo2bJlVt/3l2SGK5e7PJiRJA8PD7m6upqXWl++/8r1FxYtWqSpU6fq4MGDVn+or9bX5Yrfc+PGja32165dWzVr1rTad+jQIe3evfuagc2V7/FKvXr10qpVq5ScnKyHHnpIhw8fVkpKSolLnL/99luNGzdOycnJOnv2rNVYTk6OPDw8bmnf1ztnV9OxY0f16NFDEyZM0PTp09WpUyeFhYXp2WeflYuLiyTp8OHD8vX1LfXrgMW/e1f+rvn4+KhGjRrm+y6t1z/6cwIA2BbzortzXnQtN3rcefPmqWHDhjp06JC2bNliFf6VxZXvVZLuu+8+nT17VqdOnZKPj0+J8eLz1KRJE6v9zs7Ouvfee0vMV3x9fVW1atUSryH9vqZncThZGuZauJMRSgEVSIcOHXT48GF99tlnWr9+vT788ENNnz5d8fHxVp+o2drVJgB/+9vftGXLFo0aNUpt2rRRtWrVVFRUpK5du151EUQnJ6cy7ZNkdbXR4sWLNWDAAIWFhWnUqFHy8vKSk5OTYmNjdfjw4T/wrqwVFRXpL3/5i0aPHn3V8eLJxbU88cQTqlKlilasWKGHHnpIK1askKOjo3r27GnWHD58WI899piaNm2qadOmyc/PT87Ozlq7dq2mT59+U4tH3mjfNzqZk37/9O3jjz/W1q1b9cUXX2jdunV64YUXNHXqVG3dulXVqlW74eOVxdV6/aM/JwDAnYN50e/uxHlReR1348aN5gLde/bsUXBw8E297u2OuRbuZIRSQAVTq1YtDRw4UAMHDtSZM2fUoUMHjR8/3px8XeuPTP369fXVV1/pt99+s/pU8ODBg+Z48X8WFRUpPT3d6tOjH3/8scw9nj59WklJSZowYYJiYmLM/Tdzef31fPzxx7r33nv1ySefWL33q126fKXi93zo0CGru+OdOnVKp0+ftqpt2LChzpw5o5CQkJvqs2rVqnr88ce1cuVKTZs2TcuXL9cjjzwiX19fs+aLL75Qfn6+Pv/8c6tPSK+8Y44t+74R7du3V/v27fXGG29o6dKl6tu3r5YtW6bBgwerYcOGWrdunX799ddrfoJX/Lt36NAh85NqSTpx4oSys7PN910aW75fAID9MS+ydqfMi671c7mR4x4/flwjRoxQly5d5OzsrFdffVUWi8VqvnC98OVqP4MffvhBVapUueaVQMXHT0tLszpPBQUFSk9PL9H7sWPHlJeXZ3W11A8//CDp9zvc3QjmWrgTsaYUUIFceXl2tWrV1KhRI6tbuBb/wbvylrTdu3dXYWGhZs2aZbV/+vTpcnBwULdu3STJ/N747Nmzreree++9MvdZ/EmeccUtlW/F3Tiu9lrbtm1TcnLydZ8bEhKiypUr67333rN6/tX6/Nvf/qbk5GStW7euxFh2drYuXrx43dfr1auXjh07pg8//FDff/+9evXqdd33kpOTowULFti17+s5ffp0iZ918d19in83e/ToIcMwNGHChBLPL35u9+7dJZV8H9OmTZOkUu90VMwW7xcAcHtgXlS217od50VVq1Yt8TO50eMOGTJERUVFmjdvnubOnatKlSpp0KBBVr1f6+dfLDk52WqtraNHj+qzzz5Tly5drnllWkhIiJydnfXuu+9avda8efOUk5NTYr5y8eJFvf/+++bjgoICvf/++6pdu7bVelalYa6FOxlXSgEVSEBAgDp16qTAwEDVqlVLO3bs0Mcff6yIiAizpviP20svvSSLxSInJyf17t1bTzzxhDp37qx//vOfOnLkiFq3bq3169frs88+08iRI9WwYUPz+T169NCMGTP0yy+/mLc+Lv5EpyyX+7q7u6tDhw6aMmWKLly4oD/96U9av3690tPTy/2cPP744/rkk0/01FNPKTQ0VOnp6YqPj1dAQIDOnDlT6nNr166tV199VbGxsXr88cfVvXt37dq1S19++WWJNRtGjRqlzz//XI8//rgGDBigwMBA5eXlac+ePfr444915MiREs+5Uvfu3VW9enW9+uqrcnJyUo8ePazGiz/pe+KJJ/Tiiy/qzJkz+uCDD+Tl5aXjx4/bre/rWbRokWbPnq2nnnpKDRs21G+//aYPPvhA7u7u5uSnc+fOeu655/Tuu+/q0KFD5tcVvvnmG3Xu3FkRERFq3bq1+vfvr7lz5yo7O1sdO3bU9u3btWjRIoWFhalz587X7cUW7xcAcHtgXlTSnTIvCgwM1Jw5czR58mQ1atRIXl5eevTRR8t83AULFmjNmjVauHCh6tatK+n3oLBfv36aM2eOuTB98c//n//8p3r37q3KlSvriSeeMMOqFi1ayGKx6KWXXpKLi4sZPl4t2Ln8PEVHR2vChAnq2rWr/vrXvyotLU2zZ8/WAw88oH79+lnV+/r66q233tKRI0d03333afny5UpNTdXcuXNVuXLlUn8mxZhr4Y5mwzv9AShF8e1kr3Ur144dO1731seTJ082HnzwQaNGjRqGm5ub0bRpU+ONN96wup3sxYsXjREjRhi1a9c2HBwcrG6D/NtvvxmRkZGGr6+vUblyZaNx48bG22+/bXXbX8MwjLy8PCM8PNyoVauWUa1aNSMsLMxIS0szJFndirj4tsWnTp0q8X7++9//Gk899ZRRo0YNw8PDw+jZs6dx7Nixa94++cpj9O/f36hatep1z1NRUZHxr3/9y6hfv77h4uJi3H///cbq1auN/v37G/Xr17/qub5cYWGhMWHCBKNOnTqGm5ub0alTJ2Pv3r0lzn3x+YuOjjYaNWpkODs7G56ensZDDz1kvPPOO2W+pW/fvn0NSUZISMhVxz///HOjVatWhqurq9GgQQPjrbfeMubPn1/idsbl3Xd6erohyXj77bfL9D4ut3PnTqNPnz5GvXr1DBcXF8PLy8t4/PHHrW6xbBi//26+/fbbRtOmTQ1nZ2ejdu3aRrdu3YyUlBSz5sKFC8aECRMMf39/o3Llyoafn58RHR1tnD9/3upY9evXv+ZtwMvj5wQAuLWYF93d86LMzEwjNDTUqF69uiHJ6NixY5mPe/ToUcPDw8N44oknShz3qaeeMqpWrWr89NNP5r5JkyYZf/rTnwxHR0er+ZQkIzw83Fi8eLHRuHFj83xt2LDB6pjFv6uXz8MMwzBmzZplNG3a1KhcubLh7e1tDB8+3Dh9+rRVTfHPZ8eOHUZwcLDh6upq1K9f35g1a1ap5+dKzLVwJ3MwjCuu8wOAm5Camqr7779fixcvVt++fe3dDgAAgN0wLwKAsmFNKQA37Ny5cyX2zZgxQ46OjurQoYMdOgIAALAP5kUAcPNYUwrADZsyZYpSUlLUuXNnVapUSV9++aW+/PJLDR06VH5+fvZuDzZ06tQpFRYWXnPc2dn5mnd4AQCgImBehFuJuRYqOr6+B+CGJSYmasKECdq/f7/OnDmjevXq6bnnntM///lPVapE1n03adCggX7++edrjnfs2FEbN260XUMAANgY8yLcSsy1UNERSgEAbtq333571a8tFKtZs2aZb2cMAAAAa8y1UNERSgEAAAAAAMDmWOgcAAAAAAAANseXnG2oqKhIx44dU/Xq1eXg4GDvdgAAQBkYhqHffvtNvr6+cnTk8zxbY/4EAMCdp6zzJ0IpGzp27Bh34AAA4A519OhR1a1b195t3HWYPwEAcOe63vyJUMqGqlevLun3H4q7u7uduwEAAGWRm5srPz8/8+84bIv5EwAAd56yzp8IpWyo+JJzd3d3JlUAANxh+OqYfTB/AgDgznW9+RMLIwAAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANnfbhFJvvvmmHBwcNHLkSHPf+fPnFR4ernvuuUfVqlVTjx49dOLECavnZWRkKDQ0VFWqVJGXl5dGjRqlixcvWtVs3LhRbdu2lYuLixo1aqSFCxeWeP24uDg1aNBArq6uCgoK0vbt263Gy9ILAAAAAAAAyua2CKW+++47vf/++2rVqpXV/sjISH3xxRdauXKlNm3apGPHjunpp582xwsLCxUaGqqCggJt2bJFixYt0sKFCxUTE2PWpKenKzQ0VJ07d1ZqaqpGjhypwYMHa926dWbN8uXLFRUVpXHjxmnnzp1q3bq1LBaLTp48WeZeAAAAAAAAUHYOhmEY9mzgzJkzatu2rWbPnq3JkyerTZs2mjFjhnJyclS7dm0tXbpUzzzzjCTp4MGDatasmZKTk9W+fXt9+eWXevzxx3Xs2DF5e3tLkuLj4zVmzBidOnVKzs7OGjNmjNasWaO9e/ear9m7d29lZ2crISFBkhQUFKQHHnhAs2bNkiQVFRXJz89PI0aM0D/+8Y8y9VIWubm58vDwUE5Ojtzd3cvtHAIAgFuHv9/2xfkHAODOU9a/33a/Uio8PFyhoaEKCQmx2p+SkqILFy5Y7W/atKnq1aun5ORkSVJycrJatmxpBlKSZLFYlJubq3379pk1Vx7bYrGYxygoKFBKSopVjaOjo0JCQsyasvRyNfn5+crNzbXaAAAAAAAAIFWy54svW7ZMO3fu1HfffVdiLDMzU87OzqpRo4bVfm9vb2VmZpo1lwdSxePFY6XV5Obm6ty5czp9+rQKCwuvWnPw4MEy93I1sbGxmjBhwjXHAQAAAAAA7lZ2u1Lq6NGjevnll7VkyRK5urraq41bKjo6Wjk5OeZ29OhRe7cEAAAAAABwW7BbKJWSkqKTJ0+qbdu2qlSpkipVqqRNmzbp3XffVaVKleTt7a2CggJlZ2dbPe/EiRPy8fGRJPn4+JS4A17x4+vVuLu7y83NTZ6ennJycrpqzeXHuF4vV+Pi4iJ3d3erDQAAAAAAAHYMpR577DHt2bNHqamp5tauXTv17dvX/HflypWVlJRkPictLU0ZGRkKDg6WJAUHB2vPnj1Wd8lLTEyUu7u7AgICzJrLj1FcU3wMZ2dnBQYGWtUUFRUpKSnJrAkMDLxuLwAAALYQGxurBx54QNWrV5eXl5fCwsKUlpZmVXP+/HmFh4frnnvuUbVq1dSjR48SH8BlZGQoNDRUVapUkZeXl0aNGqWLFy9a1WzcuFFt27aVi4uLGjVqpIULF5boJy4uTg0aNJCrq6uCgoK0ffv2G+4FAADcnewWSlWvXl0tWrSw2qpWrap77rlHLVq0kIeHhwYNGqSoqCht2LBBKSkpGjhwoIKDg8273XXp0kUBAQF67rnn9P3332vdunUaO3aswsPD5eLiIkkaNmyYfvrpJ40ePVoHDx7U7NmztWLFCkVGRpq9REVF6YMPPtCiRYt04MABDR8+XHl5eRo4cKAklakXAAAAW9i0aZPCw8O1detWJSYm6sKFC+rSpYvy8vLMmsjISH3xxRdauXKlNm3apGPHjunpp582xwsLCxUaGqqCggJt2bJFixYt0sKFCxUTE2PWpKenKzQ0VJ07d1ZqaqpGjhypwYMHa926dWbN8uXLFRUVpXHjxmnnzp1q3bq1LBaL1QeG1+sFAADcxYzbSMeOHY2XX37ZfHzu3Dnj73//u1GzZk2jSpUqxlNPPWUcP37c6jlHjhwxunXrZri5uRmenp7GK6+8Yly4cMGqZsOGDUabNm0MZ2dn49577zUWLFhQ4rXfe+89o169eoazs7Px4IMPGlu3brUaL0sv15OTk2NIMnJycm7oeQAAwH5u97/fJ0+eNCQZmzZtMgzDMLKzs43KlSsbK1euNGsOHDhgSDKSk5MNwzCMtWvXGo6OjkZmZqZZM2fOHMPd3d3Iz883DMMwRo8ebTRv3tzqtXr16mVYLBbz8YMPPmiEh4ebjwsLCw1fX18jNja2zL1cz+1+/gEAQEll/fvtYBiGYcdM7K6Sm5srDw8P5eTksL4UAAB3iNv97/ePP/6oxo0ba8+ePWrRooW+/vprPfbYYzp9+rTVnYPr16+vkSNHKjIyUjExMfr888+Vmppqjqenp+vee+/Vzp07df/996tDhw5q27atZsyYYdYsWLBAI0eOVE5OjgoKClSlShV9/PHHCgsLM2v69++v7OxsffbZZ2Xq5Xpu9/MPAABKKuvf70o27AkAAADlqKioSCNHjtSf//xntWjRQpKUmZkpZ2dnqxBIkry9vZWZmWnWeHt7lxgvHiutJjc3V+fOndPp06dVWFh41ZqDBw+WuZcr5efnKz8/33ycm5t7vdMAAADuUHZbUwoAAAB/THh4uPbu3atly5bZu5VyExsbKw8PD3Pz8/Ozd0sAAOAWIZQCAAC4A0VERGj16tXasGGD6tata+738fFRQUGBsrOzrepPnDghHx8fs+bKO+AVP75ejbu7u9zc3OTp6SknJ6er1lx+jOv1cqXo6Gjl5OSY29GjR8twNgAAwJ2Ir+8BAIASMjIylJWVZe82boinp6fq1atn7zZuOcMwNGLECH366afauHGj/P39rcYDAwNVuXJlJSUlqUePHpKktLQ0ZWRkKDg4WJIUHBysN954QydPnpSXl5ckKTExUe7u7goICDBr1q5da3XsxMRE8xjOzs4KDAxUUlKSuaZUUVGRkpKSFBERUeZeruTi4mLeRRkAbkf8jQTKD6EUAACwkpGRoabNmunc2bP2buWGuFWpooMHDlT4SXd4eLiWLl2qzz77TNWrVzfXZvLw8JCbm5s8PDw0aNAgRUVFqVatWnJ3d9eIESMUHBys9u3bS5K6dOmigIAAPffcc5oyZYoyMzM1duxYhYeHm4HQsGHDNGvWLI0ePVovvPCCvv76a61YsUJr1qwxe4mKilL//v3Vrl07Pfjgg5oxY4by8vI0cOBAs6fr9QIAd5Lf/0Y21bmz5+zdyg1xq+KmgwcOVvi/kbjzEEoBAAArWVlZOnf2rP42eY68/Bvbu50yOZl+SCvGDldWVlaFn3DPmTNHktSpUyer/QsWLNCAAQMkSdOnT5ejo6N69Oih/Px8WSwWzZ4926x1cnLS6tWrNXz4cAUHB6tq1arq37+/Jk6caNb4+/trzZo1ioyM1MyZM1W3bl19+OGHslgsZk2vXr106tQpxcTEKDMzU23atFFCQoLV4ufX6wUA7iS//408p37v95P3fd7Xf8Jt4MQPJ7T4xcV3xd9I3HkIpQAAwFV5+TfWn5q1tncbuIJhGNetcXV1VVxcnOLi4q5ZU79+/RJfz7tSp06dtGvXrlJrIiIizK/r3WwvAHCn8b7PW36tuRED8Eex0DkAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAm7NrKDVnzhy1atVK7u7ucnd3V3BwsL788ktzvFOnTnJwcLDahg0bZnWMjIwMhYaGqkqVKvLy8tKoUaN08eJFq5qNGzeqbdu2cnFxUaNGjbRw4cISvcTFxalBgwZydXVVUFCQtm/fbjV+/vx5hYeH65577lG1atXUo0cPnThxovxOBgAAAAAAwF3ErqFU3bp19eabbyolJUU7duzQo48+qieffFL79u0za4YMGaLjx4+b25QpU8yxwsJChYaGqqCgQFu2bNGiRYu0cOFCxcTEmDXp6ekKDQ1V586dlZqaqpEjR2rw4MFat26dWbN8+XJFRUVp3Lhx2rlzp1q3bi2LxaKTJ0+aNZGRkfriiy+0cuVKbdq0SceOHdPTTz99i88QAAAAAABAxWTXUOqJJ55Q9+7d1bhxY91333164403VK1aNW3dutWsqVKlinx8fMzN3d3dHFu/fr3279+vxYsXq02bNurWrZsmTZqkuLg4FRQUSJLi4+Pl7++vqVOnqlmzZoqIiNAzzzyj6dOnm8eZNm2ahgwZooEDByogIEDx8fGqUqWK5s+fL0nKycnRvHnzNG3aND366KMKDAzUggULtGXLFqteAQAAAAAAUDa3zZpShYWFWrZsmfLy8hQcHGzuX7JkiTw9PdWiRQtFR0fr7Nmz5lhycrJatmwpb29vc5/FYlFubq55tVVycrJCQkKsXstisSg5OVmSVFBQoJSUFKsaR0dHhYSEmDUpKSm6cOGCVU3Tpk1Vr149swYAAAAAAABlV8neDezZs0fBwcE6f/68qlWrpk8//VQBAQGSpGeffVb169eXr6+vdu/erTFjxigtLU2ffPKJJCkzM9MqkJJkPs7MzCy1Jjc3V+fOndPp06dVWFh41ZqDBw+ax3B2dlaNGjVK1BS/ztXk5+crPz/ffJybm1vW0wIAAAAAAFCh2T2UatKkiVJTU5WTk6OPP/5Y/fv316ZNmxQQEKChQ4eadS1btlSdOnX02GOP6fDhw2rYsKEduy6b2NhYTZgwwd5tAAAAAAAA3Hbs/vU9Z2dnNWrUSIGBgYqNjVXr1q01c+bMq9YGBQVJkn788UdJko+PT4k74BU/9vHxKbXG3d1dbm5u8vT0lJOT01VrLj9GQUGBsrOzr1lzNdHR0crJyTG3o0ePlnYqAAAAAAAA7hp2D6WuVFRUZPWVt8ulpqZKkurUqSNJCg4O1p49e6zukpeYmCh3d3fzK4DBwcFKSkqyOk5iYqK5bpWzs7MCAwOtaoqKipSUlGTWBAYGqnLlylY1aWlpysjIsFr/6kouLi5yd3e32gAAAP6ozZs364knnpCvr68cHBy0atUqq3EHB4erbm+//bZZ06BBgxLjb775ptVxdu/erUceeUSurq7y8/OzugtysZUrV6pp06ZydXVVy5YttXbtWqtxwzAUExOjOnXqyM3NTSEhITp06FD5nQwAAHDHsmsoFR0drc2bN+vIkSPas2ePoqOjtXHjRvXt21eHDx/WpEmTlJKSoiNHjujzzz/X888/rw4dOqhVq1aSpC5duiggIEDPPfecvv/+e61bt05jx45VeHi4XFxcJEnDhg3TTz/9pNGjR+vgwYOaPXu2VqxYocjISLOPqKgoffDBB1q0aJEOHDig4cOHKy8vTwMHDpQkeXh4aNCgQYqKitKGDRuUkpKigQMHKjg4WO3bt7f9iQMAAHe1vLw8tW7dWnFxcVcdP378uNU2f/58OTg4qEePHlZ1EydOtKobMWKEOZabm6suXbqofv36SklJ0dtvv63x48dr7ty5Zs2WLVvUp08fDRo0SLt27VJYWJjCwsK0d+9es2bKlCl69913FR8fr23btqlq1aqyWCw6f/58OZ8VAABwp7HrmlInT57U888/r+PHj8vDw0OtWrXSunXr9Je//EVHjx7VV199pRkzZigvL09+fn7q0aOHxo4daz7fyclJq1ev1vDhwxUcHKyqVauqf//+mjhxolnj7++vNWvWKDIyUjNnzlTdunX14YcfymKxmDW9evXSqVOnFBMTo8zMTLVp00YJCQlWi59Pnz5djo6O6tGjh/Lz82WxWDR79mzbnCgAAIDLdOvWTd26dbvm+JXLC3z22Wfq3Lmz7r33Xqv91atXv+ZSBEuWLFFBQYHmz58vZ2dnNW/eXKmpqZo2bZq57ufMmTPVtWtXjRo1SpI0adIkJSYmatasWYqPj5dhGJoxY4bGjh2rJ598UpL00UcfydvbW6tWrVLv3r1v+hwAAIA7n11DqXnz5l1zzM/PT5s2bbruMerXr1/iMvErderUSbt27Sq1JiIiQhEREdccd3V1VVxc3DU/kQQAALgdnThxQmvWrNGiRYtKjL355puaNGmS6tWrp2effVaRkZGqVOn36WFycrI6dOggZ2dns95iseitt97S6dOnVbNmTSUnJysqKsrqmBaLxfw6YXp6ujIzMxUSEmKOe3h4KCgoSMnJyVcNpbh7MQAAdw+7330PAAAAt86iRYtUvXp1Pf3001b7X3rpJbVt21a1atXSli1bFB0drePHj2vatGmSpMzMTPn7+1s9p/gq8szMTNWsWVOZmZlWV5YX12RmZpp1lz/vajVX4u7FAADcPQilAAAAKrD58+erb9++cnV1tdp/+RVOrVq1krOzs1588UXFxsaaa3PaQ3R0tFVvubm58vPzs1s/AADg1rnt7r4HAACA8vHNN98oLS1NgwcPvm5tUFCQLl68qCNHjkj6fV2qEydOWNUUPy5eh+paNZePX/68q9VcibsXAwBw9yCUAgAAqKDmzZunwMBAtW7d+rq1qampcnR0lJeXlyQpODhYmzdv1oULF8yaxMRENWnSRDVr1jRrkpKSrI6TmJio4OBgSb/fcMbHx8eqJjc3V9u2bTNrAADA3Yuv7wEAANxhzpw5ox9//NF8nJ6ertTUVNWqVUv16tWT9Hv4s3LlSk2dOrXE85OTk7Vt2zZ17txZ1atXV3JysiIjI9WvXz8zcHr22Wc1YcIEDRo0SGPGjNHevXs1c+ZMTZ8+3TzOyy+/rI4dO2rq1KkKDQ3VsmXLtGPHDs2dO1eS5ODgoJEjR2ry5Mlq3Lix/P399frrr8vX11dhYWG38AwBAIA7AaEUAADAHWbHjh3q3Lmz+bh4Dab+/ftr4cKFkqRly5bJMAz16dOnxPNdXFy0bNkyjR8/Xvn5+fL391dkZKTVWk4eHh5av369wsPDFRgYKE9PT8XExGjo0KFmzUMPPaSlS5dq7Nixeu2119S4cWOtWrVKLVq0MGtGjx6tvLw8DR06VNnZ2Xr44YeVkJBQYo0rAABw9yGUAgAAuMN06tRJhmGUWjN06FCrAOlybdu21datW6/7Oq1atdI333xTak3Pnj3Vs2fPa447ODho4sSJmjhx4nVfDwAA3F1YUwoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwObsGkrNmTNHrVq1kru7u9zd3RUcHKwvv/zSHD9//rzCw8N1zz33qFq1aurRo4dOnDhhdYyMjAyFhoaqSpUq8vLy0qhRo3Tx4kWrmo0bN6pt27ZycXFRo0aNtHDhwhK9xMXFqUGDBnJ1dVVQUJC2b99uNV6WXgAAAAAAAFA2dg2l6tatqzfffFMpKSnasWOHHn30UT355JPat2+fJCkyMlJffPGFVq5cqU2bNunYsWN6+umnzecXFhYqNDRUBQUF2rJlixYtWqSFCxcqJibGrElPT1doaKg6d+6s1NRUjRw5UoMHD9a6devMmuXLlysqKkrjxo3Tzp071bp1a1ksFp08edKsuV4vAAAAAAAAKDu7hlJPPPGEunfvrsaNG+u+++7TG2+8oWrVqmnr1q3KycnRvHnzNG3aND366KMKDAzUggULtGXLFm3dulWStH79eu3fv1+LFy9WmzZt1K1bN02aNElxcXEqKCiQJMXHx8vf319Tp05Vs2bNFBERoWeeeUbTp083+5g2bZqGDBmigQMHKiAgQPHx8apSpYrmz58vSWXqBQAAAAAAAGV326wpVVhYqGXLlikvL0/BwcFKSUnRhQsXFBISYtY0bdpU9erVU3JysiQpOTlZLVu2lLe3t1ljsViUm5trXm2VnJxsdYzimuJjFBQUKCUlxarG0dFRISEhZk1Zerma/Px85ebmWm0AAAAAAAC4DUKpPXv2qFq1anJxcdGwYcP06aefKiAgQJmZmXJ2dlaNGjWs6r29vZWZmSlJyszMtAqkiseLx0qryc3N1blz55SVlaXCwsKr1lx+jOv1cjWxsbHy8PAwNz8/v7KdFAAAAAAAgArO7qFUkyZNlJqaqm3btmn48OHq37+/9u/fb++2ykV0dLRycnLM7ejRo/ZuCQAAVACbN2/WE088IV9fXzk4OGjVqlVW4wMGDJCDg4PV1rVrV6uaX3/9VX379pW7u7tq1KihQYMG6cyZM1Y1u3fv1iOPPCJXV1f5+flpypQpJXpZuXKlmjZtKldXV7Vs2VJr1661GjcMQzExMapTp47c3NwUEhKiQ4cOlc+JAAAAdzS7h1LOzs5q1KiRAgMDFRsbq9atW2vmzJny8fFRQUGBsrOzrepPnDghHx8fSZKPj0+JO+AVP75ejbu7u9zc3OTp6SknJ6er1lx+jOv1cjUuLi7mnQWLNwAAgD8qLy9PrVu3Vlxc3DVrunbtquPHj5vbf/7zH6vxvn37at++fUpMTNTq1au1efNmDR061BzPzc1Vly5dVL9+faWkpOjtt9/W+PHjNXfuXLNmy5Yt6tOnjwYNGqRdu3YpLCxMYWFh2rt3r1kzZcoUvfvuu4qPj9e2bdtUtWpVWSwWnT9/vhzPCAAAuBPZPZS6UlFRkfLz8xUYGKjKlSsrKSnJHEtLS1NGRoaCg4MlScHBwdqzZ4/VXfISExPl7u6ugIAAs+byYxTXFB/D2dlZgYGBVjVFRUVKSkoya8rSCwAAgK1069ZNkydP1lNPPXXNGhcXF/n4+JhbzZo1zbEDBw4oISFBH374oYKCgvTwww/rvffe07Jly3Ts2DFJ0pIlS1RQUKD58+erefPm6t27t1566SVNmzbNPM7MmTPVtWtXjRo1Ss2aNdOkSZPUtm1bzZo1S9LvV0nNmDFDY8eO1ZNPPqlWrVrpo48+0rFjx0pc3QUAAO4+dg2loqOjtXnzZh05ckR79uxRdHS0Nm7cqL59+8rDw0ODBg1SVFSUNmzYoJSUFA0cOFDBwcFq3769JKlLly4KCAjQc889p++//17r1q3T2LFjFR4eLhcXF0nSsGHD9NNPP2n06NE6ePCgZs+erRUrVigyMtLsIyoqSh988IEWLVqkAwcOaPjw4crLy9PAgQMlqUy9AAAA3E42btwoLy8vNWnSRMOHD9cvv/xijiUnJ6tGjRpq166duS8kJESOjo7atm2bWdOhQwc5OzubNRaLRWlpaTp9+rRZU9oNZdLT05WZmWlV4+HhoaCgoFJvFgMAAO4Olez54idPntTzzz+v48ePy8PDQ61atdK6dev0l7/8RZI0ffp0OTo6qkePHsrPz5fFYtHs2bPN5zs5OWn16tUaPny4goODVbVqVfXv318TJ040a/z9/bVmzRpFRkZq5syZqlu3rj788ENZLBazplevXjp16pRiYmKUmZmpNm3aKCEhwWrx8+v1AgAAcLvo2rWrnn76afn7++vw4cN67bXX1K1bNyUnJ8vJyUmZmZny8vKyek6lSpVUq1Ytqxu9+Pv7W9VcfkOZmjVrXvOGMpcf4/LnXa3mSvn5+crPzzcfc/diAAAqLruGUvPmzSt13NXVVXFxcaWul1C/fv0SC2peqVOnTtq1a1epNREREYqIiPhDvQAAANwOevfubf67ZcuWatWqlRo2bKiNGzfqscces2Nn1xcbG6sJEybYuw0AAGADt92aUgAAAChf9957rzw9PfXjjz9K+v0mLpevySlJFy9e1K+//louN5S5fPzy512t5krcvRgAgLsHoRQAAEAF99///le//PKL6tSpI+n3G8FkZ2crJSXFrPn6669VVFSkoKAgs2bz5s26cOGCWZOYmKgmTZqYi6Zf74Yy/v7+8vHxsarJzc3Vtm3brnmzGO5eDADA3YNQCgAA4A5z5swZpaamKjU1VdLvC4qnpqYqIyNDZ86c0ahRo7R161YdOXJESUlJevLJJ9WoUSNzTc1mzZqpa9euGjJkiLZv365vv/1WERER6t27t3x9fSVJzz77rJydnTVo0CDt27dPy5cv18yZMxUVFWX28fLLLyshIUFTp07VwYMHNX78eO3YscNcEsHBwUEjR47U5MmT9fnnn2vPnj16/vnn5evrq7CwMJueMwAAcPux65pSAAAAuHE7duxQ586dzcfFQVH//v01Z84c7d69W4sWLVJ2drZ8fX3VpUsXTZo0ybw7sSQtWbJEEREReuyxx8ybubz77rvmuIeHh9avX6/w8HAFBgbK09NTMTExGjp0qFnz0EMPaenSpRo7dqxee+01NW7cWKtWrVKLFi3MmtGjRysvL09Dhw5Vdna2Hn74YSUkJMjV1fVWniIAAHAHIJQCAAC4w3Tq1EmGYVxzfN26ddc9Rq1atbR06dJSa1q1aqVvvvmm1JqePXuqZ8+e1xx3cHDQxIkTre6ODAAAIPH1PQAAAAAAANgBoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZXyd4NAAAAAACAW+vAgQP2buGGeHp6ql69evZuA7cYoRQAAAAAABVU7olcOTg6qF+/fvZu5Ya4VXHTwQMHCaYqOEIpAAAAAAAqqHM552QUGer3fj953+dt73bK5MQPJ7T4xcXKysoilKrgCKUAAAAAAKjgvO/zll9rP3u3AVhhoXMAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwuUr2bgAAAAAAcHfKyMhQVlaWvdsoswMHDti7BaBCIZQCAAAAANhcRkaGmjZrqnNnz9m7FQB2QigFAAAAALC5rKwsnTt7Tv3e7yfv+7zt3U6Z7P9qv75840t7twFUGIRSAAAAAAC78b7PW36t/ezdRpmc+OGEvVsAKhQWOgcAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDm7BpKxcbG6oEHHlD16tXl5eWlsLAwpaWlWdV06tRJDg4OVtuwYcOsajIyMhQaGqoqVarIy8tLo0aN0sWLF61qNm7cqLZt28rFxUWNGjXSwoULS/QTFxenBg0ayNXVVUFBQdq+fbvV+Pnz5xUeHq577rlH1apVU48ePXTixInyORkAAAAAAAB3EbuGUps2bVJ4eLi2bt2qxMREXbhwQV26dFFeXp5V3ZAhQ3T8+HFzmzJlijlWWFio0NBQFRQUaMuWLVq0aJEWLlyomJgYsyY9PV2hoaHq3LmzUlNTNXLkSA0ePFjr1q0za5YvX66oqCiNGzdOO3fuVOvWrWWxWHTy5EmzJjIyUl988YVWrlypTZs26dixY3r66adv4RkCAAAAAAComCrZ88UTEhKsHi9cuFBeXl5KSUlRhw4dzP1VqlSRj4/PVY+xfv167d+/X1999ZW8vb3Vpk0bTZo0SWPGjNH48ePl7Oys+Ph4+fv7a+rUqZKkZs2a6f/+7/80ffp0WSwWSdK0adM0ZMgQDRw4UJIUHx+vNWvWaP78+frHP/6hnJwczZs3T0uXLtWjjz4qSVqwYIGaNWumrVu3qn379uV+fgAAAAAAACqq22pNqZycHElSrVq1rPYvWbJEnp6eatGihaKjo3X27FlzLDk5WS1btpS3t7e5z2KxKDc3V/v27TNrQkJCrI5psViUnJwsSSooKFBKSopVjaOjo0JCQsyalJQUXbhwwaqmadOmqlevnlkDAAAAAACAsrHrlVKXKyoq0siRI/XnP/9ZLVq0MPc/++yzql+/vnx9fbV7926NGTNGaWlp+uSTTyRJmZmZVoGUJPNxZmZmqTW5ubk6d+6cTp8+rcLCwqvWHDx40DyGs7OzatSoUaKm+HWulJ+fr/z8fPNxbm5uWU8HAAAAAABAhXbbXCkVHh6uvXv3atmyZVb7hw4dKovFopYtW6pv37766KOP9Omnn+rw4cN26rTsYmNj5eHhYW5+fn72bgkAAFQAmzdv1hNPPCFfX185ODho1apV5tiFCxc0ZswYtWzZUlWrVpWvr6+ef/55HTt2zOoYDRo0KHEzmTfffNOqZvfu3XrkkUfk6uoqPz8/q3U9i61cuVJNmzaVq6urWrZsqbVr11qNG4ahmJgY1alTR25ubgoJCdGhQ4fK72QAAIA71m0RSkVERGj16tXasGGD6tatW2ptUFCQJOnHH3+UJPn4+JS4A17x4+J1qK5V4+7uLjc3N3l6esrJyemqNZcfo6CgQNnZ2desuVJ0dLRycnLM7ejRo6W+NwAAgLLIy8tT69atFRcXV2Ls7Nmz2rlzp15//XXt3LlTn3zyidLS0vTXv/61RO3EiROtbiYzYsQIcyw3N1ddunRR/fr1lZKSorffflvjx4/X3LlzzZotW7aoT58+GjRokHbt2qWwsDCFhYVp7969Zs2UKVP07rvvKj4+Xtu2bVPVqlVlsVh0/vz5cj4rAADgTmPXUMowDEVEROjTTz/V119/LX9//+s+JzU1VZJUp04dSVJwcLD27NljdZe8xMREubu7KyAgwKxJSkqyOk5iYqKCg4MlSc7OzgoMDLSqKSoqUlJSklkTGBioypUrW9WkpaUpIyPDrLmSi4uL3N3drTYAAIA/qlu3bpo8ebKeeuqpEmMeHh5KTEzU3/72NzVp0kTt27fXrFmzlJKSooyMDKva6tWry8fHx9yqVq1qji1ZskQFBQWaP3++mjdvrt69e+ull17StGnTzJqZM2eqa9euGjVqlJo1a6ZJkyapbdu2mjVrlqTf53ozZszQ2LFj9eSTT6pVq1b66KOPdOzYMauruwAAwN3JrqFUeHi4Fi9erKVLl6p69erKzMxUZmamzp07J0k6fPiwJk2apJSUFB05ckSff/65nn/+eXXo0EGtWrWSJHXp0kUBAQF67rnn9P3332vdunUaO3aswsPD5eLiIkkaNmyYfvrpJ40ePVoHDx7U7NmztWLFCkVGRpq9REVF6YMPPtCiRYt04MABDR8+XHl5eebd+Dw8PDRo0CBFRUVpw4YNSklJ0cCBAxUcHMyd9wAAwG0tJydHDg4OJdbGfPPNN3XPPffo/vvv19tvv62LFy+aY8nJyerQoYOcnZ3NfRaLRWlpaTp9+rRZU9rNZNLT05WZmWlV4+HhoaCgoGveKCY/P1+5ublWGwAAqJjsutD5nDlzJEmdOnWy2r9gwQINGDBAzs7O+uqrrzRjxgzl5eXJz89PPXr00NixY81aJycnrV69WsOHD1dwcLCqVq2q/v37a+LEiWaNv7+/1qxZo8jISM2cOVN169bVhx9+KIvFYtb06tVLp06dUkxMjDIzM9WmTRslJCRYLX4+ffp0OTo6qkePHsrPz5fFYtHs2bNv0dkBAAD4486fP68xY8aoT58+Vldtv/TSS2rbtq1q1aqlLVu2KDo6WsePHzevhMrMzCxxFfvlN5OpWbPmNW8mc/nNZi5/3tVqrhQbG6sJEyb8gXcMAADuFHYNpQzDKHXcz89PmzZtuu5x6tevX2JRzSt16tRJu3btKrUmIiJCERER1xx3dXVVXFzcVddvAAAAuN1cuHBBf/vb32QYhvlhYLGoqCjz361atZKzs7NefPFFxcbGmleb20N0dLRVb7m5udwsBgCACuq2WOgcAAAA5as4kPr555/N9TZLExQUpIsXL+rIkSOS/tjNZC4fv/x5V6u5EmtyAgBw9yCUAgAAqGCKA6lDhw7pq6++0j333HPd56SmpsrR0VFeXl6Sfr9RzObNm3XhwgWzJjExUU2aNFHNmjXNmtJuJuPv7y8fHx+rmtzcXG3btu2aN4oBAAB3D7t+fQ8AAAA37syZM/rxxx/Nx+np6UpNTVWtWrVUp04dPfPMM9q5c6dWr16twsJCc/2mWrVqydnZWcnJydq2bZs6d+6s6tWrKzk5WZGRkerXr58ZOD377LOaMGGCBg0apDFjxmjv3r2aOXOmpk+fbr7uyy+/rI4dO2rq1KkKDQ3VsmXLtGPHDs2dO1eS5ODgoJEjR2ry5Mlq3Lix/P399frrr8vX11dhYWG2O2EAAOC2RCgFAABwh9mxY4c6d+5sPi5eg6l///4aP368Pv/8c0lSmzZtrJ63YcMGderUSS4uLlq2bJnGjx+v/Px8+fv7KzIy0motJw8PD61fv17h4eEKDAyUp6enYmJiNHToULPmoYce0tKlSzV27Fi99tpraty4sVatWqUWLVqYNaNHj1ZeXp6GDh2q7OxsPfzww0pISJCrq+utODUAAOAOQigFAABwh+nUqVOpN4y53s1k2rZtq61bt173dVq1aqVvvvmm1JqePXuqZ8+e1xx3cHDQxIkTre6MDAAAILGmFAAAAAAAAOyAUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANlfpZp+Yl5enTZs2KSMjQwUFBVZjL7300h9uDAAAoCJiDgUAAPC7mwqldu3ape7du+vs2bPKy8tTrVq1lJWVpSpVqsjLy4sJFQAAwFUwhwIAALjkpr6+FxkZqSeeeEKnT5+Wm5ubtm7dqp9//lmBgYF65513yrtHAACACoE5FAAAwCU3FUqlpqbqlVdekaOjo5ycnJSfny8/Pz9NmTJFr732Wnn3CAAAUCEwhwIAALjkpkKpypUry9Hx96d6eXkpIyNDkuTh4aGjR4+WX3cAAAAVCHMoAACAS25qTan7779f3333nRo3bqyOHTsqJiZGWVlZ+ve//60WLVqUd48AAAAVAnMoAACAS27qSql//etfqlOnjiTpjTfeUM2aNTV8+HCdOnVKc+fOLdcGAQAAKgrmUAAAAJfc1JVS7dq1M//t5eWlhISEcmsIAACgomIOBQAAcMlNXSkFAAAAAAAA/BFlvlKqbdu2SkpKUs2aNXX//ffLwcHhmrU7d+4sl+YAAADudMyhAAAArq7ModSTTz4pFxcXSVJYWNit6gcAAKBCYQ4FAABwdWUOpcaNG3fVfwMAAODamEMBAABc3U2tKfXdd99p27ZtJfZv27ZNO3bs+MNNAQAAVETMoQAAAC65qVAqPDxcR48eLbH/f//7n8LDw/9wUwAAABURcygAAIBLbiqU2r9/v9q2bVti//3336/9+/f/4aYAAAAqIuZQAAAAl9xUKOXi4qITJ06U2H/8+HFVqlTmZaoAAADuKsyhAAAALrmpUKpLly6Kjo5WTk6OuS87O1uvvfaa/vKXv5RbcwAAABUJcygAAIBLbuojuXfeeUcdOnRQ/fr1df/990uSUlNT5e3trX//+9/l2iAAAEBFwRwKAADgkpsKpf70pz9p9+7dWrJkib7//nu5ublp4MCB6tOnjypXrlzePQIAAFQIzKEAAAAuuenFC6pWraqhQ4eWZy8AAAAVHnMoAACA3910KHXo0CFt2LBBJ0+eVFFRkdVYTEzMH24MAACgImIOBQAA8LubCqU++OADDR8+XJ6envLx8ZGDg4M55uDgwIQKAADgKphDAQAAXHJTodTkyZP1xhtvaMyYMeXdDwAAQIXFHAoAAOASx5t50unTp9WzZ8/y7gUAAKBCYw4FAABwyU2FUj179tT69evLuxcAAIAKjTkUAADAJTf19b1GjRrp9ddf19atW9WyZcsStzB+6aWXyqU5AACAioQ5FAAAwCU3FUrNnTtX1apV06ZNm7Rp0yarMQcHByZUAAAAV8EcCgAA4JKbCqXS09PLuw8AAIAKjzkUAADAJTe1plSxgoICpaWl6eLFi+XVDwAAQIXHHAoAAOAmQ6mzZ89q0KBBqlKlipo3b66MjAxJ0ogRI/Tmm2+Wa4MAAAAVBXMoAACAS24qlIqOjtb333+vjRs3ytXV1dwfEhKi5cuXl1tzAAAAFQlzKAAAgEtuak2pVatWafny5Wrfvr0cHBzM/c2bN9fhw4fLrTkAAICKhDkUAADAJTd1pdSpU6fk5eVVYn9eXp7VBAsAAACXMIcCAAC45KZCqXbt2mnNmjXm4+JJ1Icffqjg4ODy6QwAAKCCYQ4FAABwyU19fe9f//qXunXrpv379+vixYuaOXOm9u/fry1btmjTpk3l3SMAAECFwBwKAADgkpu6Uurhhx9WamqqLl68qJYtW2r9+vXy8vJScnKyAgMDy7tHAACACoE5FAAAwCU3FUpJUsOGDfXBBx9o+/bt2r9/vxYvXqyWLVve0DFiY2P1wAMPqHr16vLy8lJYWJjS0tKsas6fP6/w8HDdc889qlatmnr06KETJ05Y1WRkZCg0NFRVqlSRl5eXRo0apYsXL1rVbNy4UW3btpWLi4saNWqkhQsXlugnLi5ODRo0kKurq4KCgrR9+/Yb7gUAAKA05TGHAgAAqAhuKpTKyMgodSurTZs2KTw8XFu3blViYqIuXLigLl26KC8vz6yJjIzUF198oZUrV2rTpk06duyYnn76aXO8sLBQoaGhKigo0JYtW7Ro0SItXLhQMTExZk16erpCQ0PVuXNnpaamauTIkRo8eLDWrVtn1ixfvlxRUVEaN26cdu7cqdatW8tisejkyZNl7gUAAKA05TWHAgAAqAhuak2pBg0alHqHmMLCwjIdJyEhwerxwoUL5eXlpZSUFHXo0EE5OTmaN2+eli5dqkcffVSStGDBAjVr1kxbt25V+/bttX79eu3fv19fffWVvL291aZNG02aNEljxozR+PHj5ezsrPj4ePn7+2vq1KmSpGbNmun//u//NH36dFksFknStGnTNGTIEA0cOFCSFB8frzVr1mj+/Pn6xz/+UaZeAAAASlNecygAAICK4KaulNq1a5d27txpbtu2bVN8fLzuu+8+rVy58qabycnJkSTVqlVLkpSSkqILFy4oJCTErGnatKnq1aun5ORkSVJycrJatmwpb29vs8ZisSg3N1f79u0zay4/RnFN8TEKCgqUkpJiVePo6KiQkBCzpiy9XCk/P1+5ublWGwAAuHuV1xxq8+bNeuKJJ+Tr6ysHBwetWrXKatwwDMXExKhOnTpyc3NTSEiIDh06ZFXz66+/qm/fvnJ3d1eNGjU0aNAgnTlzxqpm9+7deuSRR+Tq6io/Pz9NmTKlRC8rV65U06ZN5erqqpYtW2rt2rU33AsAALg73VQo1bp1a6utXbt2GjJkiN555x29++67N9VIUVGRRo4cqT//+c9q0aKFJCkzM1POzs6qUaOGVa23t7cyMzPNmssDqeLx4rHSanJzc3Xu3DllZWWpsLDwqjWXH+N6vVwpNjZWHh4e5ubn51fGswEAACqi8ppD5eXlqXXr1oqLi7vq+JQpU/Tuu+8qPj5e27ZtU9WqVWWxWHT+/Hmzpm/fvtq3b58SExO1evVqbd68WUOHDjXHc3Nz1aVLF9WvX18pKSl6++23NX78eM2dO9es2bJli/r06aNBgwZp165dCgsLU1hYmPbu3XtDvQAAgLvTTS90fjVNmjTRd999d1PPDQ8P1969e7Vs2bLybMmuoqOjlZOTY25Hjx61d0sAAOA2dKNzqG7dumny5Ml66qmnSowZhqEZM2Zo7NixevLJJ9WqVSt99NFHOnbsmHlF1YEDB5SQkKAPP/xQQUFBevjhh/Xee+9p2bJlOnbsmCRpyZIlKigo0Pz589W8eXP17t1bL730kqZNm2a+1syZM9W1a1eNGjVKzZo106RJk9S2bVvNmjWrzL0AAIC7102FUld+JS0nJ0cHDx7U2LFj1bhx4xs+XkREhFavXq0NGzaobt265n4fHx8VFBQoOzvbqv7EiRPy8fExa668A17x4+vVuLu7y83NTZ6ennJycrpqzeXHuF4vV3JxcZG7u7vVBgAA7l7lPYe6mvT0dGVmZlotOeDh4aGgoCCr5Q9q1Kihdu3amTUhISFydHTUtm3bzJoOHTrI2dnZrLFYLEpLS9Pp06fNmtKWSChLLwAA4O51U6FUjRo1VLNmTXOrVauWAgIClJycrDlz5pT5OIZhKCIiQp9++qm+/vpr+fv7W40HBgaqcuXKSkpKMvelpaUpIyNDwcHBkqTg4GDt2bPH6i55iYmJcnd3V0BAgFlz+TGKa4qP4ezsrMDAQKuaoqIiJSUlmTVl6QUAAKA05TWHKk3xsgLXW5bAy8vLarxSpUqqVatWuSyRcPn49Xq5EmtyAgBw97ipu+99/fXXVneOcXR0VO3atdWoUSNVqlT2Q4aHh2vp0qX67LPPVL16dXNy4uHhITc3N3l4eGjQoEGKiopSrVq15O7urhEjRig4ONi8212XLl0UEBCg5557TlOmTFFmZqbGjh2r8PBwubi4SJKGDRumWbNmafTo0XrhhRf09ddfa8WKFVqzZo3ZS1RUlPr376927drpwQcf1IwZM5SXl2feja8svQAAAJSmvOZQFVlsbKwmTJhg7zYAAIAN3NTsp1OnTuXy4sWfCF55vAULFmjAgAGSpOnTp8vR0VE9evRQfn6+LBaLZs+ebdY6OTlp9erVGj58uIKDg1W1alX1799fEydONGv8/f21Zs0aRUZGaubMmapbt64+/PBDWSwWs6ZXr146deqUYmJilJmZqTZt2ighIcHqk73r9QIAAFCa8ppDlaZ4WYETJ06oTp065v4TJ06oTZs2Zs3lV5lL0sWLF/Xrr7+WyxIJl49fr5crRUdHKyoqynycm5vLzWIAAKigbiqUio2Nlbe3t1544QWr/fPnz9epU6c0ZsyYMh3HMIzr1ri6uiouLu6ad5eRpPr165e4/fCVOnXqpF27dpVaExERoYiIiD/UCwAAwLWU1xyqNP7+/vLx8VFSUpIZ/OTm5mrbtm0aPny4pN+XNsjOzlZKSooCAwMl/X4VV1FRkYKCgsyaf/7zn7pw4YIqV64s6fflD5o0aaKaNWuaNUlJSRo5cqT5+pcvkVCWXq7k4uJiXu0OAAAqtptaU+r9999X06ZNS+xv3ry54uPj/3BTAAAAFVF5zaHOnDmj1NRUpaamSvp9QfHU1FRlZGTIwcFBI0eO1OTJk/X5559rz549ev755+Xr66uwsDBJUrNmzdS1a1cNGTJE27dv17fffquIiAj17t1bvr6+kqRnn31Wzs7OGjRokPbt26fly5dr5syZVlcxvfzyy0pISNDUqVN18OBBjR8/Xjt27DA/5CtLLwAA4O51U1dKZWZmWl2CXax27do6fvz4H24KAACgIiqvOdSOHTvUuXNn83FxUNS/f38tXLhQo0ePVl5enoYOHars7Gw9/PDDSkhIkKurq/mcJUuWKCIiQo899pi5PMG7775rjnt4eGj9+vUKDw9XYGCgPD09FRMTo6FDh5o1Dz30kJYuXaqxY8fqtddeU+PGjbVq1Sq1aNHCrClLLwAA4O50U6GUn5+fvv322xJ3y/v222/NT9cAAABgrbzmUJ06dSp1GQQHBwdNnDjRao3NK9WqVUtLly4t9XVatWqlb775ptSanj17qmfPnn+oFwAAcHe6qVBqyJAhGjlypC5cuKBHH31UkpSUlKTRo0frlVdeKdcGAQAAKgrmUAAAAJfcVCg1atQo/fLLL/r73/+ugoICSb8vAj5mzBhFR0eXa4MAAAAVBXMoAACAS24qlHJwcNBbb72l119/XQcOHJCbm5saN27MnVIAAABKwRwKAADgkpu6+16xzMxM/frrr2rYsKFcXFxKXdsAAAAAv2MOBQAAcJOh1C+//KLHHntM9913n7p3727eLWbQoEGshwAAAHANzKEAAAAuualQKjIyUpUrV1ZGRoaqVKli7u/Vq5cSEhLKrTkAAICKhDkUAADAJTe1ptT69eu1bt061a1b12p/48aN9fPPP5dLYwAAABUNcygAAIBLbupKqby8PKtP94r9+uuvLNQJAABwDcyhAAAALrmpUOqRRx7RRx99ZD52cHBQUVGRpkyZos6dO5dbcwAAABUJcygAAIBLburre1OmTNFjjz2mHTt2qKCgQKNHj9a+ffv066+/6ttvvy3vHgEAACoE5lAAAACX3NSVUi1atNAPP/yghx9+WE8++aTy8vL09NNPa9euXWrYsGF59wgAAFAhMIcCAAC45IavlLpw4YK6du2q+Ph4/fOf/7wVPQEAAFQ4zKEAAACs3fCVUpUrV9bu3btvRS8AAAAVFnMoAAAAazf19b1+/fpp3rx55d0LAABAhcYcCgAA4JKbWuj84sWLmj9/vr766isFBgaqatWqVuPTpk0rl+YAAAAqEuZQAAAAl9xQKPXTTz+pQYMG2rt3r9q2bStJ+uGHH6xqHBwcyq87AACACoA5FAAAQEk3FEo1btxYx48f14YNGyRJvXr10rvvvitvb+9b0hwAAEBFwBwKAACgpBtaU8owDKvHX375pfLy8sq1IQAAgIqGORQAAEBJN7XQebErJ1gAAAC4PuZQAAAANxhKOTg4lFjvgPUPAAAASsccCgAAoKQbWlPKMAwNGDBALi4ukqTz589r2LBhJe4c88knn5RfhwAAAHc45lAAAAAl3VAo1b9/f6vH/fr1K9dmAAAAKiLmUAAAACXdUCi1YMGCW9UHAABAhcUcCgAAoKQ/tNA5AAAAAAAAcDMIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzdk1lNq8ebOeeOIJ+fr6ysHBQatWrbIaHzBggBwcHKy2rl27WtX8+uuv6tu3r9zd3VWjRg0NGjRIZ86csarZvXu3HnnkEbm6usrPz09Tpkwp0cvKlSvVtGlTubq6qmXLllq7dq3VuGEYiomJUZ06deTm5qaQkBAdOnSofE4EAAAAAADAXcauoVReXp5at26tuLi4a9Z07dpVx48fN7f//Oc/VuN9+/bVvn37lJiYqNWrV2vz5s0aOnSoOZ6bm6suXbqofv36SklJ0dtvv63x48dr7ty5Zs2WLVvUp08fDRo0SLt27VJYWJjCwsK0d+9es2bKlCl69913FR8fr23btqlq1aqyWCw6f/58OZ4RAAAAAACAu0Mle754t27d1K1bt1JrXFxc5OPjc9WxAwcOKCEhQd99953atWsnSXrvvffUvXt3vfPOO/L19dWSJUtUUFCg+fPny9nZWc2bN1dqaqqmTZtmhlczZ85U165dNWrUKEnSpEmTlJiYqFmzZik+Pl6GYWjGjBkaO3asnnzySUnSRx99JG9vb61atUq9e/cur1MCAAAAAABwV7jt15TauHGjvLy81KRJEw0fPly//PKLOZacnKwaNWqYgZQkhYSEyNHRUdu2bTNrOnToIGdnZ7PGYrEoLS1Np0+fNmtCQkKsXtdisSg5OVmSlJ6erszMTKsaDw8PBQUFmTVXk5+fr9zcXKsNAADgVmvQoEGJJRAcHBwUHh4uSerUqVOJsWHDhlkdIyMjQ6GhoapSpYq8vLw0atQoXbx40apm48aNatu2rVxcXNSoUSMtXLiwRC9xcXFq0KCBXF1dFRQUpO3bt9+y9w0AAO4st3Uo1bVrV3300UdKSkrSW2+9pU2bNqlbt24qLCyUJGVmZsrLy8vqOZUqVVKtWrWUmZlp1nh7e1vVFD++Xs3l45c/72o1VxMbGysPDw9z8/Pzu6H3DwAAcDO+++47q+UPEhMTJUk9e/Y0a4YMGWJVc/mam4WFhQoNDVVBQYG2bNmiRYsWaeHChYqJiTFr0tPTFRoaqs6dOys1NVUjR47U4MGDtW7dOrNm+fLlioqK0rhx47Rz5061bt1aFotFJ0+etMFZAAAAt7vbOpTq3bu3/vrXv6ply5YKCwvT6tWr9d1332njxo32bq1MoqOjlZOTY25Hjx61d0sAAOAuULt2bfn4+Jjb6tWr1bBhQ3Xs2NGsqVKlilWNu7u7ObZ+/Xrt379fixcvVps2bdStWzdNmjRJcXFxKigokCTFx8fL399fU6dOVbNmzRQREaFnnnlG06dPN48zbdo0DRkyRAMHDlRAQIDi4+NVpUoVzZ8/33YnAwAA3LZu61DqSvfee688PT31448/SpJ8fHxKfNJ28eJF/frrr+Y6VD4+Pjpx4oRVTfHj69VcPn75865WczUuLi5yd3e32gAAAGypoKBAixcv1gsvvCAHBwdz/5IlS+Tp6akWLVooOjpaZ8+eNceSk5PVsmVLq6vELRaLcnNztW/fPrOmtOUPCgoKlJKSYlXj6OiokJAQlj8AAACS7rBQ6r///a9++eUX1alTR5IUHBys7OxspaSkmDVff/21ioqKFBQUZNZs3rxZFy5cMGsSExPVpEkT1axZ06xJSkqyeq3ExEQFBwdLkvz9/eXj42NVk5ubq23btpk1AAAAt6NVq1YpOztbAwYMMPc9++yzWrx4sTZs2KDo6Gj9+9//Vr9+/czxP7L8QW5urs6dO6esrCwVFhay/AEAALgmu95978yZM+ZVT9LvaxOkpqaqVq1aqlWrliZMmKAePXrIx8dHhw8f1ujRo9WoUSNZLBZJUrNmzdS1a1cNGTJE8fHxunDhgiIiItS7d2/5+vpK+n3SNWHCBA0aNEhjxozR3r17NXPmTKtLy19++WV17NhRU6dOVWhoqJYtW6YdO3Zo7ty5kiQHBweNHDlSkydPVuPGjeXv76/XX39dvr6+CgsLs90JAwAAuEHz5s1Tt27dzLmRJPMOxJLUsmVL1alTR4899pgOHz6shg0b2qNNU3R0tKKioszHubm5BFMAAFRQdg2lduzYoc6dO5uPiycg/fv315w5c7R7924tWrRI2dnZ8vX1VZcuXTRp0iS5uLiYz1myZIkiIiL02GOPydHRUT169NC7775rjnt4eGj9+vUKDw9XYGCgPD09FRMTYzUZe+ihh7R06VKNHTtWr732mho3bqxVq1apRYsWZs3o0aOVl5enoUOHKjs7Ww8//LASEhLk6up6K08RAADATfv555/11Vdf6ZNPPim1rvgK8x9//FENGzaUj49PibvklXX5A3d3d7m5ucnJyUlOTk43tfzB5XM9AABQcdk1lOrUqZMMw7jm+OV3b7mWWrVqaenSpaXWtGrVSt98802pNT179rS6I82VHBwcNHHiRE2cOPG6PQEAANwOFixYIC8vL4WGhpZal5qaKklWSyS88cYbOnnypHmn48TERLm7uysgIMCsWbt2rdVxLl/+wNnZWYGBgUpKSjKvLC8qKlJSUpIiIiLK6y0CAIA72B21phQAAADKpqioSAsWLFD//v1VqdKlzyEPHz6sSZMmKSUlRUeOHNHnn3+u559/Xh06dFCrVq0kSV26dFFAQICee+45ff/991q3bp3Gjh2r8PBw8yqmYcOG6aefftLo0aN18OBBzZ49WytWrFBkZKT5WlFRUfrggw+0aNEiHThwQMOHD1deXp4GDhxo25MBAABuS3a9UgoAAAC3xldffaWMjAy98MILVvudnZ311VdfacaMGcrLy5Ofn5969OihsWPHmjVOTk5avXq1hg8fruDgYFWtWlX9+/e3umLc399fa9asUWRkpGbOnKm6devqww8/NNf+lKRevXrp1KlTiomJUWZmptq0aaOEhIQSi58DAIC7E6EUAABABdSlS5erLpPg5+enTZs2Xff59evXL/H1vCt16tRJu3btKrUmIiKCr+sBAICr4ut7AAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzVWydwMAAAAAAABXOnDggL1buCGenp6qV6+evdu4oxBKAQAAAACA20buiVw5ODqoX79+9m7lhrhVcdPBAwcJpm4AoRQAAAAAALhtnMs5J6PIUL/3+8n7Pm97t1MmJ344ocUvLlZWVhah1A0glAIAAAAAALcd7/u85dfaz95t4BZioXMAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzdn17nubN2/W22+/rZSUFB0/flyffvqpwsLCzHHDMDRu3Dh98MEHys7O1p///GfNmTNHjRs3Nmt+/fVXjRgxQl988YUcHR3Vo0cPzZw5U9WqVTNrdu/erfDwcH333XeqXbu2RowYodGjR1v1snLlSr3++us6cuSIGjdurLfeekvdu3e/oV4AAAAAwF4yMjKUlZVl7zbK7MCBA/ZuAYCd2TWUysvLU+vWrfXCCy/o6aefLjE+ZcoUvfvuu1q0aJH8/f31+uuvy2KxaP/+/XJ1dZUk9e3bV8ePH1diYqIuXLiggQMHaujQoVq6dKkkKTc3V126dFFISIji4+O1Z88evfDCC6pRo4aGDh0qSdqyZYv69Omj2NhYPf7441q6dKnCwsK0c+dOtWjRosy9AAAAAIA9ZGRkqGmzpjp39py9WwGAMrNrKNWtWzd169btqmOGYWjGjBkaO3asnnzySUnSRx99JG9vb61atUq9e/fWgQMHlJCQoO+++07t2rWTJL333nvq3r273nnnHfn6+mrJkiUqKCjQ/Pnz5ezsrObNmys1NVXTpk0zQ6mZM2eqa9euGjVqlCRp0qRJSkxM1KxZsxQfH1+mXgAAAG4X48eP14QJE6z2NWnSRAcPHpQknT9/Xq+88oqWLVum/Px8WSwWzZ49W97e3mZ9RkaGhg8frg0bNqhatWrq37+/YmNjVanSpenjxo0bFRUVpX379snPz09jx47VgAEDrF43Li5Ob7/9tjIzM9W6dWu99957evDBB2/dmwfuUllZWTp39pz6vd9P3vd5X/8Jt4H9X+3Xl298ae82ANiRXUOp0qSnpyszM1MhISHmPg8PDwUFBSk5OVm9e/dWcnKyatSoYQZSkhQSEiJHR0dt27ZNTz31lJKTk9WhQwc5OzubNRaLRW+99ZZOnz6tmjVrKjk5WVFRUVavb7FYtGrVqjL3AgAAcDtp3ry5vvrqK/Px5WFSZGSk1qxZo5UrV8rDw0MRERF6+umn9e2330qSCgsLFRoaKh8fH23ZskXHjx/X888/r8qVK+tf//qXpN/nR6GhoRo2bJiWLFmipKQkDR48WHXq1JHFYpEkLV++XFFRUYqPj1dQUJBmzJghi8WitLQ0eXl52fBsAHcP7/u85dfaz95tlMmJH07YuwUAdnbbLnSemZkpSVaf2BU/Lh7LzMwsMaGpVKmSatWqZVVztWNc/hrXqrl8/Hq9XE1+fr5yc3OtNgAAAFuoVKmSfHx8zM3T01OSlJOTo3nz5mnatGl69NFHFRgYqAULFmjLli3aunWrJGn9+vXav3+/Fi9erDZt2qhbt26aNGmS4uLiVFBQIEmKj4+Xv7+/pk6dqmbNmikiIkLPPPOMpk+fbvYwbdo0DRkyRAMHDlRAQIDi4+NVpUoVzZ8/3/YnBAAA3HZu21CqIoiNjZWHh4e5+fndGZ9YAACAO9+hQ4fk6+ure++9V3379lVGRoYkKSUlRRcuXLC6Arxp06aqV6+ekpOTJUnJyclq2bKl1QdyFotFubm52rdvn1lz+TGKa4qPUVBQoJSUFKsaR0dHhYSEmDUAAODudtuGUj4+PpKkEyesL+k8ceKEOebj46OTJ09ajV+8eFG//vqrVc3VjnH5a1yr5vLx6/VyNdHR0crJyTG3o0ePXuddAwAA/HFBQUFauHChEhISNGfOHKWnp+uRRx7Rb7/9pszMTDk7O6tGjRpWz7nyKvGbvdI8NzdX586dU1ZWlgoLC7nSHAAAXNNtG0r5+/vLx8dHSUlJ5r7c3Fxt27ZNwcHBkqTg4GBlZ2crJSXFrPn6669VVFSkoKAgs2bz5s26cOGCWZOYmKgmTZqoZs2aZs3lr1NcU/w6ZenlalxcXOTu7m61AQAA3GrdunVTz5491apVK1ksFq1du1bZ2dlasWKFvVu7Lq40BwDg7mHXUOrMmTNKTU1VamqqpN8XzExNTVVGRoYcHBw0cuRITZ48WZ9//rn27Nmj559/Xr6+vgoLC5MkNWvWTF27dtWQIUO0fft2ffvtt4qIiFDv3r3l6+srSXr22Wfl7OysQYMGad++fVq+fLlmzpxptbD5yy+/rISEBE2dOlUHDx7U+PHjtWPHDkVEREhSmXoBAAC4XdWoUUP33XeffvzxR/n4+KigoEDZ2dlWNVdeJX6zV5q7u7vLzc1Nnp6ecnJy4kpzAABwTXYNpXbs2KH7779f999/vyQpKipK999/v2JiYiRJo0eP1ogRIzR06FA98MADOnPmjBISEuTq6moeY8mSJWratKkee+wxde/eXQ8//LDmzp1rjnt4eGj9+vVKT09XYGCgXnnlFcXExGjo0KFmzUMPPaSlS5dq7ty5at26tT7++GOtWrVKLVq0MGvK0gsAAMDt6MyZMzp8+LDq1KmjwMBAVa5c2eoK8LS0NGVkZFhdjb5nzx6rZRISExPl7u6ugIAAs6a0K82dnZ0VGBhoVVNUVKSkpCSuNAcAAJKkStcvuXU6deokwzCuOe7g4KCJEydq4sSJ16ypVauWli5dWurrtGrVSt98802pNT179lTPnj3/UC8AAAC3g1dffVVPPPGE6tevr2PHjmncuHFycnJSnz595OHhoUGDBikqKkq1atWSu7u7RowYoeDgYLVv316S1KVLFwUEBOi5557TlClTlJmZqbFjxyo8PFwuLi6SpGHDhmnWrFkaPXq0XnjhBX399ddasWKF1qxZY/YRFRWl/v37q127dnrwwQc1Y8YM5eXlaeDAgXY5LwAA4PZi11AKAAAA5e+///2v+vTpo19++UW1a9fWww8/rK1bt6p27dqSpOnTp8vR0VE9evRQfn6+LBaLZs+ebT7fyclJq1ev1vDhwxUcHKyqVauqf//+Vh/O+fv7a82aNYqMjNTMmTNVt25dffjhh7JYLGZNr169dOrUKcXExCgzM1Nt2rRRQkJCicXPAQDA3YlQCgAAoIJZtmxZqeOurq6Ki4tTXFzcNWvq16+vtWvXlnqcTp06adeuXaXWREREmOt0AgAAXO62vfseAAAAAAAAKi5CKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5irZuwEAACq6jIwMZWVl2buNMjtw4IC9WwAAAMBdgFAKAIBbKCMjQ02bNdO5s2ft3QoAAABwWyGUAgDgFsrKytK5s2f1t8lz5OXf2N7tlEnat0lKnB1r7zYAAABQwRFKAQBgA17+jfWnZq3t3UaZnEw/ZO8WAAAAcBdgoXMAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZHKAUAAAAAAACbI5QCAAAAAACAzRFKAQAAAAAAwOYIpQAAAAAAAGBzhFIAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANhcJXs3AAAAAAAAUBEcOHDA3i3cEE9PT9WrV89ur08oBQAAAAAA8AfknsiVg6OD+vXrZ+9WbohbFTcdPHDQbsEUoRQAAAAAAMAfcC7nnIwiQ/3e7yfv+7zt3U6ZnPjhhBa/uFhZWVmEUgAAAAAAAHcy7/u85dfaz95t3DFY6BwAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANgcoRQAAAAAAABsjlAKAAAAAAAANkcoBQAAAAAAAJsjlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYHKEUAAAAAAAAbI5QCgAAAAAAADZ3W4dS48ePl4ODg9XWtGlTc/z8+fMKDw/XPffco2rVqqlHjx46ceKE1TEyMjIUGhqqKlWqyMvLS6NGjdLFixetajZu3Ki2bdvKxcVFjRo10sKFC0v0EhcXpwYNGsjV1VVBQUHavn37LXnPAAAAAAAAd4PbOpSSpObNm+v48ePm9n//93/mWGRkpL744gutXLlSmzZt0rFjx/T000+b44WFhQoNDVVBQYG2bNmiRYsWaeHChYqJiTFr0tPTFRoaqs6dOys1NVUjR47U4MGDtW7dOrNm+fLlioqK0rhx47Rz5061bt1aFotFJ0+etM1JAAAAuAGxsbF64IEHVL16dXl5eSksLExpaWlWNZ06dSrx4d+wYcOsavhwDwAA3Eq3fShVqVIl+fj4mJunp6ckKScnR/PmzdO0adP06KOPKjAwUAsWLNCWLVu0detWSdL69eu1f/9+LV68WG3atFG3bt00adIkxcXFqaCgQJIUHx8vf39/TZ06Vc2aNVNERISeeeYZTZ8+3exh2rRpGjJkiAYOHKiAgADFx8erSpUqmj9/vu1PCAAAwHVs2rRJ4eHh2rp1qxITE3XhwgV16dJFeXl5VnVDhgyx+vBvypQp5hgf7gEAgFvttg+lDh06JF9fX917773q27evMjIyJEkpKSm6cOGCQkJCzNqmTZuqXr16Sk5OliQlJyerZcuW8vb2NmssFotyc3O1b98+s+byYxTXFB+joKBAKSkpVjWOjo4KCQkxa64lPz9fubm5VhsAAMCtlpCQoAEDBqh58+Zq3bq1Fi5cqIyMDKWkpFjVValSxerDP3d3d3OMD/cAAMCtdluHUkFBQVq4cKESEhI0Z84cpaen65FHHtFvv/2mzMxMOTs7q0aNGlbP8fb2VmZmpiQpMzPTKpAqHi8eK60mNzdX586dU1ZWlgoLC69aU3yMa4mNjZWHh4e5+fn53fA5AAAA+KNycnIkSbVq1bLav2TJEnl6eqpFixaKjo7W2bNnzTF7fbjHh3oAANw9Ktm7gdJ069bN/HerVq0UFBSk+vXra8WKFXJzc7NjZ2UTHR2tqKgo83Fubi7BFAAAsKmioiKNHDlSf/7zn9WiRQtz/7PPPqv69evL19dXu3fv1pgxY5SWlqZPPvlEUvl8uHf69Olrfrh38ODBq/YbGxurCRMm/LE3DQAA7gi3dSh1pRo1aui+++7Tjz/+qL/85S8qKChQdna21dVSJ06ckI+PjyTJx8enxEKaxXfnu7zmyjv2nThxQu7u7nJzc5OTk5OcnJyuWlN8jGtxcXGRi4vLTb1XAACA8hAeHq69e/da3SxGkoYOHWr+u2XLlqpTp44ee+wxHT58WA0bNrR1myY+1AMA4O5xW39970pnzpzR4cOHVadOHQUGBqpy5cpKSkoyx9PS0pSRkaHg4GBJUnBwsPbs2WO1kGZiYqLc3d0VEBBg1lx+jOKa4mM4OzsrMDDQqqaoqEhJSUlmDQAAwO0oIiJCq1ev1oYNG1S3bt1Sa4OCgiRJP/74o6Rrf3BXPFZaTfGHe56enjf84Z6Li4vc3d2tNgAAUDHd1qHUq6++qk2bNunIkSPasmWLnnrqKTk5OalPnz7y8PDQoEGDFBUVpQ0bNiglJUUDBw5UcHCw2rdvL0nq0qWLAgIC9Nxzz+n777/XunXrNHbsWIWHh5tXMA0bNkw//fSTRo8erYMHD2r27NlasWKFIiMjzT6ioqL0wQcfaNGiRTpw4ICGDx+uvLw8DRw40C7nBQAAoDSGYSgiIkKffvqpvv76a/n7+1/3OampqZKkOnXqSOLDPQAAcOvd1l/f++9//6s+ffrol19+Ue3atfXwww9r69atql27tiRp+vTpcnR0VI8ePZSfny+LxaLZs2ebz3dyctLq1as1fPhwBQcHq2rVqurfv78mTpxo1vj7+2vNmjWKjIzUzJkzVbduXX344YeyWCxmTa9evXTq1CnFxMQoMzNTbdq0UUJCQon1EQAAAG4H4eHhWrp0qT777DNVr17dXAPKw8NDbm5uOnz4sJYuXaru3bvrnnvu0e7duxUZGakOHTqoVatWkqw/3JsyZYoyMzOv+uHerFmzNHr0aL3wwgv6+uuvtWLFCq1Zs8bsJSoqSv3791e7du304IMPasaMGXy4BwAAJN3modSyZctKHXd1dVVcXJzi4uKuWVO/fn2tXbu21ON06tRJu3btKrUmIiJCERERpdYAAADcDubMmSPp9znO5RYsWKABAwbI2dlZX331lRkQ+fn5qUePHho7dqxZy4d7AADgVrutQykAAK6UkZGhrKwse7dRZgcOHLB3C7gLGYZR6rifn582bdp03ePw4R4AALiVCKUAAHeMjIwMNW3WTOfOnrV3KwAAAAD+IEIpAMAdIysrS+fOntXfJs+Rl39je7dTJmnfJilxdqy92wAAAABuO4RSAIA7jpd/Y/2pWWt7t1EmJ9MP2bsFAAAA4LbkaO8GAAAAAAAAcPchlAIAAAAAAIDNEUoBAAAAAADA5gilAAAAAAAAYHOEUgAAAAAAALA5QikAAAAAAADYXCV7NwAAAAAAt5uMjAxlZWXZu40yO3DggL1bAIAbRigFAAAAAJfJyMhQ02ZNde7sOXu3AgAVGqEUAAAAAFwmKytL586eU7/3+8n7Pm97t1Mm+7/ary/f+NLebQDADSGUAgAAAICr8L7PW36t/ezdRpmc+OGEvVsAgBvGQucAAAAAAACwOUIpAAAAAAAA2ByhFAAAAAAAAGyOUAoAAAAAAAA2RygFAAAAAAAAmyOUAgAAAAAAgM0RSgEAAAAAAMDmCKUAAAAAAABgc4RSAAAAAAAAsDlCKQAAAAAAANhcJXs3gPKRkZGhrKwse7dxQzw9PVWvXj17t4HbFL/TAAAAAFCxEUpVABkZGWrarJnOnT1r71ZuiFuVKjp44AD/Jx4l8DsNAAAAABUfoVQFkJWVpXNnz+pvk+fIy7+xvdspk5Pph7Ri7HBlZWXxf+BRAr/TAAAAAFDxEUpVIF7+jfWnZq3t3QZQbvidBgAAAICKi4XOAQAAAAAAYHOEUgAAAAAAALA5vr4Huzpw4IC9W7hh3GENFcmddpfDO/F/MwAAAABcHaEU7OK3rBNycHRUv3797N3KDeMOa6go7tS7HAIAAACoGAilYBfnfsuVUVR0R91dTeIOa6hY7sS7HKZ9m6TE2bH2bgMAAABAOSCUgl3dqXdXu9O+QsRXDlGaO+m/hyfTD9m7BQAAAADlhFAKuAF36tcO+cohAAAAAOB2QygF3IA78WuHfOUQAAAAAHA7IpQCbsKd9HUnAP+/vfsPrunO/zj+ipAQRBASLLZ+xa/4Pcky28asTBPFMu23RYtoLW2XVUst2W1pdbtlGduO0dWxxO7Mtpaulhk/W8MUTSn1W6hoKhiJDTYS0ZB4f//ouOtKRG7c3F95PmbOTO+5n3Pyft9PTvLqB+cAAAAA8EUsSgE1hD/dB8ufagUAAAAAVA2LUkCA89f7YAEAgMCRnZ2tvLw8b5dRafwBGQB4BotSQIDzx/tgndqzXZ+9/463ywAAAG6QnZ2tzl0660bRDW+XAgDwMSxKATWEP90H61LWaW+XAAAA3CQvL083im5ozAdjFNUpytvlVMqJz09o89ubvV0GAAQ8FqUAAAAAVLuoTlFq3bO1t8uolNxvc71dAgDUCCxKAYAb+dM9KPypVgAAAACBh0UpAHADbigPAAAAAK5hUQoA3IAbygMAAACAa1iUAgA34obyAAAAAFA5tbxdAAAAAAAAAGoeFqUAAAAAAADgcSxKAQAAAAAAwOO4pxQAAADgR7Kzs5WXl+ftMiotIyPD2yUAAHwUi1IuWrp0qRYuXKicnBz17NlTS5YsUVxcnLfLAgAA8Gm+mqH8bYHn4sWL+r+n/08/3PjB26UAAPDQWJRywb/+9S9Nnz5dy5YtU3x8vN59910lJSXp1KlTat68ubfLAwAA8Em+mqGys7PVuUtn3Si64bUaqmrMB2MU1SnK22VUyonPT2jz25u9XQYAwAexKOWCxYsXa+LEiXr++eclScuWLdPGjRu1cuVKzZ4928vVAQAA+CZfzVB5eXm6UXTDLxd4ojpFqXXP1t4up1Jyv831dgkAAB/FolQl3bx5UwcOHFBqaqpjX61atZSYmKj09HQvVgYAAOC7/CFDscADAIB3sChVSXl5eSotLVVUlPOfokVFRenkyZPlHlNcXKzi4mLH6/z8fEnStWvX3FpbYWGhJOlCxhHdLLru1nNXl/98f1qSf9Us+Wfd1OwZ1OwZ1OwZflnz2TOSfvyd6O7fs3fOZ2ZuPW9N4WqG8lR+kv6Xoc4dPqfi68UPGO0bck7nSKLm6kbNnkHNnkHNnuGPNV/KvCTJy/nJUCkXLlwwSfbll1867Z85c6bFxcWVe8zcuXNNEhsbGxsbG1sAbOfOnfNE5Ag4rmYo8hMbGxsbG1vgbA/KT/xNqUqKjIxUcHCwcnOd/8p0bm6uoqOjyz0mNTVV06dPd7y+ffu2rly5oqZNmyooKMhttV27dk2tW7fWuXPnFB4e7rbz+pJA75H+/F+g90h//i/Qe6zO/sxMBQUFatmypVvPW1O4mqE8lZ8krotAEOg90p//C/Qe6c+/+UJ+YlGqkkJCQtS3b19t375dI0aMkPRjSNq+fbumTJlS7jGhoaEKDQ112hcREVFtNYaHhwfkhXK3QO+R/vxfoPdIf/4v0Husrv4aNWrk9nPWFK5mKE/nJ4nrIhAEeo/05/8CvUf682/ezE8sSrlg+vTpSklJUb9+/RQXF6d3331X169fdzxJBgAAAGWRoQAAQHlYlHLByJEj9Z///Edz5sxRTk6OevXqpS1btpS5cScAAAD+hwwFAADKw6KUi6ZMmXLff67nLaGhoZo7d26Zv+oeSAK9R/rzf4HeI/35v0DvMdD7CwRkKM8L9P6kwO+R/vxfoPdIf/7NF/oLMuP5xgAAAAAAAPCsWt4uAAAAAAAAADUPi1IAAAAAAADwOBalAAAAAAAA4HEsSvmJt99+WwMGDFBYWJgiIiIqdYyZac6cOWrRooXq1aunxMREnT592mnMlStX9Nxzzyk8PFwRERGaMGGCCgsLq6GDirlax/fff6+goKByt7Vr1zrGlff+6tWrPdGSk6p8zgMHDixT+0svveQ0Jjs7W0OGDFFYWJiaN2+umTNnqqSkpDpbuS9Xe7xy5Yp+85vfKCYmRvXq1VObNm00depU5efnO43z1hwuXbpUP/3pT1W3bl3Fx8dr3759FY5fu3atOnfurLp16yo2NlabNm1yer8y16OnudLj8uXL9eijj6px48Zq3LixEhMTy4wfP358mblKTk6u7jbuy5X+Vq1aVab2unXrOo3xtTl0pb/yfp4EBQVpyJAhjjG+NH9ffPGFhg0bppYtWyooKEiffvrpA4/ZuXOn+vTpo9DQUHXo0EGrVq0qM8bV6xr+L9DzU1VqIUP9yFcyVKDlJynwMxT56X/8MT9JZKh7eT1DGfzCnDlzbPHixTZ9+nRr1KhRpY6ZP3++NWrUyD799FM7fPiw/fKXv7RHHnnEbty44RiTnJxsPXv2tK+++sp27dplHTp0sNGjR1dTF/fnah0lJSV28eJFp+3NN9+0Bg0aWEFBgWOcJEtLS3Mad3f/nlKVzzkhIcEmTpzoVHt+fr7j/ZKSEuvevbslJibawYMHbdOmTRYZGWmpqanV3U65XO3x6NGj9uSTT9qGDRssMzPTtm/fbh07drSnnnrKaZw35nD16tUWEhJiK1eutOPHj9vEiRMtIiLCcnNzyx2/Z88eCw4Otj//+c924sQJe+2116xOnTp29OhRx5jKXI+e5GqPzz77rC1dutQOHjxoGRkZNn78eGvUqJGdP3/eMSYlJcWSk5Od5urKlSueasmJq/2lpaVZeHi4U+05OTlOY3xpDl3t7/Lly069HTt2zIKDgy0tLc0xxpfmb9OmTfaHP/zB1q1bZ5Lsk08+qXD8d999Z2FhYTZ9+nQ7ceKELVmyxIKDg23Lli2OMa5+ZggMgZ6fqlILGcq3MlQg5SezwM9Q5Cdn/pafzMhQ9/KFDMWilJ9JS0urVKi6ffu2RUdH28KFCx37/vvf/1poaKh99NFHZmZ24sQJk2Rff/21Y8zmzZstKCjILly44Pba78dddfTq1cteeOEFp32VuRCrW1X7S0hIsFdeeeW+72/atMlq1arl9IP/r3/9q4WHh1txcbFbaq8sd83hmjVrLCQkxG7duuXY5405jIuLs8mTJztel5aWWsuWLe2dd94pd/wzzzxjQ4YMcdoXHx9vL774oplV7nr0NFd7vFdJSYk1bNjQ/v73vzv2paSk2PDhw91dapW42t+Dfrb62hw+7Pz95S9/sYYNG1phYaFjny/N390q8zPgd7/7nXXr1s1p38iRIy0pKcnx+mE/M/i3QMxP7qyFDOWdDBVo+cks8DMU+cmZv+UnMzLUvXwhQ/HP9wJUVlaWcnJylJiY6NjXqFEjxcfHKz09XZKUnp6uiIgI9evXzzEmMTFRtWrV0t69ez1WqzvqOHDggA4dOqQJEyaUeW/y5MmKjIxUXFycVq5cqR+vT895mP7++c9/KjIyUt27d1dqaqqKioqczhsbG6uoqCjHvqSkJF27dk3Hjx93fyMVcNf3Un5+vsLDw1W7dm2n/Z6cw5s3b+rAgQNO106tWrWUmJjouHbulZ6e7jRe+nEu7oyvzPXoSVXp8V5FRUW6deuWmjRp4rR/586dat68uWJiYvTyyy/r8uXLbq29MqraX2Fhodq2bavWrVtr+PDhTteRL82hO+ZvxYoVGjVqlOrXr++03xfmryoedA264zNDzeBP+cldtZChfuSNDBVI+UkK/AxFfiqfv+QniQxVHl/IULUfPAT+KCcnR5KcftneeX3nvZycHDVv3tzp/dq1a6tJkyaOMZ7gjjpWrFihLl26aMCAAU77582bp1/84hcKCwvTtm3b9Otf/1qFhYWaOnWq2+p/kKr29+yzz6pt27Zq2bKljhw5olmzZunUqVNat26d47zlze+d9zzJHXOYl5ent956S5MmTXLa7+k5zMvLU2lpabmf7cmTJ8s95n5zcfe1dmff/cZ4UlV6vNesWbPUsmVLp19QycnJevLJJ/XII4/ozJkz+v3vf6/BgwcrPT1dwcHBbu2hIlXpLyYmRitXrlSPHj2Un5+vRYsWacCAATp+/Lh+8pOf+NQcPuz87du3T8eOHdOKFSuc9vvK/FXF/a7Ba9eu6caNG7p69epDf8+jZvCn/OSuWshQP/JGhgqk/HSnlkDOUOSnsvwpP0lkqPL4QoZiUcqLZs+erQULFlQ4JiMjQ507d/ZQRe5V2f4e1o0bN/Thhx/q9ddfL/Pe3ft69+6t69eva+HChW75hVzd/d0dLmJjY9WiRQsNGjRIZ86cUfv27at8Xld4ag6vXbumIUOGqGvXrnrjjTec3qvOOUTVzJ8/X6tXr9bOnTudbmY5atQox3/HxsaqR48eat++vXbu3KlBgwZ5o9RK69+/v/r37+94PWDAAHXp0kUffPCB3nrrLS9W5n4rVqxQbGys4uLinPb78/yhZgn0/CSRoST/zlDkJ5SH/OT/yFDVg0UpL5oxY4bGjx9f4Zh27dpV6dzR0dGSpNzcXLVo0cKxPzc3V7169XKMuXTpktNxJSUlunLliuP4h1HZ/h62jo8//lhFRUUaN27cA8fGx8frrbfeUnFxsUJDQx84viKe6u+O+Ph4SVJmZqbat2+v6OjoMk89yM3NlSS3zJ/kmR4LCgqUnJyshg0b6pNPPlGdOnUqHO/OOSxPZGSkgoODHZ/lHbm5ufftJTo6usLxlbkePakqPd6xaNEizZ8/X59//rl69OhR4dh27dopMjJSmZmZHv2F/DD93VGnTh317t1bmZmZknxrDh+mv+vXr2v16tWaN2/eA7+Ot+avKu53DYaHh6tevXoKDg5+6O8J+I5Az08SGUry7wxVE/OTFPgZivz0YL6cnyQyVHl8IkO55c5U8BhXb9S5aNEix778/Pxyb9S5f/9+x5itW7d67UbnVa0jISGhzBNH7uePf/yjNW7cuMq1VoW7Pufdu3ebJDt8+LCZ/e8mnXc/9eCDDz6w8PBw++GHH9zXQCVUtcf8/Hz72c9+ZgkJCXb9+vVKfS1PzGFcXJxNmTLF8bq0tNRatWpV4U06hw4d6rSvf//+ZW7SWdH16Gmu9mhmtmDBAgsPD7f09PRKfY1z585ZUFCQrV+//qHrdVVV+rtbSUmJxcTE2G9/+1sz8705rGp/aWlpFhoaanl5eQ/8Gt6cv7upkjfp7N69u9O+0aNHl7lJ58N8T8C/BWJ+ckctZCjvZqhAy09mgZ+hyE8V8/X8ZEaGupcvZCgWpfzE2bNn7eDBg45H9h48eNAOHjzo9OjemJgYW7duneP1/PnzLSIiwtavX29Hjhyx4cOHl/tI4969e9vevXtt9+7d1rFjR6880vhBdZw/f95iYmJs7969TsedPn3agoKCbPPmzWXOuWHDBlu+fLkdPXrUTp8+be+//76FhYXZnDlzqr2fe7naX2Zmps2bN8/2799vWVlZtn79emvXrp099thjjmPuPM748ccft0OHDtmWLVusWbNmXnmcsZnrPebn51t8fLzFxsZaZmam0yNUS0pKzMx7c7h69WoLDQ21VatW2YkTJ2zSpEkWERHheErP2LFjbfbs2Y7xe/bssdq1a9uiRYssIyPD5s6dW+7jjB90PXqSqz3Onz/fQkJC7OOPP3aaqzs/gwoKCuzVV1+19PR0y8rKss8//9z69OljHTt29PgiaVX6e/PNN23r1q125swZO3DggI0aNcrq1q1rx48fd4zxpTl0tb87fv7zn9vIkSPL7Pe1+SsoKHD8npNkixcvtoMHD9rZs2fNzGz27Nk2duxYx/g7jzOeOXOmZWRk2NKlS8t9nHFFnxkCU6Dnp8rUQoby7QwVSPnJLPAzFPnJv/OTGRnKFzMUi1J+IiUlxSSV2Xbs2OEYI8nS0tIcr2/fvm2vv/66RUVFWWhoqA0aNMhOnTrldN7Lly/b6NGjrUGDBhYeHm7PP/+8U1DzlAfVkZWVVaZfM7PU1FRr3bq1lZaWljnn5s2brVevXtagQQOrX7++9ezZ05YtW1bu2Orman/Z2dn22GOPWZMmTSw0NNQ6dOhgM2fOtPz8fKfzfv/99zZ48GCrV6+eRUZG2owZM5weB+xJrva4Y8eOcr+nJVlWVpaZeXcOlyxZYm3atLGQkBCLi4uzr776yvFeQkKCpaSkOI1fs2aNderUyUJCQqxbt262ceNGp/crcz16mis9tm3btty5mjt3rpmZFRUV2eOPP27NmjWzOnXqWNu2bW3ixIle/R9+V/qbNm2aY2xUVJQ98cQT9s033zidz9fm0NXv0ZMnT5ok27ZtW5lz+dr83e/nw52eUlJSLCEhocwxvXr1spCQEGvXrp3T78M7KvrMEJgCPT9VphYylG9nqEDLT2aBn6HITymO1/6Yn8zIUL6WoYLMPPxsVwAAAAAAANR4tbxdAAAAAAAAAGoeFqUAAAAAAADgcSxKAQAAAAAAwONYlAIAAAAAAIDHsSgFAAAAAAAAj2NRCgAAAAAAAB7HohQAAAAAAAA8jkUpAAAAAAAAeByLUgBQSQMHDtS0adO8XQYAAIDfID8BqAiLUgBqhGHDhik5Obnc93bt2qWgoCAdOXLEw1UBAAD4LvITgOrGohSAGmHChAn67LPPdP78+TLvpaWlqV+/furRo0e11lBaWqrbt29X69cAAABwF/ITgOrGohSAGmHo0KFq1qyZVq1a5bS/sLBQa9eu1YgRIzR69Gi1atVKYWFhio2N1UcffVThOa9evapx48apcePGCgsL0+DBg3X69GnH+6tWrVJERIQ2bNigrl27KjQ0VNnZ2SouLtarr76qVq1aqX79+oqPj9fOnTsdx509e1bDhg1T48aNVb9+fXXr1k2bNm1y58cBAADwQOQnANWNRSkANULt2rU1btw4rVq1Smbm2L927VqVlpZqzJgx6tu3rzZu3Khjx45p0qRJGjt2rPbt23ffc44fP1779+/Xhg0blJ6eLjPTE088oVu3bjnGFBUVacGCBfrb3/6m48ePq3nz5poyZYrS09O1evVqHTlyRE8//bSSk5MdgWzy5MkqLi7WF198oaNHj2rBggVq0KBB9X04AAAA5SA/Aah2BgA1REZGhkmyHTt2OPY9+uijNmbMmHLHDxkyxGbMmOF4nZCQYK+88oqZmX377bcmyfbs2eN4Py8vz+rVq2dr1qwxM7O0tDSTZIcOHXKMOXv2rAUHB9uFCxecvtagQYMsNTXVzMxiY2PtjTfeeKheAQAA3IH8BKA61fbmghgAeFLnzp01YMAArVy5UgMHDlRmZqZ27dqlefPmqbS0VH/605+0Zs0aXbhwQTdv3lRxcbHCwsLKPVdGRoZq166t+Ph4x76mTZsqJiZGGRkZjn0hISFO91o4evSoSktL1alTJ6fzFRcXq2nTppKkqVOn6uWXX9a2bduUmJiop556qtrv1wAAAFAe8hOA6sQ/3wNQo0yYMEH//ve/VVBQoLS0NLVv314JCQlauHCh3nvvPc2aNUs7duzQoUOHlJSUpJs3bz7U16tXr56CgoIcrwsLCxUcHKwDBw7o0KFDji0jI0PvvfeeJOlXv/qVvvvuO40dO1ZHjx5Vv379tGTJkoeqAwAAoKrITwCqC4tSAGqUZ555RrVq1dKHH36of/zjH3rhhRcUFBSkPXv2aPjw4RozZox69uypdu3a6dtvv73vebp06aKSkhLt3bvXse/y5cs6deqUunbtet/jevfurdLSUl26dEkdOnRw2qKjox3jWrdurZdeeknr1q3TjBkztHz5cvd8AAAAAC4iPwGoLixKAahRGjRooJEjRyo1NVUXL17U+PHjJUkdO3bUZ599pi+//FIZGRl68cUXlZube9/zdOzYUcOHD9fEiRO1e/duHT58WGPGjFGrVq00fPjw+x7XqVMnPffccxo3bpzWrVunrKws7du3T++88442btwoSZo2bZq2bt2qrKwsffPNN9qxY4e6dOni1s8BAACgsshPAKoLi1IAapwJEybo6tWrSkpKUsuWLSVJr732mvr06aOkpCQNHDhQ0dHRGjFiRIXnSUtLU9++fTV06FD1799fZqZNmzapTp06Dzxu3LhxmjFjhmJiYjRixAh9/fXXatOmjSSptLRUkydPVpcuXZScnKxOnTrp/fffd0vvAAAAVUF+AlAdgszuerYnAAAAAAAA4AH8TSkAAAAAAAB4HItSAAAAAAAA8DgWpQAAAAAAAOBxLEoBAAAAAADA41iUAgAAAAAAgMexKAUAAAAAAACPY1EKAAAAAAAAHseiFAAAAAAAADyORSkAAAAAAAB4HItSAAAAAAAA8DgWpQAAAAAAAOBxLEoBAAAAAADA4/4fV671rPfupv0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_text=reviews[reviews[\"has_text\"]!=0]\n",
    "\n",
    "# Crear el bloque de histogramas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Histograma para columna_1\n",
    "axes[0].hist(reviews_text['vader_score'], bins=10, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Histograma de vader_score')\n",
    "axes[0].set_xlabel('Valores')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Histograma para columna_2\n",
    "axes[1].hist(reviews_text['textblob_score'], bins=10, color='lightgreen', edgecolor='black')\n",
    "axes[1].set_title('Histograma de textblob_score')\n",
    "axes[1].set_xlabel('Valores')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "\n",
    "# Ajustar el espacio entre los histogramas\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar los histogramas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmero de reviews totales: 751917\n",
      "Nmero de reviews totales con texto: 649952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nmero de reviews totales: {reviews.shape[0]}\")\n",
    "print(f\"Nmero de reviews totales con texto: {reviews_text.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creamos un dtaframe solo con las reviews que tienen texto\n",
    "reviews_text=reviews[reviews[\"has_text\"]!=0]\n",
    "# Calcular la matriz de correlacin para las columnas 'rating', 'vader_score' y 'textblob_score'\n",
    "correlation_matrix = reviews_text[['rating', 'vader_score', 'textblob_score']].corr()\n",
    "\n",
    "# Crear un diagrama de calor para visualizar la matriz de correlacin\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Matriz de Correlacin entre Rating, Vader Score y TextBlob Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A las reviews que tengan ceros en las columnas `vader_score` y `textblob_score` las clasificaremos como buenas si `rating`>=4 y malas si `rating`<=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews1=reviews.copy()\n",
    "# Crear la columna 'review_buena_vader' segn las condiciones dadas\n",
    "reviews1['review_buena_vader'] = reviews1.apply(\n",
    "    lambda row: 1 if row['vader_score'] > 0 else (\n",
    "        0 if row['vader_score'] < 0 else (\n",
    "            1 if row['rating'] >= 4 else 0\n",
    "        )\n",
    "    ), axis=1)\n",
    "\n",
    "# Crear la columna 'review_buena_textblob' segn las condiciones dadas\n",
    "reviews1['review_buena_textblob'] = reviews1.apply(\n",
    "    lambda row: 1 if row['textblob_score'] > 0 else (\n",
    "        0 if row['textblob_score'] < 0 else (\n",
    "            1 if row['rating'] >= 4 else 0\n",
    "        )\n",
    "    ), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la matriz de correlacin para las columnas 'rating', 'vader_score' y 'textblob_score'\n",
    "correlation_matrix = reviews1[['rating', 'review_buena_vader', 'review_buena_textblob']].corr()\n",
    "\n",
    "# Crear un diagrama de calor para visualizar la matriz de correlacin\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Matriz de Correlacin entre Rating, Vader Score y TextBlob Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la correlacin entre el `raiting` y el la clasificacin de \"buena\" y \"mala\" para las reviews aumento para ambos metodos de anlisis de sentimiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quedmosnos por ahora con `vader` porque es la que tiene la mayor correlacin con el rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>has_text</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>textblob_score</th>\n",
       "      <th>date</th>\n",
       "      <th>review_buena_vader</th>\n",
       "      <th>review_buena_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gormleysonth297269849815</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>0.205903</td>\n",
       "      <td>2018-09-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gormleysonth297269849815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gormleysonth297269849815</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gormleysonth297269849815</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2019-04-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gormleysonth297269849815</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751912</th>\n",
       "      <td>craftstreetk280493827005</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.518333</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751913</th>\n",
       "      <td>phokiengiang278518827006</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.632440</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751914</th>\n",
       "      <td>oecjapanesee277943827291</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8773</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751915</th>\n",
       "      <td>craftstreetk280493827005</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.393393</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751916</th>\n",
       "      <td>thesimplegre280638825043</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8458</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751917 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  rating  has_text  vader_score  \\\n",
       "0       gormleysonth297269849815       5         1       0.9576   \n",
       "1       gormleysonth297269849815       1         1       0.9186   \n",
       "2       gormleysonth297269849815       5         1       0.6808   \n",
       "3       gormleysonth297269849815       5         1       0.7906   \n",
       "4       gormleysonth297269849815       5         1       0.4404   \n",
       "...                          ...     ...       ...          ...   \n",
       "751912  craftstreetk280493827005       5         1       0.9892   \n",
       "751913  phokiengiang278518827006       4         1       0.9714   \n",
       "751914  oecjapanesee277943827291       3         1       0.8773   \n",
       "751915  craftstreetk280493827005       5         1       0.9806   \n",
       "751916  thesimplegre280638825043       1         1      -0.8458   \n",
       "\n",
       "        textblob_score        date  review_buena_vader  review_buena_textblob  \n",
       "0             0.205903  2018-09-17                   1                      1  \n",
       "1             0.497500  2018-09-20                   1                      1  \n",
       "2             0.100000  2018-08-22                   1                      1  \n",
       "3             0.750000  2019-04-17                   1                      1  \n",
       "4             0.700000  2019-05-20                   1                      1  \n",
       "...                ...         ...                 ...                    ...  \n",
       "751912        0.518333  2017-08-03                   1                      1  \n",
       "751913        0.632440  2017-12-25                   1                      1  \n",
       "751914        0.118750  2017-07-14                   1                      1  \n",
       "751915        0.393393  2018-03-20                   1                      1  \n",
       "751916        0.062500  2017-04-03                   0                      1  \n",
       "\n",
       "[751917 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos las reseas positivas (donde 'review_buena_vader' es 1)\n",
    "reviews_positivas = reviews1[reviews1['review_buena_vader'] == 1].groupby('id').size().reset_index(name='reviews_positivas')\n",
    "\n",
    "# Contamos las reseas negativas (donde 'review_buena_vader' es 0)\n",
    "reviews_negativas = reviews1[reviews1['review_buena_vader'] == 0].groupby('id').size().reset_index(name='reviews_negativas')\n",
    "\n",
    "# Unimos los resultados con el DataFrame original en funcin de 'gmap_id'\n",
    "reviews1 = reviews1.merge(reviews_positivas, on='id', how='left')\n",
    "reviews1 = reviews1.merge(reviews_negativas, on='id', how='left')\n",
    "reviews1[\"reviews_positivas\"]=reviews1[\"reviews_positivas\"].fillna(0)\n",
    "reviews1[\"reviews_negativas\"]=reviews1[\"reviews_negativas\"].fillna(0)\n",
    "\n",
    "reviews1 = reviews1.sort_values(by='id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatos_business.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26329 entries, 0 to 26328\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 26329 non-null  object \n",
      " 1   name               26329 non-null  object \n",
      " 2   street_address     15567 non-null  object \n",
      " 3   postal_code        26326 non-null  float64\n",
      " 4   latitude           26329 non-null  float64\n",
      " 5   longitude          26329 non-null  float64\n",
      " 6   city_id            26329 non-null  int64  \n",
      " 7   category_id        26329 non-null  object \n",
      " 8   stars              26329 non-null  float64\n",
      " 9   review_count       26329 non-null  int64  \n",
      " 10  is_open            26329 non-null  int64  \n",
      " 11  address            10421 non-null  object \n",
      " 12  reviews_positivas  14431 non-null  float64\n",
      " 13  reviews_negativas  14431 non-null  float64\n",
      "dtypes: float64(6), int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "metadatos1 = pd.merge(metadatos_business, reviews1[['id','reviews_positivas','reviews_negativas']], on='id', how='left')\n",
    "metadatos1=metadatos1.drop_duplicates(subset=\"id\",ignore_index=True)\n",
    "metadatos1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No todos los restaurantes del dataframe de metadata estan en reviews. Esto deja un gran nmero de entradas vacas en las columnas de `reviews_positivas` y `reviews_negativas`. Lo que haremos es ver la distribucin gaussiana que mejor se ajuste a las entradas quu no sean vacas. Luego rellenaremos estas ltimas con valores aleatorios siguiendo esas distribuciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redondeo_columna(df,columna):\n",
    "    '''Redondea los valores float de la columna a enteros, pero los que se redondean en 0 los cambia por 1'''\n",
    "    df[columna]=df[columna].round()\n",
    "    df[columna] = df[columna].replace(0, 1)\n",
    "    return df\n",
    "\n",
    "def rellenado_con_distribucion(df,columna):\n",
    "    '''Rellena los valores nulos de una columna numrica con nmeros positivos aleatorios que sigan la distribucin \n",
    "       que mejor se ajusta con los valores no nulos'''\n",
    "    columna_non_null=df[columna].dropna()\n",
    "    mu, std = norm.fit(columna_non_null)\n",
    "    lower, upper = 0, np.inf\n",
    "    truncnorm_dist = truncnorm((lower - mu) / std, (upper - mu) / std, loc=mu, scale=std)\n",
    "    random_values = truncnorm_dist.rvs(size=df[columna].isnull().sum())\n",
    "    random_values_series = pd.Series(random_values, index=df[df[columna].isnull()].index)\n",
    "    df[columna] = df[columna].fillna(random_values_series)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_positivas_non_null = metadatos1['reviews_positivas'].dropna()\n",
    "reviews_negativas_non_null = metadatos1['reviews_negativas'].dropna()\n",
    "\n",
    "# Visualizar la distribucin de los valores no nulos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  # 1 fila, 3 columnas\n",
    "\n",
    "sns.histplot(reviews_positivas_non_null.dropna(), kde=True, ax=axes[0], color='blue')\n",
    "axes[0].set_title('Distribucin de Reviews Positivas (sin valores nulos)')\n",
    "axes[0].set_xlabel('Reviews Positivas')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "\n",
    "sns.histplot(reviews_negativas_non_null, kde=True, ax=axes[1], color='green')\n",
    "axes[1].set_title('Distribucin de Reviews Negativas (sin valores nulos)')\n",
    "axes[1].set_xlabel('Reviews Negativas')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "metadatos1=rellenado_con_distribucion(metadatos1,'reviews_positivas')\n",
    "metadatos1=rellenado_con_distribucion(metadatos1,'reviews_negativas')\n",
    "metadatos1=redondeo_columna(metadatos1,['reviews_positivas','reviews_negativas'])\n",
    "\n",
    "# Visualizar la distribucin de los valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))  # 1 fila, 3 columnas\n",
    "\n",
    "sns.histplot(metadatos1['reviews_positivas'], kde=True, ax=axes[0], color='blue')\n",
    "axes[0].set_title('Distribucin de Reviews Positivas con vacos rellenados')\n",
    "axes[0].set_xlabel('Reviews Positivas')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "\n",
    "sns.histplot(metadatos1['reviews_negativas'], kde=True, ax=axes[1], color='green')\n",
    "axes[1].set_title('Distribucin de Reviews Negativas con vacos rellenados')\n",
    "axes[1].set_xlabel('Reviews Negativas')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, las distribuciones resultantes de rellenar las entradas vacas tienen las mismas caractersticas de las originales, solo que son mucho ms pobladas. Ahora creamos una columna `numero_reviews` que sea la suma de ambas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_positivas</th>\n",
       "      <th>reviews_negativas</th>\n",
       "      <th>numero_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26324</th>\n",
       "      <td>89.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26325</th>\n",
       "      <td>91.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26326</th>\n",
       "      <td>146.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26327</th>\n",
       "      <td>202.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26328</th>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26329 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviews_positivas  reviews_negativas  numero_reviews\n",
       "0                   88.0               31.0           119.0\n",
       "1                   51.0               13.0            64.0\n",
       "2                  219.0               26.0           245.0\n",
       "3                   19.0                1.0            20.0\n",
       "4                   14.0                1.0            15.0\n",
       "...                  ...                ...             ...\n",
       "26324               89.0               17.0           106.0\n",
       "26325               91.0                9.0           100.0\n",
       "26326              146.0               13.0           159.0\n",
       "26327              202.0               14.0           216.0\n",
       "26328               79.0                4.0            83.0\n",
       "\n",
       "[26329 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatos1[\"numero_reviews\"]=metadatos1[\"reviews_positivas\"]+metadatos1[\"reviews_negativas\"]\n",
    "metadatos1[[\"reviews_positivas\",\"reviews_negativas\",\"numero_reviews\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna Population a formato numrico\n",
    "metadatos1 = metadatos1.merge(ciudades[['city_id','city', 'population']], left_on='city_id', right_on='city_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el nmero de restaurantes por ciudad\n",
    "numero_restaurantes = metadatos1.groupby('city').size()\n",
    "# Unir el conteo de restaurantes con el DataFrame original\n",
    "metadatos1['numero_restaurantes'] = metadatos1['city'].map(numero_restaurantes)\n",
    "metadatos1 = metadatos1.sort_values(by='city', ascending=True)\n",
    "metadatos1=metadatos1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'street_address', 'postal_code', 'latitude', 'longitude',\n",
       "       'city_id', 'category_id', 'stars', 'review_count', 'is_open', 'address',\n",
       "       'reviews_positivas', 'reviews_negativas', 'numero_reviews', 'city',\n",
       "       'population', 'numero_restaurantes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatos1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatos1.to_csv('metadatos_ML.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Codificar las categoras y ciudades (Label Encoding)\\nlabel_encoder_city = LabelEncoder()\\nmetadatos1['city_encoded'] = label_encoder_city.fit_transform(metadatos1['city'])\\n\\nlabel_encoder_category = LabelEncoder()\\nmetadatos1['category_encoded'] = label_encoder_category.fit_transform(metadatos1['categories'])\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Codificar las categoras y ciudades (Label Encoding)\n",
    "label_encoder_city = LabelEncoder()\n",
    "metadatos1['city_encoded'] = label_encoder_city.fit_transform(metadatos1['city'])\n",
    "\n",
    "label_encoder_category = LabelEncoder()\n",
    "metadatos1['category_encoded'] = label_encoder_category.fit_transform(metadatos1['categories'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Phi_categora(id_categoria,df):\n",
    "\n",
    "    # Filtramos por categorias\n",
    "    df_filtrado=df[df['category_id'].apply(lambda x: id_categoria in x)]\n",
    "    # Calculamos columnas para la frmula \n",
    "    df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
    "    df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
    "    df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
    "    df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
    "    df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
    "    df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
    "    df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
    "    # Escalamos las columnas para que queden en un rango entre 0 y 1\n",
    "    variables_para_escalar=[\"P_h\",'1/P_r','1/P_c']\n",
    "    '''scaler = RobustScaler()\n",
    "    df_filtrado[[\"P_h\"]] = scaler.fit_transform(df_filtrado[[\"P_h\"]])\n",
    "    df_filtrado[['1/P_r','1/P_c']] = np.log1p(np.log1p(df_filtrado[['1/P_r','1/P_c']]))'''\n",
    "    df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
    "    scaler = MinMaxScaler()\n",
    "    df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
    "    # Creamos la columna con el coeficiente Phi\n",
    "    a=1\n",
    "    b=2\n",
    "    c=2.5\n",
    "    df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
    "    # Eliminamos los duplicados en las ciudades para que tengamos solo datos de ciudades\n",
    "    df_final=df_filtrado.drop_duplicates(subset=\"city\",ignore_index=True)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ac armo los datos de entrenamiento y los de testeo. El tema de las categoras hay que corregirlo. Hay demaciadas categorias y hay algunas que tienen 1 restaurante. Eso no puede quedar as para el futuro. Paula est en eso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_h\"]=(df_filtrado[\"population\"]/df_filtrado[\"numero_restaurantes\"])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{r,i}\"]=(df_filtrado['reviews_positivas']/df_filtrado['reviews_negativas'])*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"P_{c,i}\"]=df_filtrado['stars']*df_filtrado['numero_reviews']\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{r,i}'] = df_filtrado.groupby('city')[\"P_{r,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_r'] = (df_filtrado['suma P_{r,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['suma P_{c,i}'] = df_filtrado.groupby('city')[\"P_{c,i}\"].transform('sum')\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['1/P_c'] = (df_filtrado['suma P_{c,i}']/df_filtrado['numero_restaurantes'])**(-1)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[['1/P_r']] = np.log1p(np.log1p(df_filtrado[['1/P_r']]))\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[variables_para_escalar] = scaler.fit_transform(df_filtrado[variables_para_escalar])\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25208\\4062725084.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado[\"Phi\"]=a*df_filtrado[\"P_h\"]+b*df_filtrado[\"1/P_r\"]+c*df_filtrado[\"1/P_c\"]\n"
     ]
    }
   ],
   "source": [
    "metadatos1['category_id']=metadatos1['category_id'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "categorias_list=[i for i in range(1,categorias.shape[0]+1)]\n",
    "dfs_categorias = [Phi_categora(categoria,metadatos1) for categoria in categorias_list]\n",
    "for i in range(1,len(dfs_categorias)+1):\n",
    "    dfs_categorias[i-1]['category_id']=i\n",
    "\n",
    "X=[dfs_categorias[i][['city_id', 'category_id']] for i in range(len(dfs_categorias))]\n",
    "y=[dfs_categorias[i]['Phi'] for i in range(len(dfs_categorias))]\n",
    "\n",
    "# Filtrar los dataframes que tienen ms de una muestra\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "\n",
    "for i in range(len(dfs_categorias)):\n",
    "    if len(X[i]) > 1:  # Solo dividir si hay ms de 1 muestra\n",
    "        X_temp, X_temp_test, y_temp, y_temp_test = train_test_split(X[i], y[i], test_size=0.2, random_state=42)\n",
    "        X_train_list.append(X_temp)\n",
    "        X_test_list.append(X_temp_test)\n",
    "        y_train_list.append(y_temp)\n",
    "        y_test_list.append(y_temp_test)\n",
    "    else:\n",
    "        print(f\"Categoria '{categorias[i]}' tiene solo una muestra. No se puede dividir.\")\n",
    "\n",
    "X_train=pd.concat([df for df in X_train_list],axis=0, ignore_index=True)\n",
    "X_test=pd.concat([df for df in X_test_list],axis=0, ignore_index=True)\n",
    "y_train=pd.concat([df for df in y_train_list],axis=0, ignore_index=True)\n",
    "y_test=pd.concat([df for df in y_test_list],axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el `numero de neuronas por capas` para ver como cambia el Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - loss: 207.2467 - val_loss: 1.9897\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 13.7038 - val_loss: 0.9224\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 6.5227 - val_loss: 0.4206\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.6319 - val_loss: 0.3295\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 2.7119 - val_loss: 0.2438\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 1.5842 - val_loss: 0.1603\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 1.2149 - val_loss: 0.1187\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.9410 - val_loss: 0.1028\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - loss: 0.6628 - val_loss: 0.0852\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.5217 - val_loss: 0.0816\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.4951 - val_loss: 0.0775\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.4062 - val_loss: 0.0781\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.3445 - val_loss: 0.0778\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.2769 - val_loss: 0.0750\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.2445 - val_loss: 0.0787\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1825 - val_loss: 0.0733\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.1886 - val_loss: 0.0719\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.1654 - val_loss: 0.0729\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1475 - val_loss: 0.0733\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1347 - val_loss: 0.0727\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.1198 - val_loss: 0.0734\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1057 - val_loss: 0.0729\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0925 - val_loss: 0.0729\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.1001 - val_loss: 0.0736\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0990 - val_loss: 0.0729\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0854 - val_loss: 0.0730\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0845 - val_loss: 0.0738\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0912 - val_loss: 0.0735\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0882 - val_loss: 0.0733\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0775 - val_loss: 0.0733\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0829 - val_loss: 0.0732\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0901 - val_loss: 0.0734\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - loss: 0.0876 - val_loss: 0.0734\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 0.0832 - val_loss: 0.0733\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - loss: 0.0851 - val_loss: 0.0733\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - loss: 0.0870 - val_loss: 0.0731\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0776 - val_loss: 0.0733\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - loss: 0.0885 - val_loss: 0.0733\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0943 - val_loss: 0.0732\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0843 - val_loss: 0.0733\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0847 - val_loss: 0.0731\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0952 - val_loss: 0.0731\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0802 - val_loss: 0.0730\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0761 - val_loss: 0.0731\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0751 - val_loss: 0.0728\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0791 - val_loss: 0.0731\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0779 - val_loss: 0.0728\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0842 - val_loss: 0.0732\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0917 - val_loss: 0.0726\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0833 - val_loss: 0.0732\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0746 - val_loss: 0.0727\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0784 - val_loss: 0.0729\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0777 - val_loss: 0.0731\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0770 - val_loss: 0.0730\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0796 - val_loss: 0.0722\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.0788 - val_loss: 0.0720\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0846 - val_loss: 0.0738\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0799 - val_loss: 0.0734\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0844 - val_loss: 0.0721\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0911 - val_loss: 0.0720\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0909 - val_loss: 0.0716\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0846 - val_loss: 0.0722\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0788 - val_loss: 0.0721\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0862 - val_loss: 0.0720\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0925 - val_loss: 0.0722\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0849 - val_loss: 0.0730\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0943 - val_loss: 0.0721\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0791 - val_loss: 0.0726\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0796 - val_loss: 0.0722\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0882 - val_loss: 0.0714\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0741 - val_loss: 0.0716\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0845 - val_loss: 0.0714\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0789 - val_loss: 0.0715\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0850 - val_loss: 0.0722\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0787 - val_loss: 0.0719\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0880 - val_loss: 0.0716\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0835 - val_loss: 0.0716\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0789 - val_loss: 0.0715\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0766 - val_loss: 0.0718\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0769 - val_loss: 0.0720\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0807 - val_loss: 0.0713\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0849 - val_loss: 0.0717\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0787 - val_loss: 0.0723\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0866 - val_loss: 0.0718\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0809 - val_loss: 0.0720\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0783 - val_loss: 0.0720\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0802 - val_loss: 0.0718\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0923 - val_loss: 0.0709\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0775 - val_loss: 0.0718\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0785 - val_loss: 0.0715\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 0.0859 - val_loss: 0.0713\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0823 - val_loss: 0.0718\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0863 - val_loss: 0.0712\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0820 - val_loss: 0.0711\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0825 - val_loss: 0.0708\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.0804 - val_loss: 0.0711\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - loss: 0.0881 - val_loss: 0.0714\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 0.0869 - val_loss: 0.0708\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0809 - val_loss: 0.0711\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0806 - val_loss: 0.0712\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0817 - val_loss: 0.0721\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0825 - val_loss: 0.0714\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0831 - val_loss: 0.0715\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0797 - val_loss: 0.0705\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0817 - val_loss: 0.0713\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.0781 - val_loss: 0.0707\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0781 - val_loss: 0.0729\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0890 - val_loss: 0.0714\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0840 - val_loss: 0.0711\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0776 - val_loss: 0.0714\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0725 - val_loss: 0.0711\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0814 - val_loss: 0.0705\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0814 - val_loss: 0.0709\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0770 - val_loss: 0.0722\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0879 - val_loss: 0.0716\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0850 - val_loss: 0.0708\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0809 - val_loss: 0.0707\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0801 - val_loss: 0.0712\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 0.0892 - val_loss: 0.0705\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0837 - val_loss: 0.0712\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.0864 - val_loss: 0.0707\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - loss: 0.0855 - val_loss: 0.0713\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0846 - val_loss: 0.0709\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.0854 - val_loss: 0.0718\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0827 - val_loss: 0.0709\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0739 - val_loss: 0.0715\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0811 - val_loss: 0.0706\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0786 - val_loss: 0.0703\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0848 - val_loss: 0.0712\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0762 - val_loss: 0.0710\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0769 - val_loss: 0.0715\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0866 - val_loss: 0.0723\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0746 - val_loss: 0.0705\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0825 - val_loss: 0.0712\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0883 - val_loss: 0.0711\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0820 - val_loss: 0.0706\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0805 - val_loss: 0.0718\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - loss: 0.0779 - val_loss: 0.0739\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.0903 - val_loss: 0.0706\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0783 - val_loss: 0.0708\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 0.0795 - val_loss: 0.0715\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0834 - val_loss: 0.0700\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0792 - val_loss: 0.0715\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0848 - val_loss: 0.0714\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0866 - val_loss: 0.0704\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.0781 - val_loss: 0.0708\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0875 - val_loss: 0.0703\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.0810 - val_loss: 0.0710\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 97ms/step - loss: 0.0946 - val_loss: 0.0704\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 0.0775 - val_loss: 0.0710\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - loss: 141.5035 - val_loss: 0.1188\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.4137 - val_loss: 0.2563\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 2.4751 - val_loss: 0.1548\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 1.2073 - val_loss: 0.0966\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.6139 - val_loss: 0.0728\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.2689 - val_loss: 0.0754\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.1333 - val_loss: 0.0731\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0891 - val_loss: 0.0736\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0806 - val_loss: 0.0742\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0847 - val_loss: 0.0738\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0819 - val_loss: 0.0735\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0812 - val_loss: 0.0737\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0801 - val_loss: 0.0735\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0858 - val_loss: 0.0729\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0788 - val_loss: 0.0730\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0798 - val_loss: 0.0727\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0925 - val_loss: 0.0734\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0829 - val_loss: 0.0729\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0871 - val_loss: 0.0728\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0798 - val_loss: 0.0728\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0827 - val_loss: 0.0729\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0878 - val_loss: 0.0732\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0842 - val_loss: 0.0735\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0873 - val_loss: 0.0726\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0783 - val_loss: 0.0727\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0983 - val_loss: 0.0726\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0745 - val_loss: 0.0727\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0759 - val_loss: 0.0732\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0818 - val_loss: 0.0726\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0757 - val_loss: 0.0724\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0786 - val_loss: 0.0732\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0782 - val_loss: 0.0729\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0794 - val_loss: 0.0725\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0758 - val_loss: 0.0727\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0817 - val_loss: 0.0728\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0847 - val_loss: 0.0725\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0911 - val_loss: 0.0727\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0854 - val_loss: 0.0727\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0828 - val_loss: 0.0724\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0770 - val_loss: 0.0729\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0834 - val_loss: 0.0726\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0814 - val_loss: 0.0733\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0716 - val_loss: 0.0725\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0818 - val_loss: 0.0725\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0750 - val_loss: 0.0726\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0832 - val_loss: 0.0732\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0855 - val_loss: 0.0730\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0911 - val_loss: 0.0724\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0783 - val_loss: 0.0726\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0935 - val_loss: 0.0723\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0852 - val_loss: 0.0721\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0831 - val_loss: 0.0724\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0823 - val_loss: 0.0726\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0829 - val_loss: 0.0721\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0884 - val_loss: 0.0725\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0854 - val_loss: 0.0720\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0743 - val_loss: 0.0720\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0893 - val_loss: 0.0719\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0814 - val_loss: 0.0725\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0766 - val_loss: 0.0725\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0763 - val_loss: 0.0726\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0827 - val_loss: 0.0726\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0871 - val_loss: 0.0720\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0804 - val_loss: 0.0723\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0764 - val_loss: 0.0728\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0760 - val_loss: 0.0719\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0806 - val_loss: 0.0724\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0710 - val_loss: 0.0720\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0834 - val_loss: 0.0732\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0857 - val_loss: 0.0721\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0787 - val_loss: 0.0719\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0783 - val_loss: 0.0731\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0829 - val_loss: 0.0727\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0843 - val_loss: 0.0719\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0800 - val_loss: 0.0726\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0867 - val_loss: 0.0727\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0879 - val_loss: 0.0722\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0834 - val_loss: 0.0718\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0765 - val_loss: 0.0723\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0799 - val_loss: 0.0721\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0873 - val_loss: 0.0715\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0805 - val_loss: 0.0715\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0775 - val_loss: 0.0716\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0730 - val_loss: 0.0727\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0802 - val_loss: 0.0727\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0815 - val_loss: 0.0722\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0781 - val_loss: 0.0720\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0790 - val_loss: 0.0718\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0826 - val_loss: 0.0721\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0780 - val_loss: 0.0719\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0802 - val_loss: 0.0720\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0846 - val_loss: 0.0720\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0804 - val_loss: 0.0715\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0792 - val_loss: 0.0719\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0782 - val_loss: 0.0725\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0838 - val_loss: 0.0723\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0866 - val_loss: 0.0722\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0823 - val_loss: 0.0717\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0827 - val_loss: 0.0722\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0853 - val_loss: 0.0719\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0826 - val_loss: 0.0722\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0890 - val_loss: 0.0717\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0787 - val_loss: 0.0723\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0718 - val_loss: 0.0722\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0797 - val_loss: 0.0719\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0814 - val_loss: 0.0726\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0821 - val_loss: 0.0718\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0803 - val_loss: 0.0725\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0814 - val_loss: 0.0721\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0818 - val_loss: 0.0716\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0822 - val_loss: 0.0714\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0840 - val_loss: 0.0715\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0856 - val_loss: 0.0716\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0948 - val_loss: 0.0719\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0803 - val_loss: 0.0720\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0792 - val_loss: 0.0723\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0842 - val_loss: 0.0726\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0777 - val_loss: 0.0712\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0879 - val_loss: 0.0725\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0821 - val_loss: 0.0727\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0720 - val_loss: 0.0717\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0818 - val_loss: 0.0712\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0826 - val_loss: 0.0719\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0974 - val_loss: 0.0723\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0843 - val_loss: 0.0718\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0903 - val_loss: 0.0715\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0831 - val_loss: 0.0714\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 0.0741 - val_loss: 0.0720\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0869 - val_loss: 0.0721\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0882 - val_loss: 0.0712\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0843 - val_loss: 0.0715\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0910 - val_loss: 0.0718\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0837 - val_loss: 0.0727\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0823 - val_loss: 0.0718\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0814 - val_loss: 0.0728\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0812 - val_loss: 0.0724\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0780 - val_loss: 0.0724\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0854 - val_loss: 0.0713\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0907 - val_loss: 0.0720\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0815 - val_loss: 0.0712\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0851 - val_loss: 0.0727\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0833 - val_loss: 0.0728\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0817 - val_loss: 0.0715\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0817 - val_loss: 0.0720\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0780 - val_loss: 0.0724\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0814 - val_loss: 0.0720\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0848 - val_loss: 0.0721\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0709 - val_loss: 0.0720\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0837 - val_loss: 0.0718\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - loss: 42.2906 - val_loss: 0.4810\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 1.0085 - val_loss: 0.1115\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.2754 - val_loss: 0.0826\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1626 - val_loss: 0.0815\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1203 - val_loss: 0.0781\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0866 - val_loss: 0.0731\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0823 - val_loss: 0.0736\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0787 - val_loss: 0.0731\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0872 - val_loss: 0.0734\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0781 - val_loss: 0.0739\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0766 - val_loss: 0.0773\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0806 - val_loss: 0.0732\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0835 - val_loss: 0.0739\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0862 - val_loss: 0.0735\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0887 - val_loss: 0.0731\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0860 - val_loss: 0.0728\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0864 - val_loss: 0.0730\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0845 - val_loss: 0.0726\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.0933 - val_loss: 0.0725\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0854 - val_loss: 0.0723\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0790 - val_loss: 0.0727\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0739 - val_loss: 0.0735\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0787 - val_loss: 0.0730\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0920 - val_loss: 0.0731\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0758 - val_loss: 0.0729\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0801 - val_loss: 0.0734\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0773 - val_loss: 0.0729\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0795 - val_loss: 0.0721\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0773 - val_loss: 0.0724\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0873 - val_loss: 0.0725\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0774 - val_loss: 0.0723\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0867 - val_loss: 0.0737\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0901 - val_loss: 0.0725\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0806 - val_loss: 0.0724\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0797 - val_loss: 0.0725\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0727 - val_loss: 0.0726\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0795 - val_loss: 0.0724\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0832 - val_loss: 0.0724\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0853 - val_loss: 0.0728\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0847 - val_loss: 0.0721\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0787 - val_loss: 0.0725\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0779 - val_loss: 0.0724\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0749 - val_loss: 0.0729\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0868 - val_loss: 0.0729\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0780 - val_loss: 0.0737\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0807 - val_loss: 0.0723\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0820 - val_loss: 0.0723\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0755 - val_loss: 0.0722\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0901 - val_loss: 0.0721\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0866 - val_loss: 0.0720\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0978 - val_loss: 0.0722\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0845 - val_loss: 0.0723\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0803 - val_loss: 0.0732\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0869 - val_loss: 0.0726\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0847 - val_loss: 0.0733\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0877 - val_loss: 0.0725\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0825 - val_loss: 0.0720\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0829 - val_loss: 0.0733\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0896 - val_loss: 0.0723\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0812 - val_loss: 0.0720\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0777 - val_loss: 0.0719\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0839 - val_loss: 0.0726\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.0808 - val_loss: 0.0727\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0723 - val_loss: 0.0722\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0760 - val_loss: 0.0723\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0863 - val_loss: 0.0725\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0815 - val_loss: 0.0723\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0778 - val_loss: 0.0733\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0847 - val_loss: 0.0722\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0816 - val_loss: 0.0721\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0949 - val_loss: 0.0729\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0821 - val_loss: 0.0724\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0915 - val_loss: 0.0731\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0837 - val_loss: 0.0736\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0730 - val_loss: 0.0720\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0831 - val_loss: 0.0720\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0756 - val_loss: 0.0718\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0969 - val_loss: 0.0718\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0848 - val_loss: 0.0728\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0813 - val_loss: 0.0719\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0770 - val_loss: 0.0722\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0813 - val_loss: 0.0724\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0816 - val_loss: 0.0729\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0880 - val_loss: 0.0727\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0812 - val_loss: 0.0723\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0782 - val_loss: 0.0720\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0861 - val_loss: 0.0723\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0896 - val_loss: 0.0725\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0827 - val_loss: 0.0723\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0847 - val_loss: 0.0727\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0720 - val_loss: 0.0727\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0824 - val_loss: 0.0721\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0859 - val_loss: 0.0725\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0803 - val_loss: 0.0722\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0805 - val_loss: 0.0723\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0844 - val_loss: 0.0713\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0874 - val_loss: 0.0725\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0748 - val_loss: 0.0729\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0806 - val_loss: 0.0725\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0814 - val_loss: 0.0718\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0890 - val_loss: 0.0728\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0779 - val_loss: 0.0725\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0800 - val_loss: 0.0724\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0907 - val_loss: 0.0730\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0765 - val_loss: 0.0720\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0857 - val_loss: 0.0725\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0937 - val_loss: 0.0724\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0896 - val_loss: 0.0721\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0867 - val_loss: 0.0735\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0932 - val_loss: 0.0719\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0800 - val_loss: 0.0723\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0864 - val_loss: 0.0726\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0843 - val_loss: 0.0723\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0831 - val_loss: 0.0719\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0821 - val_loss: 0.0722\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0904 - val_loss: 0.0722\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0822 - val_loss: 0.0726\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0853 - val_loss: 0.0715\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0829 - val_loss: 0.0715\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0851 - val_loss: 0.0721\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0799 - val_loss: 0.0719\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0889 - val_loss: 0.0727\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0874 - val_loss: 0.0722\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0884 - val_loss: 0.0724\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0819 - val_loss: 0.0728\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0819 - val_loss: 0.0723\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0828 - val_loss: 0.0716\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0825 - val_loss: 0.0724\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0834 - val_loss: 0.0718\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0791 - val_loss: 0.0738\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0740 - val_loss: 0.0726\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0816 - val_loss: 0.0725\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0842 - val_loss: 0.0714\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0833 - val_loss: 0.0717\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0876 - val_loss: 0.0724\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0803 - val_loss: 0.0719\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0877 - val_loss: 0.0715\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0899 - val_loss: 0.0719\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0808 - val_loss: 0.0713\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0820 - val_loss: 0.0715\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0900 - val_loss: 0.0723\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0800 - val_loss: 0.0717\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0846 - val_loss: 0.0722\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0887 - val_loss: 0.0723\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0847 - val_loss: 0.0723\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0871 - val_loss: 0.0714\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0764 - val_loss: 0.0712\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0767 - val_loss: 0.0716\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0825 - val_loss: 0.0726\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - loss: 24.1983 - val_loss: 0.0955\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.5154 - val_loss: 0.0795\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.2312 - val_loss: 0.0787\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1504 - val_loss: 0.0746\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.1128 - val_loss: 0.0761\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0963 - val_loss: 0.0728\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0965 - val_loss: 0.0713\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 0.0855 - val_loss: 0.0715\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0870 - val_loss: 0.0722\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0863 - val_loss: 0.0720\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0809 - val_loss: 0.0716\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0769 - val_loss: 0.0708\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0753 - val_loss: 0.0733\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0760 - val_loss: 0.0721\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0846 - val_loss: 0.0723\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0789 - val_loss: 0.0725\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0907 - val_loss: 0.0723\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0919 - val_loss: 0.0726\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0821 - val_loss: 0.0729\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0831 - val_loss: 0.0733\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0819 - val_loss: 0.0723\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0755 - val_loss: 0.0734\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0739 - val_loss: 0.0728\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0853 - val_loss: 0.0724\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0726 - val_loss: 0.0729\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0849 - val_loss: 0.0729\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0911 - val_loss: 0.0720\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0871 - val_loss: 0.0725\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0791 - val_loss: 0.0721\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0777 - val_loss: 0.0724\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0736\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0745 - val_loss: 0.0743\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0763 - val_loss: 0.0732\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0867 - val_loss: 0.0725\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0814 - val_loss: 0.0717\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0814 - val_loss: 0.0723\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0830 - val_loss: 0.0719\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0850 - val_loss: 0.0727\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0752 - val_loss: 0.0729\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0722\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0867 - val_loss: 0.0734\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0799 - val_loss: 0.0729\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0814 - val_loss: 0.0726\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0827 - val_loss: 0.0735\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0744 - val_loss: 0.0731\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0818 - val_loss: 0.0721\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0825 - val_loss: 0.0717\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0853 - val_loss: 0.0732\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0851 - val_loss: 0.0721\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0830 - val_loss: 0.0728\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0787 - val_loss: 0.0716\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0817 - val_loss: 0.0725\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0768 - val_loss: 0.0716\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0750 - val_loss: 0.0722\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0810 - val_loss: 0.0727\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0843 - val_loss: 0.0721\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0729 - val_loss: 0.0732\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0866 - val_loss: 0.0732\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0856 - val_loss: 0.0723\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0874 - val_loss: 0.0740\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0861 - val_loss: 0.0724\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0931 - val_loss: 0.0719\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0846 - val_loss: 0.0720\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0785 - val_loss: 0.0720\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0898 - val_loss: 0.0727\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0924 - val_loss: 0.0726\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0787 - val_loss: 0.0722\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0778 - val_loss: 0.0728\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0799 - val_loss: 0.0721\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0752 - val_loss: 0.0717\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0731 - val_loss: 0.0730\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0849 - val_loss: 0.0731\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0745 - val_loss: 0.0722\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0947 - val_loss: 0.0734\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0779 - val_loss: 0.0722\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0839 - val_loss: 0.0731\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0847 - val_loss: 0.0718\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0935 - val_loss: 0.0717\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0718\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0829 - val_loss: 0.0723\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0808 - val_loss: 0.0736\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0854 - val_loss: 0.0736\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0775 - val_loss: 0.0735\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0754 - val_loss: 0.0730\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0747 - val_loss: 0.0732\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0815 - val_loss: 0.0723\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0826 - val_loss: 0.0738\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0886 - val_loss: 0.0726\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0825 - val_loss: 0.0720\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0874 - val_loss: 0.0725\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0816 - val_loss: 0.0710\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0823 - val_loss: 0.0734\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0772 - val_loss: 0.0729\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0823 - val_loss: 0.0722\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0824 - val_loss: 0.0727\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0793 - val_loss: 0.0728\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0859 - val_loss: 0.0731\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0868 - val_loss: 0.0720\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0817 - val_loss: 0.0730\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0936 - val_loss: 0.0721\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0862 - val_loss: 0.0731\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0809 - val_loss: 0.0734\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0725\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0824 - val_loss: 0.0720\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0785 - val_loss: 0.0730\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0894 - val_loss: 0.0725\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0843 - val_loss: 0.0724\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0872 - val_loss: 0.0722\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0840 - val_loss: 0.0722\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0824 - val_loss: 0.0737\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0811 - val_loss: 0.0728\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0773 - val_loss: 0.0733\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0908 - val_loss: 0.0725\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0820 - val_loss: 0.0727\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0827 - val_loss: 0.0729\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1847 - val_loss: 0.0752\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0914 - val_loss: 0.0724\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0837 - val_loss: 0.0721\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0818 - val_loss: 0.0744\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0884 - val_loss: 0.0737\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0878 - val_loss: 0.0732\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0827 - val_loss: 0.0722\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0725\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0721\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0737\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0726\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0809 - val_loss: 0.0731\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0752 - val_loss: 0.0729\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0850 - val_loss: 0.0724\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0721\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0722\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0806 - val_loss: 0.0722\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0722\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0892 - val_loss: 0.0721\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0808 - val_loss: 0.0720\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0883 - val_loss: 0.0721\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0850 - val_loss: 0.0722\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0869 - val_loss: 0.0721\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0819 - val_loss: 0.0721\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0850 - val_loss: 0.0719\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0757 - val_loss: 0.0725\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0722\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0835 - val_loss: 0.0722\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0822 - val_loss: 0.0721\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0873 - val_loss: 0.0724\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0835 - val_loss: 0.0724\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0798 - val_loss: 0.0723\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0812 - val_loss: 0.0723\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0814 - val_loss: 0.0717\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 24.2247 - val_loss: 0.1650\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3887 - val_loss: 0.0963\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1650 - val_loss: 0.0795\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1059 - val_loss: 0.0748\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0861 - val_loss: 0.0740\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0837 - val_loss: 0.0766\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0876 - val_loss: 0.0709\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0868 - val_loss: 0.0720\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0844 - val_loss: 0.0728\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0888 - val_loss: 0.0727\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0854 - val_loss: 0.0729\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0829 - val_loss: 0.0728\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0807 - val_loss: 0.0723\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0777 - val_loss: 0.0725\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0867 - val_loss: 0.0729\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0787 - val_loss: 0.0740\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0783 - val_loss: 0.0760\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0831 - val_loss: 0.0724\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0793 - val_loss: 0.0732\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0790 - val_loss: 0.0724\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0847 - val_loss: 0.0727\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0790 - val_loss: 0.0726\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0873 - val_loss: 0.0728\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0889 - val_loss: 0.0725\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0769 - val_loss: 0.0721\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0810 - val_loss: 0.0726\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0764 - val_loss: 0.0729\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0779 - val_loss: 0.0738\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0724 - val_loss: 0.0721\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0902 - val_loss: 0.0720\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0917 - val_loss: 0.0721\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0821 - val_loss: 0.0726\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0782 - val_loss: 0.0733\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0926 - val_loss: 0.0756\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0820 - val_loss: 0.0726\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0871 - val_loss: 0.0722\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0898 - val_loss: 0.0732\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0828 - val_loss: 0.0728\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0699 - val_loss: 0.0731\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0776 - val_loss: 0.0735\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0828 - val_loss: 0.0728\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0795 - val_loss: 0.0723\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0849 - val_loss: 0.0720\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0827 - val_loss: 0.0724\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0796 - val_loss: 0.0716\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0816 - val_loss: 0.0733\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0812 - val_loss: 0.0727\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0855 - val_loss: 0.0734\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0822 - val_loss: 0.0719\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0877 - val_loss: 0.0718\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0750 - val_loss: 0.0718\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0745 - val_loss: 0.0730\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0827 - val_loss: 0.0725\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0691 - val_loss: 0.0722\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0842 - val_loss: 0.0719\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0842 - val_loss: 0.0718\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0797 - val_loss: 0.0735\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0893 - val_loss: 0.0728\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0821 - val_loss: 0.0733\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0731 - val_loss: 0.0740\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0823 - val_loss: 0.0731\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0829 - val_loss: 0.0725\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0807 - val_loss: 0.0712\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0915 - val_loss: 0.0757\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0806 - val_loss: 0.0702\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0803 - val_loss: 0.0720\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0861 - val_loss: 0.0716\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0856 - val_loss: 0.0719\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0891 - val_loss: 0.0712\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0788 - val_loss: 0.0735\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0830 - val_loss: 0.0704\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0789 - val_loss: 0.0715\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0742 - val_loss: 0.0720\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0825 - val_loss: 0.0722\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0772 - val_loss: 0.0716\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0743 - val_loss: 0.0714\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0840 - val_loss: 0.0722\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0822 - val_loss: 0.0727\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0833 - val_loss: 0.0722\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0960 - val_loss: 0.0729\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1160 - val_loss: 0.0726\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0820 - val_loss: 0.0737\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0853 - val_loss: 0.0726\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0721 - val_loss: 0.0735\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0828 - val_loss: 0.0714\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0896 - val_loss: 0.0725\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0766 - val_loss: 0.0729\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0839 - val_loss: 0.0725\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0925 - val_loss: 0.0724\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0835 - val_loss: 0.0739\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0865 - val_loss: 0.0722\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0859 - val_loss: 0.0726\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0778 - val_loss: 0.0732\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0914 - val_loss: 0.0728\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0939 - val_loss: 0.0726\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0831 - val_loss: 0.0726\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0873 - val_loss: 0.0723\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0857 - val_loss: 0.0728\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0767 - val_loss: 0.0724\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0792 - val_loss: 0.0733\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0747 - val_loss: 0.0730\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0876 - val_loss: 0.0727\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0869 - val_loss: 0.0714\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0854 - val_loss: 0.0730\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0838 - val_loss: 0.0718\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0840 - val_loss: 0.0732\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0774 - val_loss: 0.0724\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0877 - val_loss: 0.0722\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0861 - val_loss: 0.0725\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0821 - val_loss: 0.0727\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0853 - val_loss: 0.0723\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0931 - val_loss: 0.0724\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0946 - val_loss: 0.0722\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0849 - val_loss: 0.0727\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0905 - val_loss: 0.0725\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0828 - val_loss: 0.0726\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0787 - val_loss: 0.0721\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0883 - val_loss: 0.0721\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0862 - val_loss: 0.0726\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0827 - val_loss: 0.0732\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0902 - val_loss: 0.0728\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0905 - val_loss: 0.0726\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0854 - val_loss: 0.0725\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0833 - val_loss: 0.0732\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0790 - val_loss: 0.0731\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0857 - val_loss: 0.0731\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0772 - val_loss: 0.0730\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0801 - val_loss: 0.0723\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0833 - val_loss: 0.0721\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0796 - val_loss: 0.0726\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0832 - val_loss: 0.0721\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0880 - val_loss: 0.0720\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0945 - val_loss: 0.0718\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0917 - val_loss: 0.0718\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0830 - val_loss: 0.0740\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0856 - val_loss: 0.0727\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0985 - val_loss: 0.0702\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0804 - val_loss: 0.0700\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0781 - val_loss: 0.0710\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0886 - val_loss: 0.0699\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0898 - val_loss: 0.0708\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0804 - val_loss: 0.0716\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0828 - val_loss: 0.0702\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0749 - val_loss: 0.0715\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0872 - val_loss: 0.0706\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0776 - val_loss: 0.0699\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0789 - val_loss: 0.0710\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0796 - val_loss: 0.0705\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0871 - val_loss: 0.0698\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Neuronas:      RMSE\n",
      "0         32  0.081530\n",
      "1         64  0.081644\n",
      "2        128  0.081917\n",
      "3        256  0.081685\n",
      "4        512  0.080570\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los RMSE calculados\n",
    "rmse_train_values = []\n",
    "rmse_test_values = []\n",
    "neurons_range = [32, 64, 128, 256, 512] \n",
    "for i in  neurons_range:\n",
    "    # Crear el modelo\n",
    "    model = Sequential()\n",
    "    # Capa de entrada\n",
    "    model.add(Dense(i, input_dim=X_train.shape[1], activation='relu'))\n",
    "    # Capa oculta\n",
    "    model.add(Dense(int(i/2), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(i/2), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(i/2), activation='relu'))\n",
    "    # Capa de salida (un solo valor para el coeficiente phi)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, epochs=150, batch_size=50, validation_data=(X_test, y_test))\n",
    "    # Realizar predicciones\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    # Asegrate de que ambos son vectores 1D\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_train.flatten()\n",
    "\n",
    "    if len(y_train.shape) > 1:\n",
    "        y_train = y_train.flatten()\n",
    "\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_test.flatten()\n",
    "\n",
    "    if len(y_test.shape) > 1:\n",
    "        y_test = y_test.flatten()\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    rmse_train_values.append(mse_train)\n",
    "    rmse_test_values.append(mse_test)\n",
    "# Graficar los resultados\n",
    "plt.plot(neurons_range, rmse_train_values, marker='o', color='b', label='Entrenamiento')\n",
    "plt.plot(neurons_range, rmse_test_values, marker='o', color='r', label='Prueba')\n",
    "plt.title('RMSE vs Nmero de Neuronas en la Capa Oculta')\n",
    "plt.xlabel('Nmero de Neuronas en la Capa Oculta')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(pd.DataFrame({\"Neuronas:\":neurons_range,\n",
    "                    \"RMSE\":rmse_test_values}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo con 512 en capa de entrada y 256 en las ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el `numero de epochs` para ver como cambia el Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - loss: 67.1247 - val_loss: 0.1779\n",
      "Epoch 2/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.6196 - val_loss: 0.0902\n",
      "Epoch 3/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.2784 - val_loss: 0.0786\n",
      "Epoch 4/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1330 - val_loss: 0.0753\n",
      "Epoch 5/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0945 - val_loss: 0.0744\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 38.9966 - val_loss: 0.2987\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.4922 - val_loss: 0.0877\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2387 - val_loss: 0.0843\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1285 - val_loss: 0.0752\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.1174 - val_loss: 0.0753\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0894 - val_loss: 0.0759\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0843 - val_loss: 0.0720\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0835 - val_loss: 0.0706\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0751 - val_loss: 0.0717\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0813 - val_loss: 0.0728\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 32.9475 - val_loss: 0.2628\n",
      "Epoch 2/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4471 - val_loss: 0.1085\n",
      "Epoch 3/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1992 - val_loss: 0.0811\n",
      "Epoch 4/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1223 - val_loss: 0.0746\n",
      "Epoch 5/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0944 - val_loss: 0.0732\n",
      "Epoch 6/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0792 - val_loss: 0.0719\n",
      "Epoch 7/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0829 - val_loss: 0.0715\n",
      "Epoch 8/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0829 - val_loss: 0.0739\n",
      "Epoch 9/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0787 - val_loss: 0.0720\n",
      "Epoch 10/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0873 - val_loss: 0.0710\n",
      "Epoch 11/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0887 - val_loss: 0.0712\n",
      "Epoch 12/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0825 - val_loss: 0.0735\n",
      "Epoch 13/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0781 - val_loss: 0.0702\n",
      "Epoch 14/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0888 - val_loss: 0.0704\n",
      "Epoch 15/15\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0825 - val_loss: 0.0721\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 54.8737 - val_loss: 0.1581\n",
      "Epoch 2/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.6180 - val_loss: 0.1258\n",
      "Epoch 3/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2906 - val_loss: 0.0830\n",
      "Epoch 4/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1393 - val_loss: 0.0762\n",
      "Epoch 5/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1037 - val_loss: 0.0730\n",
      "Epoch 6/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0839 - val_loss: 0.0715\n",
      "Epoch 7/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0766 - val_loss: 0.0713\n",
      "Epoch 8/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0831 - val_loss: 0.0712\n",
      "Epoch 9/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0936 - val_loss: 0.0717\n",
      "Epoch 10/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0794 - val_loss: 0.0738\n",
      "Epoch 11/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0729\n",
      "Epoch 12/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0816 - val_loss: 0.0763\n",
      "Epoch 13/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0790 - val_loss: 0.0764\n",
      "Epoch 14/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0878 - val_loss: 0.0727\n",
      "Epoch 15/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0801 - val_loss: 0.0742\n",
      "Epoch 16/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0851 - val_loss: 0.0729\n",
      "Epoch 17/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0804 - val_loss: 0.0723\n",
      "Epoch 18/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0742 - val_loss: 0.0728\n",
      "Epoch 19/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0803 - val_loss: 0.0737\n",
      "Epoch 20/20\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0913 - val_loss: 0.0726\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 42.5970 - val_loss: 0.1438\n",
      "Epoch 2/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5838 - val_loss: 0.0905\n",
      "Epoch 3/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2052 - val_loss: 0.0926\n",
      "Epoch 4/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1240 - val_loss: 0.0755\n",
      "Epoch 5/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1090 - val_loss: 0.0735\n",
      "Epoch 6/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0842 - val_loss: 0.0718\n",
      "Epoch 7/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0814 - val_loss: 0.0737\n",
      "Epoch 8/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0786 - val_loss: 0.0728\n",
      "Epoch 9/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0850 - val_loss: 0.0726\n",
      "Epoch 10/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0785 - val_loss: 0.0737\n",
      "Epoch 11/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0818 - val_loss: 0.0713\n",
      "Epoch 12/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0826 - val_loss: 0.0710\n",
      "Epoch 13/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0926 - val_loss: 0.0705\n",
      "Epoch 14/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0874 - val_loss: 0.0704\n",
      "Epoch 15/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0826 - val_loss: 0.0712\n",
      "Epoch 16/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0853 - val_loss: 0.0711\n",
      "Epoch 17/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0740 - val_loss: 0.0708\n",
      "Epoch 18/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0842 - val_loss: 0.0711\n",
      "Epoch 19/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0773 - val_loss: 0.0716\n",
      "Epoch 20/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0860 - val_loss: 0.0711\n",
      "Epoch 21/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0826 - val_loss: 0.0719\n",
      "Epoch 22/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0793 - val_loss: 0.0730\n",
      "Epoch 23/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0867 - val_loss: 0.0733\n",
      "Epoch 24/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0875 - val_loss: 0.0728\n",
      "Epoch 25/25\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0781 - val_loss: 0.0731\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 90.8803 - val_loss: 0.1432\n",
      "Epoch 2/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.7314 - val_loss: 0.0841\n",
      "Epoch 3/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.3833 - val_loss: 0.1106\n",
      "Epoch 4/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.2398 - val_loss: 0.0751\n",
      "Epoch 5/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1421 - val_loss: 0.0746\n",
      "Epoch 6/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0964 - val_loss: 0.0732\n",
      "Epoch 7/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0957 - val_loss: 0.0741\n",
      "Epoch 8/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0913 - val_loss: 0.0733\n",
      "Epoch 9/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0795 - val_loss: 0.0731\n",
      "Epoch 10/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0798 - val_loss: 0.0745\n",
      "Epoch 11/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0795 - val_loss: 0.0739\n",
      "Epoch 12/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0839 - val_loss: 0.0731\n",
      "Epoch 13/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0924 - val_loss: 0.0729\n",
      "Epoch 14/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0787 - val_loss: 0.0736\n",
      "Epoch 15/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0788 - val_loss: 0.0741\n",
      "Epoch 16/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0851 - val_loss: 0.0748\n",
      "Epoch 17/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0832 - val_loss: 0.0744\n",
      "Epoch 18/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0841 - val_loss: 0.0728\n",
      "Epoch 19/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0814 - val_loss: 0.0739\n",
      "Epoch 20/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0835 - val_loss: 0.0724\n",
      "Epoch 21/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0849 - val_loss: 0.0738\n",
      "Epoch 22/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0795 - val_loss: 0.0733\n",
      "Epoch 23/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0809 - val_loss: 0.0727\n",
      "Epoch 24/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0780 - val_loss: 0.0723\n",
      "Epoch 25/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0770 - val_loss: 0.0728\n",
      "Epoch 26/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0850 - val_loss: 0.0731\n",
      "Epoch 27/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0770 - val_loss: 0.0723\n",
      "Epoch 28/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0818 - val_loss: 0.0724\n",
      "Epoch 29/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0877 - val_loss: 0.0727\n",
      "Epoch 30/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0864 - val_loss: 0.0727\n",
      "Epoch 31/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0789 - val_loss: 0.0749\n",
      "Epoch 32/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0795 - val_loss: 0.0728\n",
      "Epoch 33/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0785 - val_loss: 0.0749\n",
      "Epoch 34/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0826 - val_loss: 0.0725\n",
      "Epoch 35/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0929 - val_loss: 0.0721\n",
      "Epoch 36/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0738 - val_loss: 0.0726\n",
      "Epoch 37/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0811 - val_loss: 0.0753\n",
      "Epoch 38/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0768 - val_loss: 0.0724\n",
      "Epoch 39/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0870 - val_loss: 0.0723\n",
      "Epoch 40/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0892 - val_loss: 0.0732\n",
      "Epoch 41/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0856 - val_loss: 0.0735\n",
      "Epoch 42/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0832 - val_loss: 0.0744\n",
      "Epoch 43/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0819 - val_loss: 0.0734\n",
      "Epoch 44/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0833 - val_loss: 0.0732\n",
      "Epoch 45/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0753 - val_loss: 0.0717\n",
      "Epoch 46/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0845 - val_loss: 0.0718\n",
      "Epoch 47/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0799 - val_loss: 0.0738\n",
      "Epoch 48/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0842 - val_loss: 0.0722\n",
      "Epoch 49/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0746 - val_loss: 0.0725\n",
      "Epoch 50/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0800 - val_loss: 0.0730\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 30.3025 - val_loss: 0.1624\n",
      "Epoch 2/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4316 - val_loss: 0.1074\n",
      "Epoch 3/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1968 - val_loss: 0.0888\n",
      "Epoch 4/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1373 - val_loss: 0.0743\n",
      "Epoch 5/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0957 - val_loss: 0.0742\n",
      "Epoch 6/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0971 - val_loss: 0.0715\n",
      "Epoch 7/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0903 - val_loss: 0.0712\n",
      "Epoch 8/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0892 - val_loss: 0.0717\n",
      "Epoch 9/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0881 - val_loss: 0.0703\n",
      "Epoch 10/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0911 - val_loss: 0.0704\n",
      "Epoch 11/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0853 - val_loss: 0.0701\n",
      "Epoch 12/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0828 - val_loss: 0.0706\n",
      "Epoch 13/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0883 - val_loss: 0.0706\n",
      "Epoch 14/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0772 - val_loss: 0.0712\n",
      "Epoch 15/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0785 - val_loss: 0.0711\n",
      "Epoch 16/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0825 - val_loss: 0.0703\n",
      "Epoch 17/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0818 - val_loss: 0.0705\n",
      "Epoch 18/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0780 - val_loss: 0.0728\n",
      "Epoch 19/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0843 - val_loss: 0.0704\n",
      "Epoch 20/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0779 - val_loss: 0.0707\n",
      "Epoch 21/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0773 - val_loss: 0.0702\n",
      "Epoch 22/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0711\n",
      "Epoch 23/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0805 - val_loss: 0.0759\n",
      "Epoch 24/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0808 - val_loss: 0.0705\n",
      "Epoch 25/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0832 - val_loss: 0.0717\n",
      "Epoch 26/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0782 - val_loss: 0.0704\n",
      "Epoch 27/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0723 - val_loss: 0.0732\n",
      "Epoch 28/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 29/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0775 - val_loss: 0.0728\n",
      "Epoch 30/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0923 - val_loss: 0.0743\n",
      "Epoch 31/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0805 - val_loss: 0.0721\n",
      "Epoch 32/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0710 - val_loss: 0.0729\n",
      "Epoch 33/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0905 - val_loss: 0.0732\n",
      "Epoch 34/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0819 - val_loss: 0.0738\n",
      "Epoch 35/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0793 - val_loss: 0.0728\n",
      "Epoch 36/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0792 - val_loss: 0.0727\n",
      "Epoch 37/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0818 - val_loss: 0.0728\n",
      "Epoch 38/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0814 - val_loss: 0.0728\n",
      "Epoch 39/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0791 - val_loss: 0.0724\n",
      "Epoch 40/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0795 - val_loss: 0.0723\n",
      "Epoch 41/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0863 - val_loss: 0.0721\n",
      "Epoch 42/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0881 - val_loss: 0.0726\n",
      "Epoch 43/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0823 - val_loss: 0.0718\n",
      "Epoch 44/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0839 - val_loss: 0.0731\n",
      "Epoch 45/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0775 - val_loss: 0.0726\n",
      "Epoch 46/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0811 - val_loss: 0.0732\n",
      "Epoch 47/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0819 - val_loss: 0.0727\n",
      "Epoch 48/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0816 - val_loss: 0.0743\n",
      "Epoch 49/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0792 - val_loss: 0.0727\n",
      "Epoch 50/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0830 - val_loss: 0.0727\n",
      "Epoch 51/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0904 - val_loss: 0.0728\n",
      "Epoch 52/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0841 - val_loss: 0.0732\n",
      "Epoch 53/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0722\n",
      "Epoch 54/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0725\n",
      "Epoch 55/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0800 - val_loss: 0.0728\n",
      "Epoch 56/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0722 - val_loss: 0.0732\n",
      "Epoch 57/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0774 - val_loss: 0.0723\n",
      "Epoch 58/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0852 - val_loss: 0.0730\n",
      "Epoch 59/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0935 - val_loss: 0.0726\n",
      "Epoch 60/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0869 - val_loss: 0.0737\n",
      "Epoch 61/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0874 - val_loss: 0.0738\n",
      "Epoch 62/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0798 - val_loss: 0.0723\n",
      "Epoch 63/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0865 - val_loss: 0.0730\n",
      "Epoch 64/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0781 - val_loss: 0.0726\n",
      "Epoch 65/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0821 - val_loss: 0.0721\n",
      "Epoch 66/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0809 - val_loss: 0.0727\n",
      "Epoch 67/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0776 - val_loss: 0.0720\n",
      "Epoch 68/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0843 - val_loss: 0.0725\n",
      "Epoch 69/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0846 - val_loss: 0.0722\n",
      "Epoch 70/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0814 - val_loss: 0.0728\n",
      "Epoch 71/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0829 - val_loss: 0.0719\n",
      "Epoch 72/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0941 - val_loss: 0.0724\n",
      "Epoch 73/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0775 - val_loss: 0.0730\n",
      "Epoch 74/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0919 - val_loss: 0.0731\n",
      "Epoch 75/75\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0967 - val_loss: 0.0722\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 43.1038 - val_loss: 0.3534\n",
      "Epoch 2/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.4288 - val_loss: 0.0920\n",
      "Epoch 3/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2304 - val_loss: 0.1008\n",
      "Epoch 4/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1500 - val_loss: 0.0779\n",
      "Epoch 5/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1187 - val_loss: 0.0772\n",
      "Epoch 6/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1005 - val_loss: 0.0745\n",
      "Epoch 7/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0900 - val_loss: 0.0720\n",
      "Epoch 8/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0811 - val_loss: 0.0721\n",
      "Epoch 9/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0764 - val_loss: 0.0722\n",
      "Epoch 10/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0810 - val_loss: 0.0704\n",
      "Epoch 11/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0820 - val_loss: 0.0721\n",
      "Epoch 12/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0819 - val_loss: 0.0705\n",
      "Epoch 13/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0816 - val_loss: 0.0711\n",
      "Epoch 14/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0833 - val_loss: 0.0733\n",
      "Epoch 15/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0909 - val_loss: 0.0728\n",
      "Epoch 16/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0884 - val_loss: 0.0726\n",
      "Epoch 17/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0814 - val_loss: 0.0724\n",
      "Epoch 18/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0810 - val_loss: 0.0756\n",
      "Epoch 19/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0785 - val_loss: 0.0734\n",
      "Epoch 20/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0864 - val_loss: 0.0724\n",
      "Epoch 21/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0806 - val_loss: 0.0720\n",
      "Epoch 22/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0859 - val_loss: 0.0717\n",
      "Epoch 23/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0798 - val_loss: 0.0719\n",
      "Epoch 24/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0950 - val_loss: 0.0719\n",
      "Epoch 25/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0807 - val_loss: 0.0723\n",
      "Epoch 26/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0783 - val_loss: 0.0723\n",
      "Epoch 27/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0797 - val_loss: 0.0716\n",
      "Epoch 28/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0816 - val_loss: 0.0727\n",
      "Epoch 29/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0823 - val_loss: 0.0732\n",
      "Epoch 30/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0882 - val_loss: 0.0733\n",
      "Epoch 31/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0868 - val_loss: 0.0726\n",
      "Epoch 32/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0877 - val_loss: 0.0725\n",
      "Epoch 33/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0896 - val_loss: 0.0730\n",
      "Epoch 34/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0728\n",
      "Epoch 35/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0771 - val_loss: 0.0719\n",
      "Epoch 36/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0880 - val_loss: 0.0724\n",
      "Epoch 37/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0794 - val_loss: 0.0723\n",
      "Epoch 38/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0722\n",
      "Epoch 39/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0806 - val_loss: 0.0733\n",
      "Epoch 40/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0946 - val_loss: 0.0728\n",
      "Epoch 41/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0813 - val_loss: 0.0722\n",
      "Epoch 42/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0888 - val_loss: 0.0724\n",
      "Epoch 43/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0968 - val_loss: 0.0722\n",
      "Epoch 44/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0870 - val_loss: 0.0722\n",
      "Epoch 45/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0762 - val_loss: 0.0731\n",
      "Epoch 46/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0824 - val_loss: 0.0720\n",
      "Epoch 47/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0818 - val_loss: 0.0721\n",
      "Epoch 48/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0882 - val_loss: 0.0726\n",
      "Epoch 49/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0767 - val_loss: 0.0732\n",
      "Epoch 50/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0768 - val_loss: 0.0724\n",
      "Epoch 51/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0834 - val_loss: 0.0724\n",
      "Epoch 52/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0844 - val_loss: 0.0726\n",
      "Epoch 53/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0764 - val_loss: 0.0723\n",
      "Epoch 54/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0810 - val_loss: 0.0721\n",
      "Epoch 55/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0798 - val_loss: 0.0738\n",
      "Epoch 56/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0797 - val_loss: 0.0717\n",
      "Epoch 57/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0886 - val_loss: 0.0722\n",
      "Epoch 58/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0730\n",
      "Epoch 59/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0910 - val_loss: 0.0724\n",
      "Epoch 60/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0851 - val_loss: 0.0726\n",
      "Epoch 61/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0790 - val_loss: 0.0733\n",
      "Epoch 62/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0769 - val_loss: 0.0734\n",
      "Epoch 63/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0776 - val_loss: 0.0728\n",
      "Epoch 64/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0839 - val_loss: 0.0726\n",
      "Epoch 65/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0776 - val_loss: 0.0721\n",
      "Epoch 66/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0799 - val_loss: 0.0727\n",
      "Epoch 67/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0800 - val_loss: 0.0726\n",
      "Epoch 68/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0726 - val_loss: 0.0722\n",
      "Epoch 69/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0815 - val_loss: 0.0734\n",
      "Epoch 70/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0821 - val_loss: 0.0723\n",
      "Epoch 71/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0820 - val_loss: 0.0747\n",
      "Epoch 72/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0871 - val_loss: 0.0723\n",
      "Epoch 73/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0819 - val_loss: 0.0768\n",
      "Epoch 74/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0861 - val_loss: 0.0732\n",
      "Epoch 75/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0726\n",
      "Epoch 76/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0790 - val_loss: 0.0735\n",
      "Epoch 77/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0831 - val_loss: 0.0728\n",
      "Epoch 78/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0821 - val_loss: 0.0720\n",
      "Epoch 79/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0884 - val_loss: 0.0730\n",
      "Epoch 80/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0866 - val_loss: 0.0735\n",
      "Epoch 81/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0789 - val_loss: 0.0727\n",
      "Epoch 82/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0744 - val_loss: 0.0731\n",
      "Epoch 83/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0925 - val_loss: 0.0734\n",
      "Epoch 84/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0727\n",
      "Epoch 85/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0816 - val_loss: 0.0728\n",
      "Epoch 86/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0825 - val_loss: 0.0730\n",
      "Epoch 87/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0796 - val_loss: 0.0720\n",
      "Epoch 88/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0752\n",
      "Epoch 89/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0879 - val_loss: 0.0727\n",
      "Epoch 90/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0850 - val_loss: 0.0745\n",
      "Epoch 91/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0789 - val_loss: 0.0727\n",
      "Epoch 92/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0883 - val_loss: 0.0727\n",
      "Epoch 93/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0843 - val_loss: 0.0744\n",
      "Epoch 94/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.9510 - val_loss: 0.0740\n",
      "Epoch 95/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0731\n",
      "Epoch 96/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0918 - val_loss: 0.0752\n",
      "Epoch 97/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0812 - val_loss: 0.0734\n",
      "Epoch 98/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0865 - val_loss: 0.0746\n",
      "Epoch 99/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0829 - val_loss: 0.0732\n",
      "Epoch 100/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0824 - val_loss: 0.0735\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 46.6864 - val_loss: 0.0950\n",
      "Epoch 2/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5499 - val_loss: 0.0873\n",
      "Epoch 3/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2471 - val_loss: 0.1005\n",
      "Epoch 4/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1275 - val_loss: 0.0760\n",
      "Epoch 5/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1022 - val_loss: 0.0739\n",
      "Epoch 6/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0967 - val_loss: 0.0726\n",
      "Epoch 7/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0831 - val_loss: 0.0742\n",
      "Epoch 8/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0870 - val_loss: 0.0731\n",
      "Epoch 9/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0805 - val_loss: 0.0707\n",
      "Epoch 10/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0796 - val_loss: 0.0716\n",
      "Epoch 11/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0829 - val_loss: 0.0716\n",
      "Epoch 12/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0825 - val_loss: 0.0703\n",
      "Epoch 13/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0810 - val_loss: 0.0708\n",
      "Epoch 14/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0797 - val_loss: 0.0712\n",
      "Epoch 15/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0879 - val_loss: 0.0709\n",
      "Epoch 16/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0831 - val_loss: 0.0710\n",
      "Epoch 17/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0876 - val_loss: 0.0710\n",
      "Epoch 18/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0865 - val_loss: 0.0716\n",
      "Epoch 19/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0767 - val_loss: 0.0706\n",
      "Epoch 20/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0779 - val_loss: 0.0710\n",
      "Epoch 21/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0834 - val_loss: 0.0708\n",
      "Epoch 22/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0873 - val_loss: 0.0711\n",
      "Epoch 23/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0792 - val_loss: 0.0713\n",
      "Epoch 24/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0825 - val_loss: 0.0714\n",
      "Epoch 25/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0835 - val_loss: 0.0733\n",
      "Epoch 26/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0823 - val_loss: 0.0728\n",
      "Epoch 27/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0841 - val_loss: 0.0734\n",
      "Epoch 28/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0825 - val_loss: 0.0741\n",
      "Epoch 29/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0820 - val_loss: 0.0724\n",
      "Epoch 30/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0796 - val_loss: 0.0726\n",
      "Epoch 31/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0783 - val_loss: 0.0724\n",
      "Epoch 32/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0822 - val_loss: 0.0730\n",
      "Epoch 33/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0786 - val_loss: 0.0727\n",
      "Epoch 34/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 35/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0868 - val_loss: 0.0746\n",
      "Epoch 36/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0870 - val_loss: 0.0752\n",
      "Epoch 37/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0807 - val_loss: 0.0743\n",
      "Epoch 38/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0826 - val_loss: 0.0743\n",
      "Epoch 39/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0964 - val_loss: 0.0727\n",
      "Epoch 40/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0891 - val_loss: 0.0724\n",
      "Epoch 41/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0826 - val_loss: 0.0728\n",
      "Epoch 42/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1006 - val_loss: 0.0722\n",
      "Epoch 43/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0732\n",
      "Epoch 44/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0764 - val_loss: 0.0739\n",
      "Epoch 45/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0763 - val_loss: 0.0732\n",
      "Epoch 46/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0891 - val_loss: 0.0741\n",
      "Epoch 47/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0868 - val_loss: 0.0728\n",
      "Epoch 48/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0750 - val_loss: 0.0734\n",
      "Epoch 49/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0941 - val_loss: 0.0726\n",
      "Epoch 50/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0937 - val_loss: 0.0725\n",
      "Epoch 51/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0827 - val_loss: 0.0727\n",
      "Epoch 52/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0857 - val_loss: 0.0736\n",
      "Epoch 53/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0785 - val_loss: 0.0724\n",
      "Epoch 54/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0869 - val_loss: 0.0730\n",
      "Epoch 55/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0819 - val_loss: 0.0730\n",
      "Epoch 56/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0775 - val_loss: 0.0731\n",
      "Epoch 57/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0881 - val_loss: 0.0731\n",
      "Epoch 58/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0907 - val_loss: 0.0726\n",
      "Epoch 59/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0795 - val_loss: 0.0721\n",
      "Epoch 60/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0926 - val_loss: 0.0723\n",
      "Epoch 61/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0804 - val_loss: 0.0731\n",
      "Epoch 62/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0757 - val_loss: 0.0736\n",
      "Epoch 63/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0895 - val_loss: 0.0728\n",
      "Epoch 64/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0866 - val_loss: 0.0743\n",
      "Epoch 65/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0913 - val_loss: 0.0724\n",
      "Epoch 66/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0960 - val_loss: 0.0725\n",
      "Epoch 67/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0845 - val_loss: 0.0730\n",
      "Epoch 68/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0811 - val_loss: 0.0714\n",
      "Epoch 69/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0843 - val_loss: 0.0727\n",
      "Epoch 70/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0789 - val_loss: 0.0728\n",
      "Epoch 71/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0803 - val_loss: 0.0742\n",
      "Epoch 72/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0787 - val_loss: 0.0728\n",
      "Epoch 73/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0813 - val_loss: 0.0732\n",
      "Epoch 74/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0814 - val_loss: 0.0732\n",
      "Epoch 75/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0755 - val_loss: 0.0729\n",
      "Epoch 76/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0808 - val_loss: 0.0724\n",
      "Epoch 77/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0725 - val_loss: 0.0743\n",
      "Epoch 78/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0772 - val_loss: 0.0731\n",
      "Epoch 79/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0822 - val_loss: 0.0734\n",
      "Epoch 80/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0731\n",
      "Epoch 81/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0797 - val_loss: 0.0742\n",
      "Epoch 82/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0825 - val_loss: 0.0722\n",
      "Epoch 83/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0890 - val_loss: 0.0731\n",
      "Epoch 84/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0873 - val_loss: 0.0767\n",
      "Epoch 85/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0727\n",
      "Epoch 86/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0882 - val_loss: 0.0735\n",
      "Epoch 87/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0818 - val_loss: 0.0742\n",
      "Epoch 88/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0842 - val_loss: 0.0728\n",
      "Epoch 89/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0816 - val_loss: 0.0727\n",
      "Epoch 90/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0804 - val_loss: 0.0726\n",
      "Epoch 91/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0921 - val_loss: 0.0727\n",
      "Epoch 92/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0797 - val_loss: 0.0754\n",
      "Epoch 93/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0853 - val_loss: 0.0744\n",
      "Epoch 94/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0762 - val_loss: 0.0743\n",
      "Epoch 95/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0894 - val_loss: 0.0743\n",
      "Epoch 96/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0824 - val_loss: 0.0743\n",
      "Epoch 97/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0782 - val_loss: 0.0781\n",
      "Epoch 98/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0885 - val_loss: 0.0727\n",
      "Epoch 99/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0899 - val_loss: 0.0739\n",
      "Epoch 100/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0788 - val_loss: 0.0730\n",
      "Epoch 101/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0722 - val_loss: 0.0760\n",
      "Epoch 102/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0880 - val_loss: 0.0732\n",
      "Epoch 103/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0885 - val_loss: 0.0740\n",
      "Epoch 104/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0830 - val_loss: 0.0737\n",
      "Epoch 105/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0918 - val_loss: 0.0744\n",
      "Epoch 106/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0962 - val_loss: 0.0749\n",
      "Epoch 107/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5966 - val_loss: 0.0743\n",
      "Epoch 108/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0843 - val_loss: 0.0740\n",
      "Epoch 109/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0862 - val_loss: 0.0733\n",
      "Epoch 110/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0723 - val_loss: 0.0728\n",
      "Epoch 111/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0803 - val_loss: 0.0734\n",
      "Epoch 112/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0921 - val_loss: 0.0731\n",
      "Epoch 113/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0903 - val_loss: 0.0733\n",
      "Epoch 114/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0988 - val_loss: 0.0731\n",
      "Epoch 115/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0885 - val_loss: 0.0732\n",
      "Epoch 116/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0815 - val_loss: 0.0727\n",
      "Epoch 117/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0870 - val_loss: 0.0729\n",
      "Epoch 118/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0919 - val_loss: 0.0729\n",
      "Epoch 119/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0828 - val_loss: 0.0735\n",
      "Epoch 120/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0887 - val_loss: 0.0734\n",
      "Epoch 121/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0827 - val_loss: 0.0718\n",
      "Epoch 122/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0746 - val_loss: 0.0738\n",
      "Epoch 123/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0843 - val_loss: 0.0733\n",
      "Epoch 124/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0856 - val_loss: 0.0723\n",
      "Epoch 125/125\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0807 - val_loss: 0.0729\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 25.8752 - val_loss: 0.1154\n",
      "Epoch 2/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3786 - val_loss: 0.0854\n",
      "Epoch 3/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2006 - val_loss: 0.0806\n",
      "Epoch 4/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1138 - val_loss: 0.0754\n",
      "Epoch 5/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0997 - val_loss: 0.0782\n",
      "Epoch 6/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0915 - val_loss: 0.0713\n",
      "Epoch 7/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0886 - val_loss: 0.0737\n",
      "Epoch 8/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0742 - val_loss: 0.0717\n",
      "Epoch 9/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0788 - val_loss: 0.0716\n",
      "Epoch 10/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0853 - val_loss: 0.0711\n",
      "Epoch 11/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0795 - val_loss: 0.0709\n",
      "Epoch 12/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0833 - val_loss: 0.0705\n",
      "Epoch 13/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0707\n",
      "Epoch 14/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0708\n",
      "Epoch 15/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0860 - val_loss: 0.0704\n",
      "Epoch 16/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0816 - val_loss: 0.0738\n",
      "Epoch 17/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0896 - val_loss: 0.0727\n",
      "Epoch 18/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0737\n",
      "Epoch 19/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0849 - val_loss: 0.0727\n",
      "Epoch 20/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0842 - val_loss: 0.0727\n",
      "Epoch 21/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0767 - val_loss: 0.0722\n",
      "Epoch 22/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0892 - val_loss: 0.0729\n",
      "Epoch 23/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0829 - val_loss: 0.0723\n",
      "Epoch 24/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0853 - val_loss: 0.0733\n",
      "Epoch 25/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0780 - val_loss: 0.0733\n",
      "Epoch 26/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0870 - val_loss: 0.0729\n",
      "Epoch 27/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0851 - val_loss: 0.0731\n",
      "Epoch 28/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0889 - val_loss: 0.0736\n",
      "Epoch 29/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0800 - val_loss: 0.0734\n",
      "Epoch 30/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0812 - val_loss: 0.0782\n",
      "Epoch 31/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0811 - val_loss: 0.0725\n",
      "Epoch 32/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0775 - val_loss: 0.0727\n",
      "Epoch 33/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0917 - val_loss: 0.0722\n",
      "Epoch 34/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0845 - val_loss: 0.0725\n",
      "Epoch 35/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0862 - val_loss: 0.0722\n",
      "Epoch 36/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0853 - val_loss: 0.0723\n",
      "Epoch 37/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0797 - val_loss: 0.0733\n",
      "Epoch 38/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0856 - val_loss: 0.0722\n",
      "Epoch 39/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0873 - val_loss: 0.0724\n",
      "Epoch 40/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0775 - val_loss: 0.0733\n",
      "Epoch 41/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0808 - val_loss: 0.0738\n",
      "Epoch 42/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0789 - val_loss: 0.0730\n",
      "Epoch 43/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0870 - val_loss: 0.0730\n",
      "Epoch 44/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0754 - val_loss: 0.0725\n",
      "Epoch 45/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0832 - val_loss: 0.0727\n",
      "Epoch 46/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0879 - val_loss: 0.0737\n",
      "Epoch 47/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0885 - val_loss: 0.0728\n",
      "Epoch 48/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0730\n",
      "Epoch 49/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0863 - val_loss: 0.0765\n",
      "Epoch 50/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0785 - val_loss: 0.0742\n",
      "Epoch 51/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0784 - val_loss: 0.0733\n",
      "Epoch 52/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0800 - val_loss: 0.0728\n",
      "Epoch 53/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0812 - val_loss: 0.0720\n",
      "Epoch 54/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0836 - val_loss: 0.0725\n",
      "Epoch 55/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0781 - val_loss: 0.0727\n",
      "Epoch 56/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0726\n",
      "Epoch 57/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0802 - val_loss: 0.0728\n",
      "Epoch 58/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0868 - val_loss: 0.0738\n",
      "Epoch 59/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0855 - val_loss: 0.0726\n",
      "Epoch 60/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0782 - val_loss: 0.0713\n",
      "Epoch 61/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0821 - val_loss: 0.0723\n",
      "Epoch 62/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0799 - val_loss: 0.0731\n",
      "Epoch 63/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0910 - val_loss: 0.0734\n",
      "Epoch 64/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0850 - val_loss: 0.0726\n",
      "Epoch 65/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0787 - val_loss: 0.0727\n",
      "Epoch 66/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0862 - val_loss: 0.0716\n",
      "Epoch 67/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0816 - val_loss: 0.0721\n",
      "Epoch 68/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0800 - val_loss: 0.0724\n",
      "Epoch 69/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0928 - val_loss: 0.0723\n",
      "Epoch 70/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0799 - val_loss: 0.0730\n",
      "Epoch 71/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0837 - val_loss: 0.0727\n",
      "Epoch 72/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0775 - val_loss: 0.0727\n",
      "Epoch 73/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0867 - val_loss: 0.0732\n",
      "Epoch 74/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0903 - val_loss: 0.0721\n",
      "Epoch 75/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0917 - val_loss: 0.0723\n",
      "Epoch 76/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0918 - val_loss: 0.0758\n",
      "Epoch 77/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0825 - val_loss: 0.0735\n",
      "Epoch 78/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.1146 - val_loss: 0.5580\n",
      "Epoch 79/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1784 - val_loss: 0.0736\n",
      "Epoch 80/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0768 - val_loss: 0.0728\n",
      "Epoch 81/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2919 - val_loss: 0.0729\n",
      "Epoch 82/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0883 - val_loss: 0.0728\n",
      "Epoch 83/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0805 - val_loss: 0.0724\n",
      "Epoch 84/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0824 - val_loss: 0.0729\n",
      "Epoch 85/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0871 - val_loss: 0.0715\n",
      "Epoch 86/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0856 - val_loss: 0.0728\n",
      "Epoch 87/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0885 - val_loss: 0.0719\n",
      "Epoch 88/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0937 - val_loss: 0.0732\n",
      "Epoch 89/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0885 - val_loss: 0.0735\n",
      "Epoch 90/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0859 - val_loss: 0.0745\n",
      "Epoch 91/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0865 - val_loss: 0.0744\n",
      "Epoch 92/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0884 - val_loss: 0.0744\n",
      "Epoch 93/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0845 - val_loss: 0.0743\n",
      "Epoch 94/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0822 - val_loss: 0.0739\n",
      "Epoch 95/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0905 - val_loss: 0.0736\n",
      "Epoch 96/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0819 - val_loss: 0.0744\n",
      "Epoch 97/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0903 - val_loss: 0.0729\n",
      "Epoch 98/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0743 - val_loss: 0.0729\n",
      "Epoch 99/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0822 - val_loss: 0.0727\n",
      "Epoch 100/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0826 - val_loss: 0.0728\n",
      "Epoch 101/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0725\n",
      "Epoch 102/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0829 - val_loss: 0.0731\n",
      "Epoch 103/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 104/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0884 - val_loss: 0.0730\n",
      "Epoch 105/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0832 - val_loss: 0.0719\n",
      "Epoch 106/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0721\n",
      "Epoch 107/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0808 - val_loss: 0.0731\n",
      "Epoch 108/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0835 - val_loss: 0.0728\n",
      "Epoch 109/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0859 - val_loss: 0.0721\n",
      "Epoch 110/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0828 - val_loss: 0.0723\n",
      "Epoch 111/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0943 - val_loss: 0.0728\n",
      "Epoch 112/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0799 - val_loss: 0.0722\n",
      "Epoch 113/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0789 - val_loss: 0.0734\n",
      "Epoch 114/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0901 - val_loss: 0.0723\n",
      "Epoch 115/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0847 - val_loss: 0.0728\n",
      "Epoch 116/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0825 - val_loss: 0.0726\n",
      "Epoch 117/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0843 - val_loss: 0.0723\n",
      "Epoch 118/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0902 - val_loss: 0.0719\n",
      "Epoch 119/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0811 - val_loss: 0.0730\n",
      "Epoch 120/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0822 - val_loss: 0.0728\n",
      "Epoch 121/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0767 - val_loss: 0.0730\n",
      "Epoch 122/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0811 - val_loss: 0.0721\n",
      "Epoch 123/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0725\n",
      "Epoch 124/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0838 - val_loss: 0.0721\n",
      "Epoch 125/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0866 - val_loss: 0.0723\n",
      "Epoch 126/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0714\n",
      "Epoch 127/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0783 - val_loss: 0.0735\n",
      "Epoch 128/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0784 - val_loss: 0.0734\n",
      "Epoch 129/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0831 - val_loss: 0.0734\n",
      "Epoch 130/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0870 - val_loss: 0.0724\n",
      "Epoch 131/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0842 - val_loss: 0.0728\n",
      "Epoch 132/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0796 - val_loss: 0.0731\n",
      "Epoch 133/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0909 - val_loss: 0.0735\n",
      "Epoch 134/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0794 - val_loss: 0.0735\n",
      "Epoch 135/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0743 - val_loss: 0.0736\n",
      "Epoch 136/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0844 - val_loss: 0.0728\n",
      "Epoch 137/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0879 - val_loss: 0.0730\n",
      "Epoch 138/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0892 - val_loss: 0.0727\n",
      "Epoch 139/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0863 - val_loss: 0.0726\n",
      "Epoch 140/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0722\n",
      "Epoch 141/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0924 - val_loss: 0.0723\n",
      "Epoch 142/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0881 - val_loss: 0.0727\n",
      "Epoch 143/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0886 - val_loss: 0.0715\n",
      "Epoch 144/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0790 - val_loss: 0.0734\n",
      "Epoch 145/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0785 - val_loss: 0.0728\n",
      "Epoch 146/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0838 - val_loss: 0.0732\n",
      "Epoch 147/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0763 - val_loss: 0.0722\n",
      "Epoch 148/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0997 - val_loss: 0.0724\n",
      "Epoch 149/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0887 - val_loss: 0.0726\n",
      "Epoch 150/150\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0803 - val_loss: 0.0724\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Epoch 1/175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 36.6833 - val_loss: 0.0874\n",
      "Epoch 2/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4179 - val_loss: 0.0824\n",
      "Epoch 3/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1720 - val_loss: 0.0754\n",
      "Epoch 4/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1145 - val_loss: 0.0746\n",
      "Epoch 5/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0930 - val_loss: 0.0724\n",
      "Epoch 6/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0814 - val_loss: 0.0717\n",
      "Epoch 7/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0859 - val_loss: 0.0740\n",
      "Epoch 8/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0909 - val_loss: 0.0715\n",
      "Epoch 9/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0814 - val_loss: 0.0709\n",
      "Epoch 10/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0786 - val_loss: 0.0755\n",
      "Epoch 11/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0863 - val_loss: 0.0737\n",
      "Epoch 12/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0835 - val_loss: 0.0726\n",
      "Epoch 13/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0730\n",
      "Epoch 14/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0812 - val_loss: 0.0726\n",
      "Epoch 15/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0855 - val_loss: 0.0727\n",
      "Epoch 16/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0755 - val_loss: 0.0726\n",
      "Epoch 17/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0773 - val_loss: 0.0721\n",
      "Epoch 18/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0736\n",
      "Epoch 19/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0983 - val_loss: 0.0722\n",
      "Epoch 20/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0894 - val_loss: 0.0726\n",
      "Epoch 21/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0810 - val_loss: 0.0725\n",
      "Epoch 22/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0854 - val_loss: 0.0722\n",
      "Epoch 23/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0806 - val_loss: 0.0726\n",
      "Epoch 24/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0749 - val_loss: 0.0721\n",
      "Epoch 25/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0838 - val_loss: 0.0719\n",
      "Epoch 26/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0764 - val_loss: 0.0721\n",
      "Epoch 27/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0810 - val_loss: 0.0723\n",
      "Epoch 28/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0866 - val_loss: 0.0719\n",
      "Epoch 29/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0850 - val_loss: 0.0724\n",
      "Epoch 30/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0793 - val_loss: 0.0722\n",
      "Epoch 31/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0860 - val_loss: 0.0735\n",
      "Epoch 32/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0847 - val_loss: 0.0705\n",
      "Epoch 33/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0880 - val_loss: 0.0706\n",
      "Epoch 34/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0838 - val_loss: 0.0723\n",
      "Epoch 35/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0815 - val_loss: 0.0720\n",
      "Epoch 36/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0843 - val_loss: 0.0722\n",
      "Epoch 37/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0777 - val_loss: 0.0730\n",
      "Epoch 38/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0826 - val_loss: 0.0728\n",
      "Epoch 39/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0923 - val_loss: 0.0747\n",
      "Epoch 40/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0808 - val_loss: 0.0729\n",
      "Epoch 41/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0769 - val_loss: 0.0725\n",
      "Epoch 42/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0731\n",
      "Epoch 43/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0780 - val_loss: 0.0734\n",
      "Epoch 44/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0823 - val_loss: 0.0733\n",
      "Epoch 45/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0823 - val_loss: 0.0721\n",
      "Epoch 46/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0802 - val_loss: 0.0737\n",
      "Epoch 47/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0899 - val_loss: 0.0720\n",
      "Epoch 48/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0841 - val_loss: 0.0726\n",
      "Epoch 49/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0805 - val_loss: 0.0716\n",
      "Epoch 50/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0791 - val_loss: 0.0720\n",
      "Epoch 51/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0849 - val_loss: 0.0727\n",
      "Epoch 52/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0825 - val_loss: 0.0722\n",
      "Epoch 53/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0911 - val_loss: 0.0729\n",
      "Epoch 54/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0823 - val_loss: 0.0733\n",
      "Epoch 55/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0822 - val_loss: 0.0725\n",
      "Epoch 56/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0829 - val_loss: 0.0720\n",
      "Epoch 57/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0848 - val_loss: 0.0729\n",
      "Epoch 58/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0859 - val_loss: 0.0726\n",
      "Epoch 59/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0850 - val_loss: 0.0721\n",
      "Epoch 60/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0789 - val_loss: 0.0719\n",
      "Epoch 61/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0810 - val_loss: 0.0734\n",
      "Epoch 62/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0862 - val_loss: 0.0714\n",
      "Epoch 63/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0777 - val_loss: 0.0724\n",
      "Epoch 64/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0868 - val_loss: 0.0719\n",
      "Epoch 65/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0799 - val_loss: 0.1059\n",
      "Epoch 66/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5039 - val_loss: 0.0736\n",
      "Epoch 67/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0825 - val_loss: 0.0728\n",
      "Epoch 68/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0762 - val_loss: 0.0729\n",
      "Epoch 69/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0962 - val_loss: 0.0737\n",
      "Epoch 70/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0727\n",
      "Epoch 71/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0883 - val_loss: 0.0722\n",
      "Epoch 72/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0769 - val_loss: 0.0729\n",
      "Epoch 73/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0850 - val_loss: 0.0717\n",
      "Epoch 74/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0776 - val_loss: 0.0717\n",
      "Epoch 75/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0881 - val_loss: 0.0743\n",
      "Epoch 76/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0877 - val_loss: 0.0722\n",
      "Epoch 77/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0900 - val_loss: 0.0720\n",
      "Epoch 78/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0805 - val_loss: 0.0728\n",
      "Epoch 79/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0721 - val_loss: 0.0725\n",
      "Epoch 80/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0868 - val_loss: 0.0718\n",
      "Epoch 81/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0796 - val_loss: 0.0720\n",
      "Epoch 82/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0780 - val_loss: 0.0719\n",
      "Epoch 83/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0774 - val_loss: 0.0731\n",
      "Epoch 84/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0810 - val_loss: 0.0726\n",
      "Epoch 85/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0798 - val_loss: 0.0715\n",
      "Epoch 86/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0797 - val_loss: 0.0725\n",
      "Epoch 87/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0799 - val_loss: 0.0720\n",
      "Epoch 88/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0829 - val_loss: 0.0727\n",
      "Epoch 89/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0803 - val_loss: 0.0735\n",
      "Epoch 90/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0857 - val_loss: 0.0720\n",
      "Epoch 91/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0726 - val_loss: 0.0736\n",
      "Epoch 92/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0786 - val_loss: 0.0719\n",
      "Epoch 93/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0795 - val_loss: 0.0729\n",
      "Epoch 94/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0719\n",
      "Epoch 95/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0797 - val_loss: 0.0726\n",
      "Epoch 96/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0942 - val_loss: 0.0731\n",
      "Epoch 97/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0803 - val_loss: 0.0719\n",
      "Epoch 98/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0888 - val_loss: 0.0718\n",
      "Epoch 99/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0811 - val_loss: 0.0732\n",
      "Epoch 100/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0714 - val_loss: 0.0748\n",
      "Epoch 101/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0853 - val_loss: 0.0719\n",
      "Epoch 102/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0860 - val_loss: 0.0726\n",
      "Epoch 103/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0858 - val_loss: 0.0720\n",
      "Epoch 104/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0860 - val_loss: 0.0726\n",
      "Epoch 105/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0937 - val_loss: 0.0731\n",
      "Epoch 106/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0812 - val_loss: 0.0730\n",
      "Epoch 107/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0819 - val_loss: 0.0720\n",
      "Epoch 108/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0841 - val_loss: 0.0723\n",
      "Epoch 109/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0869 - val_loss: 0.0728\n",
      "Epoch 110/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0856 - val_loss: 0.0724\n",
      "Epoch 111/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0824 - val_loss: 0.0726\n",
      "Epoch 112/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0747 - val_loss: 0.0724\n",
      "Epoch 113/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0807 - val_loss: 0.0744\n",
      "Epoch 114/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0811 - val_loss: 0.0730\n",
      "Epoch 115/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0809 - val_loss: 0.0723\n",
      "Epoch 116/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0810 - val_loss: 0.0719\n",
      "Epoch 117/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0791 - val_loss: 0.0722\n",
      "Epoch 118/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0865 - val_loss: 0.0726\n",
      "Epoch 119/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0773 - val_loss: 0.0726\n",
      "Epoch 120/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0842 - val_loss: 0.0731\n",
      "Epoch 121/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0856 - val_loss: 0.0725\n",
      "Epoch 122/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0879 - val_loss: 0.0725\n",
      "Epoch 123/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0903 - val_loss: 0.0723\n",
      "Epoch 124/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0798 - val_loss: 0.2083\n",
      "Epoch 125/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1090 - val_loss: 0.0735\n",
      "Epoch 126/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1014 - val_loss: 0.0734\n",
      "Epoch 127/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0843 - val_loss: 0.0724\n",
      "Epoch 128/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0694 - val_loss: 0.0731\n",
      "Epoch 129/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0841 - val_loss: 0.0727\n",
      "Epoch 130/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0838 - val_loss: 0.0733\n",
      "Epoch 131/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0785 - val_loss: 0.0737\n",
      "Epoch 132/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0987 - val_loss: 0.0730\n",
      "Epoch 133/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0862 - val_loss: 0.0728\n",
      "Epoch 134/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0896 - val_loss: 0.0724\n",
      "Epoch 135/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0840 - val_loss: 0.0729\n",
      "Epoch 136/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0752 - val_loss: 0.0728\n",
      "Epoch 137/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0791 - val_loss: 0.0728\n",
      "Epoch 138/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0791 - val_loss: 0.0724\n",
      "Epoch 139/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0802 - val_loss: 0.0720\n",
      "Epoch 140/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0775 - val_loss: 0.0726\n",
      "Epoch 141/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0888 - val_loss: 0.0728\n",
      "Epoch 142/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0897 - val_loss: 0.0723\n",
      "Epoch 143/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0823 - val_loss: 0.0725\n",
      "Epoch 144/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0780 - val_loss: 0.0724\n",
      "Epoch 145/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0877 - val_loss: 0.0727\n",
      "Epoch 146/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1850 - val_loss: 0.0725\n",
      "Epoch 147/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0846 - val_loss: 0.0728\n",
      "Epoch 148/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0738\n",
      "Epoch 149/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0854 - val_loss: 0.0721\n",
      "Epoch 150/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0790 - val_loss: 0.0729\n",
      "Epoch 151/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0802 - val_loss: 0.0724\n",
      "Epoch 152/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0818 - val_loss: 0.0728\n",
      "Epoch 153/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0815 - val_loss: 0.0727\n",
      "Epoch 154/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0789 - val_loss: 0.0721\n",
      "Epoch 155/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0869 - val_loss: 0.0718\n",
      "Epoch 156/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0770 - val_loss: 0.0725\n",
      "Epoch 157/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0801 - val_loss: 0.0724\n",
      "Epoch 158/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0802 - val_loss: 0.0728\n",
      "Epoch 159/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0821 - val_loss: 0.0728\n",
      "Epoch 160/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0907 - val_loss: 0.0726\n",
      "Epoch 161/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0871 - val_loss: 0.0729\n",
      "Epoch 162/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0830 - val_loss: 0.0725\n",
      "Epoch 163/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0849 - val_loss: 0.0727\n",
      "Epoch 164/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0963 - val_loss: 0.0729\n",
      "Epoch 165/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0800 - val_loss: 0.0728\n",
      "Epoch 166/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0873 - val_loss: 0.0730\n",
      "Epoch 167/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0818 - val_loss: 0.0743\n",
      "Epoch 168/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0847 - val_loss: 0.0729\n",
      "Epoch 169/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0792 - val_loss: 0.0731\n",
      "Epoch 170/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0774 - val_loss: 0.0732\n",
      "Epoch 171/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0872 - val_loss: 0.0722\n",
      "Epoch 172/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0739 - val_loss: 0.0722\n",
      "Epoch 173/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0783 - val_loss: 0.0727\n",
      "Epoch 174/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0832 - val_loss: 0.0724\n",
      "Epoch 175/175\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0818 - val_loss: 0.0729\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 27.0702 - val_loss: 0.1094\n",
      "Epoch 2/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4960 - val_loss: 0.0919\n",
      "Epoch 3/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2048 - val_loss: 0.0871\n",
      "Epoch 4/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1177 - val_loss: 0.0823\n",
      "Epoch 5/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0927 - val_loss: 0.0734\n",
      "Epoch 6/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0723\n",
      "Epoch 7/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0885 - val_loss: 0.0722\n",
      "Epoch 8/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0772 - val_loss: 0.0710\n",
      "Epoch 9/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0840 - val_loss: 0.0718\n",
      "Epoch 10/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0826 - val_loss: 0.0711\n",
      "Epoch 11/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0715\n",
      "Epoch 12/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0916 - val_loss: 0.0720\n",
      "Epoch 13/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0761 - val_loss: 0.0725\n",
      "Epoch 14/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0884 - val_loss: 0.0723\n",
      "Epoch 15/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0914 - val_loss: 0.0722\n",
      "Epoch 16/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0828 - val_loss: 0.0704\n",
      "Epoch 17/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0839 - val_loss: 0.0726\n",
      "Epoch 18/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0728 - val_loss: 0.0731\n",
      "Epoch 19/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0804 - val_loss: 0.0720\n",
      "Epoch 20/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0881 - val_loss: 0.0720\n",
      "Epoch 21/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0864 - val_loss: 0.0731\n",
      "Epoch 22/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0969 - val_loss: 0.0724\n",
      "Epoch 23/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0956 - val_loss: 0.0724\n",
      "Epoch 24/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0837 - val_loss: 0.0730\n",
      "Epoch 25/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0802 - val_loss: 0.0723\n",
      "Epoch 26/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0846 - val_loss: 0.0719\n",
      "Epoch 27/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0824 - val_loss: 0.0734\n",
      "Epoch 28/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0805 - val_loss: 0.0726\n",
      "Epoch 29/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0785 - val_loss: 0.0725\n",
      "Epoch 30/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0859 - val_loss: 0.0728\n",
      "Epoch 31/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0811 - val_loss: 0.0728\n",
      "Epoch 32/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0806 - val_loss: 0.0730\n",
      "Epoch 33/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0844 - val_loss: 0.0722\n",
      "Epoch 34/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0804 - val_loss: 0.0728\n",
      "Epoch 35/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0761 - val_loss: 0.0718\n",
      "Epoch 36/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0719\n",
      "Epoch 37/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0871 - val_loss: 0.0723\n",
      "Epoch 38/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0746 - val_loss: 0.0735\n",
      "Epoch 39/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0887 - val_loss: 0.0728\n",
      "Epoch 40/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0824 - val_loss: 0.0733\n",
      "Epoch 41/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0837 - val_loss: 0.0717\n",
      "Epoch 42/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0750 - val_loss: 0.0724\n",
      "Epoch 43/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0818 - val_loss: 0.0730\n",
      "Epoch 44/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0879 - val_loss: 0.0725\n",
      "Epoch 45/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0788 - val_loss: 0.0726\n",
      "Epoch 46/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0801 - val_loss: 0.0723\n",
      "Epoch 47/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0724 - val_loss: 0.0738\n",
      "Epoch 48/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0846 - val_loss: 0.0726\n",
      "Epoch 49/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0878 - val_loss: 0.0719\n",
      "Epoch 50/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0799 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0861 - val_loss: 0.0728\n",
      "Epoch 52/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0813 - val_loss: 0.0724\n",
      "Epoch 53/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0767 - val_loss: 0.0715\n",
      "Epoch 54/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0752 - val_loss: 0.0726\n",
      "Epoch 55/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0779 - val_loss: 0.0726\n",
      "Epoch 56/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0822 - val_loss: 0.0739\n",
      "Epoch 57/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0800 - val_loss: 0.0728\n",
      "Epoch 58/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0759 - val_loss: 0.0722\n",
      "Epoch 59/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0872 - val_loss: 0.0729\n",
      "Epoch 60/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0835 - val_loss: 0.0725\n",
      "Epoch 61/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0860 - val_loss: 0.0730\n",
      "Epoch 62/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0789 - val_loss: 0.0729\n",
      "Epoch 63/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0889 - val_loss: 0.0723\n",
      "Epoch 64/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0775 - val_loss: 0.0725\n",
      "Epoch 65/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0814 - val_loss: 0.0727\n",
      "Epoch 66/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0798 - val_loss: 0.0722\n",
      "Epoch 67/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0836 - val_loss: 0.0729\n",
      "Epoch 68/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0731\n",
      "Epoch 69/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0912 - val_loss: 0.0725\n",
      "Epoch 70/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0832 - val_loss: 0.0721\n",
      "Epoch 71/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0884 - val_loss: 0.0720\n",
      "Epoch 72/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0840 - val_loss: 0.0719\n",
      "Epoch 73/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0923 - val_loss: 0.0721\n",
      "Epoch 74/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0817 - val_loss: 0.0717\n",
      "Epoch 75/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0765 - val_loss: 0.0727\n",
      "Epoch 76/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0899 - val_loss: 0.0722\n",
      "Epoch 77/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0776 - val_loss: 0.0740\n",
      "Epoch 78/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0837 - val_loss: 0.0734\n",
      "Epoch 79/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0883 - val_loss: 0.0721\n",
      "Epoch 80/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0946 - val_loss: 0.0726\n",
      "Epoch 81/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0835 - val_loss: 0.0719\n",
      "Epoch 82/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0773 - val_loss: 0.0727\n",
      "Epoch 83/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0876 - val_loss: 0.0713\n",
      "Epoch 84/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0781 - val_loss: 0.0733\n",
      "Epoch 85/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0776 - val_loss: 0.0745\n",
      "Epoch 86/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0844 - val_loss: 0.0723\n",
      "Epoch 87/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0891 - val_loss: 0.0724\n",
      "Epoch 88/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0712 - val_loss: 0.0724\n",
      "Epoch 89/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0880 - val_loss: 0.0729\n",
      "Epoch 90/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0835 - val_loss: 0.0727\n",
      "Epoch 91/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0743 - val_loss: 0.0725\n",
      "Epoch 92/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0902 - val_loss: 0.0740\n",
      "Epoch 93/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0796 - val_loss: 0.0708\n",
      "Epoch 94/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0924 - val_loss: 0.0722\n",
      "Epoch 95/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0771 - val_loss: 0.0733\n",
      "Epoch 96/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0785 - val_loss: 0.0736\n",
      "Epoch 97/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0757 - val_loss: 0.0730\n",
      "Epoch 98/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0863 - val_loss: 0.0739\n",
      "Epoch 99/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0800 - val_loss: 0.0731\n",
      "Epoch 100/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.2986 - val_loss: 0.0808\n",
      "Epoch 101/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0866 - val_loss: 0.0729\n",
      "Epoch 102/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0828 - val_loss: 0.0722\n",
      "Epoch 103/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0759 - val_loss: 0.0722\n",
      "Epoch 104/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0743 - val_loss: 0.0722\n",
      "Epoch 105/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0861 - val_loss: 0.0728\n",
      "Epoch 106/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0826 - val_loss: 0.0734\n",
      "Epoch 107/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0938 - val_loss: 0.0717\n",
      "Epoch 108/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0810 - val_loss: 0.0713\n",
      "Epoch 109/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0878 - val_loss: 0.0731\n",
      "Epoch 110/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0757 - val_loss: 0.0721\n",
      "Epoch 111/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0844 - val_loss: 0.0719\n",
      "Epoch 112/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0795 - val_loss: 0.0720\n",
      "Epoch 113/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0835 - val_loss: 0.0712\n",
      "Epoch 114/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0857 - val_loss: 0.0715\n",
      "Epoch 115/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0859 - val_loss: 0.0718\n",
      "Epoch 116/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0882 - val_loss: 0.0720\n",
      "Epoch 117/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0856 - val_loss: 0.0718\n",
      "Epoch 118/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0840 - val_loss: 0.0725\n",
      "Epoch 119/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0794 - val_loss: 0.0718\n",
      "Epoch 120/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0811 - val_loss: 0.0721\n",
      "Epoch 121/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0896 - val_loss: 0.0721\n",
      "Epoch 122/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 123/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0873 - val_loss: 0.0726\n",
      "Epoch 124/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0783 - val_loss: 0.0728\n",
      "Epoch 125/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0811 - val_loss: 0.0722\n",
      "Epoch 126/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0778 - val_loss: 0.0724\n",
      "Epoch 127/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0813 - val_loss: 0.0723\n",
      "Epoch 128/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0848 - val_loss: 0.0726\n",
      "Epoch 129/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0803 - val_loss: 0.0721\n",
      "Epoch 130/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0793 - val_loss: 0.0721\n",
      "Epoch 131/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0793 - val_loss: 0.0718\n",
      "Epoch 132/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0803 - val_loss: 0.0707\n",
      "Epoch 133/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0879 - val_loss: 0.0723\n",
      "Epoch 134/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0899 - val_loss: 0.0727\n",
      "Epoch 135/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0834 - val_loss: 0.0727\n",
      "Epoch 136/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0952 - val_loss: 0.0726\n",
      "Epoch 137/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0862 - val_loss: 0.0716\n",
      "Epoch 138/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0869 - val_loss: 0.0716\n",
      "Epoch 139/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0784 - val_loss: 0.0720\n",
      "Epoch 140/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0837 - val_loss: 0.0734\n",
      "Epoch 141/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0851 - val_loss: 0.0718\n",
      "Epoch 142/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0818 - val_loss: 0.0725\n",
      "Epoch 143/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0821 - val_loss: 0.0716\n",
      "Epoch 144/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0807 - val_loss: 0.0725\n",
      "Epoch 145/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0796 - val_loss: 0.0731\n",
      "Epoch 146/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0777 - val_loss: 0.0724\n",
      "Epoch 147/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0811 - val_loss: 0.0720\n",
      "Epoch 148/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0970 - val_loss: 0.0722\n",
      "Epoch 149/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0848 - val_loss: 0.0701\n",
      "Epoch 150/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0756 - val_loss: 0.0705\n",
      "Epoch 151/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0872 - val_loss: 0.0701\n",
      "Epoch 152/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0856 - val_loss: 0.0703\n",
      "Epoch 153/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0748 - val_loss: 0.0705\n",
      "Epoch 154/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0764 - val_loss: 0.0700\n",
      "Epoch 155/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0767 - val_loss: 0.0699\n",
      "Epoch 156/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0824 - val_loss: 0.0705\n",
      "Epoch 157/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0807 - val_loss: 0.0716\n",
      "Epoch 158/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0778 - val_loss: 0.0699\n",
      "Epoch 159/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0844 - val_loss: 0.0703\n",
      "Epoch 160/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0787 - val_loss: 0.0709\n",
      "Epoch 161/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0723 - val_loss: 0.0712\n",
      "Epoch 162/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0763 - val_loss: 0.0710\n",
      "Epoch 163/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0802 - val_loss: 0.0712\n",
      "Epoch 164/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0826 - val_loss: 0.0722\n",
      "Epoch 165/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0786 - val_loss: 0.0717\n",
      "Epoch 166/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0773 - val_loss: 0.0704\n",
      "Epoch 167/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0783 - val_loss: 0.0715\n",
      "Epoch 168/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0796 - val_loss: 0.0701\n",
      "Epoch 169/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0800 - val_loss: 0.0705\n",
      "Epoch 170/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0705\n",
      "Epoch 171/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0881 - val_loss: 0.0699\n",
      "Epoch 172/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0832 - val_loss: 0.0706\n",
      "Epoch 173/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0783 - val_loss: 0.0704\n",
      "Epoch 174/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0778 - val_loss: 0.0706\n",
      "Epoch 175/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 176/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0846 - val_loss: 0.0708\n",
      "Epoch 177/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0873 - val_loss: 0.0704\n",
      "Epoch 178/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0806 - val_loss: 0.0701\n",
      "Epoch 179/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0748 - val_loss: 0.0698\n",
      "Epoch 180/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0956 - val_loss: 0.0708\n",
      "Epoch 181/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0791 - val_loss: 0.0726\n",
      "Epoch 182/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0709\n",
      "Epoch 183/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0844 - val_loss: 0.0697\n",
      "Epoch 184/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0862 - val_loss: 0.0698\n",
      "Epoch 185/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0827 - val_loss: 0.0701\n",
      "Epoch 186/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0786 - val_loss: 0.0706\n",
      "Epoch 187/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0782 - val_loss: 0.0707\n",
      "Epoch 188/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0767 - val_loss: 0.0708\n",
      "Epoch 189/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0708\n",
      "Epoch 190/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0862 - val_loss: 0.0703\n",
      "Epoch 191/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0852 - val_loss: 0.0705\n",
      "Epoch 192/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0784 - val_loss: 0.0700\n",
      "Epoch 193/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0699\n",
      "Epoch 194/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0834 - val_loss: 0.0700\n",
      "Epoch 195/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0902 - val_loss: 0.0700\n",
      "Epoch 196/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0773 - val_loss: 0.0705\n",
      "Epoch 197/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0848 - val_loss: 0.0704\n",
      "Epoch 198/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0859 - val_loss: 0.0705\n",
      "Epoch 199/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0814 - val_loss: 0.0706\n",
      "Epoch 200/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0816 - val_loss: 0.0706\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nmero de etapas:      RMSE\n",
      "0                   5  0.074379\n",
      "1                  10  0.072756\n",
      "2                  15  0.072116\n",
      "3                  20  0.072552\n",
      "4                  25  0.073122\n",
      "5                  50  0.073040\n",
      "6                  75  0.072238\n",
      "7                 100  0.073543\n",
      "8                 125  0.072864\n",
      "9                 150  0.072382\n",
      "10                175  0.072888\n",
      "11                200  0.070599\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los RMSE calculados\n",
    "rmse_train_values = []\n",
    "rmse_test_values = []\n",
    "nuemero_etapas = [5,10,15,20,25, 50, 75, 100, 125, 150, 175,200] \n",
    "for i in  nuemero_etapas:\n",
    "    # Crear el modelo\n",
    "    model = Sequential()\n",
    "    # Capa de entrada\n",
    "    model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "    # Capa oculta\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    # Capa de salida (un solo valor para el coeficiente phi)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, epochs=i, batch_size=50, validation_data=(X_test, y_test))\n",
    "    # Realizar predicciones\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    # Asegrate de que ambos son vectores 1D\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_train.flatten()\n",
    "\n",
    "    if len(y_train.shape) > 1:\n",
    "        y_train = y_train.flatten()\n",
    "\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_test.flatten()\n",
    "\n",
    "    if len(y_test.shape) > 1:\n",
    "        y_test = y_test.flatten()\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    rmse_train_values.append(mse_train)\n",
    "    rmse_test_values.append(mse_test)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.plot(nuemero_etapas, rmse_train_values, marker='o', color='b', label='Entrenamiento')\n",
    "plt.plot(nuemero_etapas, rmse_test_values, marker='o', color='r', label='Prueba')\n",
    "plt.title('RMSE vs nmero de etapas')\n",
    "plt.xlabel('Nmero de nmero de etapas')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(pd.DataFrame({\"nmero de etapas:\":nuemero_etapas,\n",
    "                    \"RMSE\":rmse_test_values}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo con 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el `batch_size` para ver como cambia el Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 20.7440 - val_loss: 0.0814\n",
      "Epoch 2/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0964 - val_loss: 0.0734\n",
      "Epoch 3/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0983 - val_loss: 0.0747\n",
      "Epoch 4/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0734\n",
      "Epoch 5/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0733 - val_loss: 0.0730\n",
      "Epoch 6/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0774 - val_loss: 0.0746\n",
      "Epoch 7/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0748\n",
      "Epoch 8/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0939 - val_loss: 0.0753\n",
      "Epoch 9/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0756\n",
      "Epoch 10/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0851 - val_loss: 0.0750\n",
      "Epoch 11/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0918 - val_loss: 0.0747\n",
      "Epoch 12/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.0748\n",
      "Epoch 13/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0896 - val_loss: 0.0748\n",
      "Epoch 14/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0922 - val_loss: 0.0760\n",
      "Epoch 15/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0851 - val_loss: 0.0748\n",
      "Epoch 16/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0747\n",
      "Epoch 17/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.1249 - val_loss: 0.0751\n",
      "Epoch 18/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0780 - val_loss: 0.0754\n",
      "Epoch 19/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0848 - val_loss: 0.0749\n",
      "Epoch 20/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0886 - val_loss: 0.0747\n",
      "Epoch 21/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0794 - val_loss: 0.0747\n",
      "Epoch 22/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0742 - val_loss: 0.0751\n",
      "Epoch 23/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0790 - val_loss: 0.0748\n",
      "Epoch 24/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0982 - val_loss: 0.0749\n",
      "Epoch 25/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0813 - val_loss: 0.0747\n",
      "Epoch 26/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.0751\n",
      "Epoch 27/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0853 - val_loss: 0.0748\n",
      "Epoch 28/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0862 - val_loss: 0.0748\n",
      "Epoch 29/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0842 - val_loss: 0.0748\n",
      "Epoch 30/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0920 - val_loss: 0.0747\n",
      "Epoch 31/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0880 - val_loss: 0.0747\n",
      "Epoch 32/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0904 - val_loss: 0.0747\n",
      "Epoch 33/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.0747\n",
      "Epoch 34/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0860 - val_loss: 0.0747\n",
      "Epoch 35/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0747\n",
      "Epoch 36/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0848 - val_loss: 0.0747\n",
      "Epoch 37/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0736 - val_loss: 0.0749\n",
      "Epoch 38/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0822 - val_loss: 0.0747\n",
      "Epoch 39/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0855 - val_loss: 0.0747\n",
      "Epoch 40/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0830 - val_loss: 0.0747\n",
      "Epoch 41/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 0.0748\n",
      "Epoch 42/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0849 - val_loss: 0.0755\n",
      "Epoch 43/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0874 - val_loss: 0.0747\n",
      "Epoch 44/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0844 - val_loss: 0.0747\n",
      "Epoch 45/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 0.0764\n",
      "Epoch 46/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0749\n",
      "Epoch 47/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.0747\n",
      "Epoch 48/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0827 - val_loss: 0.0747\n",
      "Epoch 49/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0982 - val_loss: 0.0747\n",
      "Epoch 50/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0812 - val_loss: 0.0747\n",
      "Epoch 51/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0861 - val_loss: 0.0748\n",
      "Epoch 52/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0823 - val_loss: 0.0747\n",
      "Epoch 53/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.0747\n",
      "Epoch 54/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0934 - val_loss: 0.0747\n",
      "Epoch 55/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0939 - val_loss: 0.0748\n",
      "Epoch 56/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0886 - val_loss: 0.0747\n",
      "Epoch 57/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0860 - val_loss: 0.0748\n",
      "Epoch 58/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0747\n",
      "Epoch 59/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0826 - val_loss: 0.0747\n",
      "Epoch 60/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0747\n",
      "Epoch 61/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0892 - val_loss: 0.0747\n",
      "Epoch 62/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0880 - val_loss: 0.0747\n",
      "Epoch 63/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0900 - val_loss: 0.0747\n",
      "Epoch 64/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0747\n",
      "Epoch 65/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0977 - val_loss: 0.0748\n",
      "Epoch 66/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0930 - val_loss: 0.0747\n",
      "Epoch 67/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.0747\n",
      "Epoch 68/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0747\n",
      "Epoch 69/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0749\n",
      "Epoch 70/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0749\n",
      "Epoch 71/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0747\n",
      "Epoch 72/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0748\n",
      "Epoch 73/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0960 - val_loss: 0.0748\n",
      "Epoch 74/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0747\n",
      "Epoch 75/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: 0.0747\n",
      "Epoch 76/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0751\n",
      "Epoch 77/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.0748\n",
      "Epoch 78/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0747\n",
      "Epoch 79/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0747\n",
      "Epoch 80/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0818 - val_loss: 0.0747\n",
      "Epoch 81/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0876 - val_loss: 0.0747\n",
      "Epoch 82/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0747\n",
      "Epoch 83/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0870 - val_loss: 0.0747\n",
      "Epoch 84/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0941 - val_loss: 0.0747\n",
      "Epoch 85/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0747\n",
      "Epoch 86/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0750\n",
      "Epoch 87/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0915 - val_loss: 0.0747\n",
      "Epoch 88/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0982 - val_loss: 0.0747\n",
      "Epoch 89/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0818 - val_loss: 0.0747\n",
      "Epoch 90/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0908 - val_loss: 0.0747\n",
      "Epoch 91/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0749\n",
      "Epoch 92/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0747\n",
      "Epoch 93/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0872 - val_loss: 0.0747\n",
      "Epoch 94/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0865 - val_loss: 0.0747\n",
      "Epoch 95/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0906 - val_loss: 0.0749\n",
      "Epoch 96/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.0747\n",
      "Epoch 97/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0749\n",
      "Epoch 98/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.0747\n",
      "Epoch 99/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0839 - val_loss: 0.0747\n",
      "Epoch 100/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0747\n",
      "Epoch 101/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0898 - val_loss: 0.0747\n",
      "Epoch 102/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0831 - val_loss: 0.0747\n",
      "Epoch 103/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.0749\n",
      "Epoch 104/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0906 - val_loss: 0.0748\n",
      "Epoch 105/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0748\n",
      "Epoch 106/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0850 - val_loss: 0.0747\n",
      "Epoch 107/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0877 - val_loss: 0.0747\n",
      "Epoch 108/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0798 - val_loss: 0.0747\n",
      "Epoch 109/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0747\n",
      "Epoch 110/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0889 - val_loss: 0.0747\n",
      "Epoch 111/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0747\n",
      "Epoch 112/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0748\n",
      "Epoch 113/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0884 - val_loss: 0.0747\n",
      "Epoch 114/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.0747\n",
      "Epoch 115/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0747\n",
      "Epoch 116/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0747\n",
      "Epoch 117/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0895 - val_loss: 0.0747\n",
      "Epoch 118/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0747\n",
      "Epoch 119/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0747\n",
      "Epoch 120/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0900 - val_loss: 0.0747\n",
      "Epoch 121/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0914 - val_loss: 0.0747\n",
      "Epoch 122/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0749\n",
      "Epoch 123/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0748\n",
      "Epoch 124/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0747\n",
      "Epoch 125/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0884 - val_loss: 0.0748\n",
      "Epoch 126/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0747\n",
      "Epoch 127/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0751\n",
      "Epoch 128/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0747\n",
      "Epoch 129/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0747\n",
      "Epoch 130/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0748\n",
      "Epoch 131/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0954 - val_loss: 0.0747\n",
      "Epoch 132/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0748\n",
      "Epoch 133/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0747\n",
      "Epoch 134/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0882 - val_loss: 0.0747\n",
      "Epoch 135/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0747\n",
      "Epoch 136/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0854 - val_loss: 0.0750\n",
      "Epoch 137/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0836 - val_loss: 0.0747\n",
      "Epoch 138/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0836 - val_loss: 0.0747\n",
      "Epoch 139/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0868 - val_loss: 0.0747\n",
      "Epoch 140/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0748\n",
      "Epoch 141/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0818 - val_loss: 0.0747\n",
      "Epoch 142/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0774 - val_loss: 0.0750\n",
      "Epoch 143/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0885 - val_loss: 0.0747\n",
      "Epoch 144/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0874 - val_loss: 0.0747\n",
      "Epoch 145/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: 0.0747\n",
      "Epoch 146/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0975 - val_loss: 0.0748\n",
      "Epoch 147/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0845 - val_loss: 0.0747\n",
      "Epoch 148/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0899 - val_loss: 0.0748\n",
      "Epoch 149/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0759 - val_loss: 0.0748\n",
      "Epoch 150/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0875 - val_loss: 0.0747\n",
      "Epoch 151/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0925 - val_loss: 0.0747\n",
      "Epoch 152/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0963 - val_loss: 0.0748\n",
      "Epoch 153/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0894 - val_loss: 0.0747\n",
      "Epoch 154/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0850 - val_loss: 0.0747\n",
      "Epoch 155/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.1001 - val_loss: 0.0747\n",
      "Epoch 156/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0747\n",
      "Epoch 157/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0790 - val_loss: 0.0747\n",
      "Epoch 158/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0884 - val_loss: 0.0748\n",
      "Epoch 159/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0844 - val_loss: 0.0749\n",
      "Epoch 160/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0917 - val_loss: 0.0748\n",
      "Epoch 161/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0869 - val_loss: 0.0747\n",
      "Epoch 162/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0896 - val_loss: 0.0748\n",
      "Epoch 163/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0772 - val_loss: 0.0747\n",
      "Epoch 164/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0869 - val_loss: 0.0747\n",
      "Epoch 165/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0875 - val_loss: 0.0747\n",
      "Epoch 166/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0954 - val_loss: 0.0747\n",
      "Epoch 167/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0797 - val_loss: 0.0748\n",
      "Epoch 168/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0864 - val_loss: 0.0747\n",
      "Epoch 169/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0776 - val_loss: 0.0747\n",
      "Epoch 170/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0748\n",
      "Epoch 171/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.0747\n",
      "Epoch 172/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.0747\n",
      "Epoch 173/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0852 - val_loss: 0.0747\n",
      "Epoch 174/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0767 - val_loss: 0.0747\n",
      "Epoch 175/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0939 - val_loss: 0.0747\n",
      "Epoch 176/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0862 - val_loss: 0.0747\n",
      "Epoch 177/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0890 - val_loss: 0.0748\n",
      "Epoch 178/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0931 - val_loss: 0.0747\n",
      "Epoch 179/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0943 - val_loss: 0.0747\n",
      "Epoch 180/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0887 - val_loss: 0.0747\n",
      "Epoch 181/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0851 - val_loss: 0.0747\n",
      "Epoch 182/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0853 - val_loss: 0.0748\n",
      "Epoch 183/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0785 - val_loss: 0.0747\n",
      "Epoch 184/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0805 - val_loss: 0.0747\n",
      "Epoch 185/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0841 - val_loss: 0.0747\n",
      "Epoch 186/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0850 - val_loss: 0.0750\n",
      "Epoch 187/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0747\n",
      "Epoch 188/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0747\n",
      "Epoch 189/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0763 - val_loss: 0.0749\n",
      "Epoch 190/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0747\n",
      "Epoch 191/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0881 - val_loss: 0.0747\n",
      "Epoch 192/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0747\n",
      "Epoch 193/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0750\n",
      "Epoch 194/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0747\n",
      "Epoch 195/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0747\n",
      "Epoch 196/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0747\n",
      "Epoch 197/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0896 - val_loss: 0.0747\n",
      "Epoch 198/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0747\n",
      "Epoch 199/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0944 - val_loss: 0.0750\n",
      "Epoch 200/200\n",
      "\u001b[1m949/949\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0850 - val_loss: 0.0748\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 17.1269 - val_loss: 0.0773\n",
      "Epoch 2/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1415 - val_loss: 0.0715\n",
      "Epoch 3/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0941 - val_loss: 0.0726\n",
      "Epoch 4/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0733 - val_loss: 0.0746\n",
      "Epoch 5/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0858 - val_loss: 0.0729\n",
      "Epoch 6/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0851 - val_loss: 0.0727\n",
      "Epoch 7/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0825 - val_loss: 0.0733\n",
      "Epoch 8/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0870 - val_loss: 0.0730\n",
      "Epoch 9/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0736\n",
      "Epoch 10/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0851 - val_loss: 0.0733\n",
      "Epoch 11/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0861 - val_loss: 0.0744\n",
      "Epoch 12/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0736\n",
      "Epoch 13/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0848 - val_loss: 0.0745\n",
      "Epoch 14/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0836 - val_loss: 0.0747\n",
      "Epoch 15/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0923 - val_loss: 0.0728\n",
      "Epoch 16/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0891 - val_loss: 0.0742\n",
      "Epoch 17/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0791 - val_loss: 0.0744\n",
      "Epoch 18/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0837 - val_loss: 0.0733\n",
      "Epoch 19/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0740\n",
      "Epoch 20/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0744 - val_loss: 0.0740\n",
      "Epoch 21/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0730\n",
      "Epoch 22/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0836 - val_loss: 0.0745\n",
      "Epoch 23/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0767 - val_loss: 0.0751\n",
      "Epoch 24/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0820 - val_loss: 0.0746\n",
      "Epoch 25/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0839 - val_loss: 0.0756\n",
      "Epoch 26/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0806 - val_loss: 0.0743\n",
      "Epoch 27/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0817 - val_loss: 0.0740\n",
      "Epoch 28/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0756 - val_loss: 0.0743\n",
      "Epoch 29/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0743\n",
      "Epoch 30/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0771 - val_loss: 0.0752\n",
      "Epoch 31/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0741\n",
      "Epoch 32/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0878 - val_loss: 0.0729\n",
      "Epoch 33/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0914 - val_loss: 0.0744\n",
      "Epoch 34/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0902 - val_loss: 0.0730\n",
      "Epoch 35/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0925 - val_loss: 0.0732\n",
      "Epoch 36/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0730\n",
      "Epoch 37/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0779 - val_loss: 0.0737\n",
      "Epoch 38/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0727\n",
      "Epoch 39/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0878 - val_loss: 0.0738\n",
      "Epoch 40/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0994 - val_loss: 0.0735\n",
      "Epoch 41/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0819 - val_loss: 0.0749\n",
      "Epoch 42/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1246 - val_loss: 0.0734\n",
      "Epoch 43/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0836 - val_loss: 0.0726\n",
      "Epoch 44/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0721\n",
      "Epoch 45/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0736\n",
      "Epoch 46/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0728\n",
      "Epoch 47/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0735\n",
      "Epoch 48/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0838 - val_loss: 0.0725\n",
      "Epoch 49/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0734\n",
      "Epoch 50/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0729\n",
      "Epoch 51/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0765 - val_loss: 0.0732\n",
      "Epoch 52/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0882 - val_loss: 0.0730\n",
      "Epoch 53/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0734\n",
      "Epoch 54/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0937 - val_loss: 0.0728\n",
      "Epoch 55/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0816 - val_loss: 0.0731\n",
      "Epoch 56/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0795 - val_loss: 0.0732\n",
      "Epoch 57/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0725\n",
      "Epoch 58/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0883 - val_loss: 0.0730\n",
      "Epoch 59/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0908 - val_loss: 0.0730\n",
      "Epoch 60/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0790 - val_loss: 0.0722\n",
      "Epoch 61/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0728\n",
      "Epoch 62/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0729\n",
      "Epoch 63/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0821 - val_loss: 0.0733\n",
      "Epoch 64/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.0726\n",
      "Epoch 65/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0787 - val_loss: 0.0731\n",
      "Epoch 66/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0738 - val_loss: 0.0732\n",
      "Epoch 67/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0725\n",
      "Epoch 68/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0720\n",
      "Epoch 69/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0721\n",
      "Epoch 70/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0721\n",
      "Epoch 71/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: 0.0732\n",
      "Epoch 72/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0866 - val_loss: 0.0719\n",
      "Epoch 73/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0880 - val_loss: 0.0726\n",
      "Epoch 74/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0798 - val_loss: 0.0736\n",
      "Epoch 75/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0790 - val_loss: 0.0738\n",
      "Epoch 76/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0774 - val_loss: 0.0731\n",
      "Epoch 77/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0779 - val_loss: 0.0724\n",
      "Epoch 78/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0741\n",
      "Epoch 79/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0887 - val_loss: 0.0727\n",
      "Epoch 80/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0808 - val_loss: 0.0718\n",
      "Epoch 81/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 82/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0776 - val_loss: 0.0723\n",
      "Epoch 83/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0855 - val_loss: 0.0716\n",
      "Epoch 84/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0890 - val_loss: 0.0715\n",
      "Epoch 85/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0720\n",
      "Epoch 86/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0750 - val_loss: 0.0726\n",
      "Epoch 87/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0840 - val_loss: 0.0725\n",
      "Epoch 88/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 89/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0826 - val_loss: 0.0736\n",
      "Epoch 90/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0725\n",
      "Epoch 91/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0852 - val_loss: 0.0734\n",
      "Epoch 92/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0919 - val_loss: 0.0733\n",
      "Epoch 93/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0899 - val_loss: 0.0728\n",
      "Epoch 94/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.0724\n",
      "Epoch 95/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0883 - val_loss: 0.0730\n",
      "Epoch 96/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0799 - val_loss: 0.0728\n",
      "Epoch 97/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0720\n",
      "Epoch 98/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0797 - val_loss: 0.0715\n",
      "Epoch 99/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0723\n",
      "Epoch 100/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0812 - val_loss: 0.0727\n",
      "Epoch 101/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0839 - val_loss: 0.0729\n",
      "Epoch 102/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0780 - val_loss: 0.0722\n",
      "Epoch 103/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0711 - val_loss: 0.0700\n",
      "Epoch 104/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0854 - val_loss: 0.0701\n",
      "Epoch 105/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0753 - val_loss: 0.0702\n",
      "Epoch 106/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0740\n",
      "Epoch 107/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0869 - val_loss: 0.0720\n",
      "Epoch 108/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0713\n",
      "Epoch 109/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0796 - val_loss: 0.0730\n",
      "Epoch 110/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0740\n",
      "Epoch 111/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0895 - val_loss: 0.0700\n",
      "Epoch 112/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0849 - val_loss: 0.0701\n",
      "Epoch 113/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0709\n",
      "Epoch 114/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0704\n",
      "Epoch 115/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0745 - val_loss: 0.0711\n",
      "Epoch 116/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0704\n",
      "Epoch 117/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0746 - val_loss: 0.0721\n",
      "Epoch 118/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0705\n",
      "Epoch 119/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0897 - val_loss: 0.0723\n",
      "Epoch 120/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0773 - val_loss: 0.0705\n",
      "Epoch 121/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0701\n",
      "Epoch 122/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0716\n",
      "Epoch 123/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0708\n",
      "Epoch 124/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0766 - val_loss: 0.0707\n",
      "Epoch 125/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0803 - val_loss: 0.0718\n",
      "Epoch 126/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0713\n",
      "Epoch 127/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0899 - val_loss: 0.0704\n",
      "Epoch 128/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0712 - val_loss: 0.0709\n",
      "Epoch 129/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0737 - val_loss: 0.0706\n",
      "Epoch 130/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0787 - val_loss: 0.0707\n",
      "Epoch 131/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0786 - val_loss: 0.0736\n",
      "Epoch 132/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0712\n",
      "Epoch 133/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0769 - val_loss: 0.0737\n",
      "Epoch 134/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0708\n",
      "Epoch 135/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0702\n",
      "Epoch 136/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0716 - val_loss: 0.0705\n",
      "Epoch 137/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0744 - val_loss: 0.0748\n",
      "Epoch 138/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0717\n",
      "Epoch 139/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0711\n",
      "Epoch 140/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0712\n",
      "Epoch 141/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0748 - val_loss: 0.0703\n",
      "Epoch 142/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0722\n",
      "Epoch 143/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0872 - val_loss: 0.0718\n",
      "Epoch 144/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0765 - val_loss: 0.0699\n",
      "Epoch 145/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0754 - val_loss: 0.0736\n",
      "Epoch 146/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0729 - val_loss: 0.0734\n",
      "Epoch 147/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0788 - val_loss: 0.0710\n",
      "Epoch 148/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0710\n",
      "Epoch 149/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0747 - val_loss: 0.0707\n",
      "Epoch 150/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0705 - val_loss: 0.0707\n",
      "Epoch 151/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0821 - val_loss: 0.0703\n",
      "Epoch 152/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0716\n",
      "Epoch 153/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0791 - val_loss: 0.0764\n",
      "Epoch 154/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0706\n",
      "Epoch 155/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0814 - val_loss: 0.0708\n",
      "Epoch 156/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0710\n",
      "Epoch 157/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0699\n",
      "Epoch 158/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0711\n",
      "Epoch 159/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0751 - val_loss: 0.0722\n",
      "Epoch 160/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0724 - val_loss: 0.0725\n",
      "Epoch 161/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0772 - val_loss: 0.0702\n",
      "Epoch 162/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0743 - val_loss: 0.0711\n",
      "Epoch 163/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0697\n",
      "Epoch 164/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0796 - val_loss: 0.0714\n",
      "Epoch 165/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0715\n",
      "Epoch 166/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0721\n",
      "Epoch 167/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0727\n",
      "Epoch 168/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0857 - val_loss: 0.0713\n",
      "Epoch 169/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0701\n",
      "Epoch 170/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0798 - val_loss: 0.0701\n",
      "Epoch 171/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0792 - val_loss: 0.0713\n",
      "Epoch 172/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0705\n",
      "Epoch 173/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0709 - val_loss: 0.0699\n",
      "Epoch 174/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0696\n",
      "Epoch 175/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0830 - val_loss: 0.0705\n",
      "Epoch 176/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0702\n",
      "Epoch 177/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0702\n",
      "Epoch 178/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0812 - val_loss: 0.0712\n",
      "Epoch 179/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0750 - val_loss: 0.0708\n",
      "Epoch 180/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0830 - val_loss: 0.0709\n",
      "Epoch 181/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0725 - val_loss: 0.0703\n",
      "Epoch 182/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0720\n",
      "Epoch 183/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0697 - val_loss: 0.0717\n",
      "Epoch 184/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0807 - val_loss: 0.0706\n",
      "Epoch 185/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0704\n",
      "Epoch 186/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 0.0717\n",
      "Epoch 187/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0712\n",
      "Epoch 188/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0783 - val_loss: 0.0700\n",
      "Epoch 189/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0767 - val_loss: 0.0732\n",
      "Epoch 190/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0755 - val_loss: 0.0707\n",
      "Epoch 191/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0740 - val_loss: 0.0729\n",
      "Epoch 192/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0700\n",
      "Epoch 193/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0835 - val_loss: 0.0721\n",
      "Epoch 194/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0706\n",
      "Epoch 195/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0831 - val_loss: 0.0704\n",
      "Epoch 196/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0700\n",
      "Epoch 197/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0723 - val_loss: 0.0707\n",
      "Epoch 198/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0785 - val_loss: 0.0711\n",
      "Epoch 199/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0837 - val_loss: 0.0724\n",
      "Epoch 200/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0724\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 62.0144 - val_loss: 0.1128\n",
      "Epoch 2/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5845 - val_loss: 0.0828\n",
      "Epoch 3/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1309 - val_loss: 0.0742\n",
      "Epoch 4/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0989 - val_loss: 0.0730\n",
      "Epoch 5/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0722\n",
      "Epoch 6/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0796 - val_loss: 0.0733\n",
      "Epoch 7/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0764 - val_loss: 0.0726\n",
      "Epoch 8/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0800 - val_loss: 0.0726\n",
      "Epoch 9/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0724\n",
      "Epoch 10/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0778 - val_loss: 0.0723\n",
      "Epoch 11/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0838 - val_loss: 0.0728\n",
      "Epoch 12/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0739 - val_loss: 0.0725\n",
      "Epoch 13/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0804 - val_loss: 0.0729\n",
      "Epoch 14/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0809 - val_loss: 0.0724\n",
      "Epoch 15/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0889 - val_loss: 0.0735\n",
      "Epoch 16/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0776 - val_loss: 0.0740\n",
      "Epoch 17/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0813 - val_loss: 0.0736\n",
      "Epoch 18/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0793 - val_loss: 0.0729\n",
      "Epoch 19/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0824 - val_loss: 0.0735\n",
      "Epoch 20/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0886 - val_loss: 0.0744\n",
      "Epoch 21/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0964 - val_loss: 0.0726\n",
      "Epoch 22/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0731\n",
      "Epoch 23/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0740\n",
      "Epoch 24/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0742\n",
      "Epoch 25/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0968 - val_loss: 0.0728\n",
      "Epoch 26/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0918 - val_loss: 0.0723\n",
      "Epoch 27/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0846 - val_loss: 0.0724\n",
      "Epoch 28/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0874 - val_loss: 0.0736\n",
      "Epoch 29/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0819 - val_loss: 0.0745\n",
      "Epoch 30/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0814 - val_loss: 0.0742\n",
      "Epoch 31/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0704 - val_loss: 0.0747\n",
      "Epoch 32/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0802 - val_loss: 0.0780\n",
      "Epoch 33/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0733\n",
      "Epoch 34/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0847 - val_loss: 0.0731\n",
      "Epoch 35/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0838 - val_loss: 0.0735\n",
      "Epoch 36/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0804 - val_loss: 0.0732\n",
      "Epoch 37/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0804 - val_loss: 0.0732\n",
      "Epoch 38/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0823 - val_loss: 0.0739\n",
      "Epoch 39/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0731\n",
      "Epoch 40/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0728\n",
      "Epoch 41/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0829 - val_loss: 0.0729\n",
      "Epoch 42/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0771 - val_loss: 0.0738\n",
      "Epoch 43/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0832 - val_loss: 0.0731\n",
      "Epoch 44/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0728\n",
      "Epoch 45/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0802 - val_loss: 0.0729\n",
      "Epoch 46/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0810 - val_loss: 0.0729\n",
      "Epoch 47/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0886 - val_loss: 0.0730\n",
      "Epoch 48/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0731\n",
      "Epoch 49/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0888 - val_loss: 0.0737\n",
      "Epoch 50/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0893 - val_loss: 0.0736\n",
      "Epoch 51/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.0723\n",
      "Epoch 52/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0808 - val_loss: 0.0731\n",
      "Epoch 53/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0723\n",
      "Epoch 54/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0791 - val_loss: 0.0734\n",
      "Epoch 55/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0857 - val_loss: 0.0726\n",
      "Epoch 56/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0853 - val_loss: 0.0723\n",
      "Epoch 57/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0906 - val_loss: 0.0731\n",
      "Epoch 58/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.0721\n",
      "Epoch 59/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0943 - val_loss: 0.0732\n",
      "Epoch 60/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0767 - val_loss: 0.0732\n",
      "Epoch 61/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0855 - val_loss: 0.0732\n",
      "Epoch 62/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0813 - val_loss: 0.0730\n",
      "Epoch 63/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0789 - val_loss: 0.0747\n",
      "Epoch 64/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0727\n",
      "Epoch 65/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0830 - val_loss: 0.0722\n",
      "Epoch 66/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0723\n",
      "Epoch 67/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0858 - val_loss: 0.0728\n",
      "Epoch 68/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0821 - val_loss: 0.0749\n",
      "Epoch 69/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0872 - val_loss: 0.0734\n",
      "Epoch 70/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0805 - val_loss: 0.0708\n",
      "Epoch 71/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0744 - val_loss: 0.0713\n",
      "Epoch 72/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0757 - val_loss: 0.0718\n",
      "Epoch 73/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0765 - val_loss: 0.0716\n",
      "Epoch 74/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0842 - val_loss: 0.0711\n",
      "Epoch 75/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.0707\n",
      "Epoch 76/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0799 - val_loss: 0.0701\n",
      "Epoch 77/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0701\n",
      "Epoch 78/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0815 - val_loss: 0.0703\n",
      "Epoch 79/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0732\n",
      "Epoch 80/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 81/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0783 - val_loss: 0.0712\n",
      "Epoch 82/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0842 - val_loss: 0.0719\n",
      "Epoch 83/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0729 - val_loss: 0.0707\n",
      "Epoch 84/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0805 - val_loss: 0.0714\n",
      "Epoch 85/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0921 - val_loss: 0.0719\n",
      "Epoch 86/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0941 - val_loss: 0.0705\n",
      "Epoch 87/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.0707\n",
      "Epoch 88/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0808 - val_loss: 0.0710\n",
      "Epoch 89/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0703\n",
      "Epoch 90/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0707\n",
      "Epoch 91/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0875 - val_loss: 0.0707\n",
      "Epoch 92/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0901 - val_loss: 0.0704\n",
      "Epoch 93/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0709\n",
      "Epoch 94/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0756 - val_loss: 0.0724\n",
      "Epoch 95/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0894 - val_loss: 0.0707\n",
      "Epoch 96/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.0710\n",
      "Epoch 97/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0832 - val_loss: 0.0710\n",
      "Epoch 98/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0705\n",
      "Epoch 99/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0806 - val_loss: 0.0710\n",
      "Epoch 100/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0707\n",
      "Epoch 101/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: 0.0723\n",
      "Epoch 102/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0709\n",
      "Epoch 103/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0778 - val_loss: 0.0709\n",
      "Epoch 104/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0797 - val_loss: 0.0712\n",
      "Epoch 105/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0818 - val_loss: 0.0703\n",
      "Epoch 106/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0935 - val_loss: 0.0714\n",
      "Epoch 107/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0798 - val_loss: 0.0714\n",
      "Epoch 108/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0705\n",
      "Epoch 109/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0901 - val_loss: 0.0707\n",
      "Epoch 110/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0878 - val_loss: 0.0707\n",
      "Epoch 111/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0759 - val_loss: 0.0713\n",
      "Epoch 112/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0700\n",
      "Epoch 113/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0705\n",
      "Epoch 114/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0704\n",
      "Epoch 115/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0777 - val_loss: 0.0714\n",
      "Epoch 116/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0887 - val_loss: 0.0711\n",
      "Epoch 117/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0756 - val_loss: 0.0702\n",
      "Epoch 118/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0910 - val_loss: 0.0705\n",
      "Epoch 119/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0716\n",
      "Epoch 120/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0851 - val_loss: 0.0707\n",
      "Epoch 121/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0886 - val_loss: 0.0703\n",
      "Epoch 122/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0805 - val_loss: 0.0705\n",
      "Epoch 123/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0810 - val_loss: 0.0711\n",
      "Epoch 124/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0714\n",
      "Epoch 125/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0706\n",
      "Epoch 126/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0872 - val_loss: 0.0721\n",
      "Epoch 127/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0865 - val_loss: 0.0709\n",
      "Epoch 128/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0836 - val_loss: 0.0718\n",
      "Epoch 129/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0815 - val_loss: 0.0713\n",
      "Epoch 130/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0752 - val_loss: 0.0713\n",
      "Epoch 131/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0891 - val_loss: 0.0704\n",
      "Epoch 132/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0707\n",
      "Epoch 133/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0708\n",
      "Epoch 134/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0839 - val_loss: 0.0733\n",
      "Epoch 135/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0733\n",
      "Epoch 136/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0706\n",
      "Epoch 137/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0845 - val_loss: 0.0734\n",
      "Epoch 138/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0706\n",
      "Epoch 139/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0702\n",
      "Epoch 140/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0707\n",
      "Epoch 141/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0758 - val_loss: 0.0805\n",
      "Epoch 142/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0850 - val_loss: 0.0713\n",
      "Epoch 143/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0889 - val_loss: 0.0711\n",
      "Epoch 144/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0787 - val_loss: 0.0708\n",
      "Epoch 145/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0756 - val_loss: 0.0709\n",
      "Epoch 146/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0814 - val_loss: 0.0708\n",
      "Epoch 147/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0803 - val_loss: 0.0707\n",
      "Epoch 148/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0890 - val_loss: 0.0706\n",
      "Epoch 149/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0813 - val_loss: 0.0705\n",
      "Epoch 150/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0768 - val_loss: 0.0706\n",
      "Epoch 151/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0721\n",
      "Epoch 152/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0875 - val_loss: 0.0726\n",
      "Epoch 153/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0823 - val_loss: 0.0704\n",
      "Epoch 154/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0745 - val_loss: 0.0712\n",
      "Epoch 155/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0778 - val_loss: 0.0705\n",
      "Epoch 156/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0782 - val_loss: 0.0705\n",
      "Epoch 157/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0766 - val_loss: 0.0706\n",
      "Epoch 158/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 159/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0702\n",
      "Epoch 160/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0863 - val_loss: 0.0706\n",
      "Epoch 161/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0936 - val_loss: 0.0706\n",
      "Epoch 162/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0862 - val_loss: 0.0707\n",
      "Epoch 163/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0802 - val_loss: 0.0709\n",
      "Epoch 164/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0712\n",
      "Epoch 165/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0881 - val_loss: 0.0721\n",
      "Epoch 166/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0708\n",
      "Epoch 167/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0855 - val_loss: 0.0708\n",
      "Epoch 168/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0743 - val_loss: 0.0706\n",
      "Epoch 169/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0776 - val_loss: 0.0705\n",
      "Epoch 170/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0732 - val_loss: 0.0713\n",
      "Epoch 171/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0754 - val_loss: 0.0730\n",
      "Epoch 172/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.0704\n",
      "Epoch 173/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0774 - val_loss: 0.0709\n",
      "Epoch 174/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0812 - val_loss: 0.0704\n",
      "Epoch 175/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0703\n",
      "Epoch 176/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0805 - val_loss: 0.0703\n",
      "Epoch 177/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0705\n",
      "Epoch 178/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0705\n",
      "Epoch 179/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0702\n",
      "Epoch 180/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0681 - val_loss: 0.0710\n",
      "Epoch 181/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0812 - val_loss: 0.0707\n",
      "Epoch 182/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0778 - val_loss: 0.0706\n",
      "Epoch 183/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0958 - val_loss: 0.0700\n",
      "Epoch 184/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0778 - val_loss: 0.0713\n",
      "Epoch 185/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0703\n",
      "Epoch 186/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0802 - val_loss: 0.0703\n",
      "Epoch 187/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0824 - val_loss: 0.0697\n",
      "Epoch 188/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0700\n",
      "Epoch 189/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0747 - val_loss: 0.0702\n",
      "Epoch 190/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0703\n",
      "Epoch 191/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0883 - val_loss: 0.0701\n",
      "Epoch 192/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0920 - val_loss: 0.0700\n",
      "Epoch 193/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0708 - val_loss: 0.0719\n",
      "Epoch 194/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0702\n",
      "Epoch 195/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0758 - val_loss: 0.0706\n",
      "Epoch 196/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0704\n",
      "Epoch 197/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0756 - val_loss: 0.0709\n",
      "Epoch 198/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0711\n",
      "Epoch 199/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0705\n",
      "Epoch 200/200\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0780 - val_loss: 0.0704\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 37.4196 - val_loss: 0.0978\n",
      "Epoch 2/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5947 - val_loss: 0.0981\n",
      "Epoch 3/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2296 - val_loss: 0.0792\n",
      "Epoch 4/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1150 - val_loss: 0.0754\n",
      "Epoch 5/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0986 - val_loss: 0.0720\n",
      "Epoch 6/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0875 - val_loss: 0.0710\n",
      "Epoch 7/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0713\n",
      "Epoch 8/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0723\n",
      "Epoch 9/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0815 - val_loss: 0.0705\n",
      "Epoch 10/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0814 - val_loss: 0.0707\n",
      "Epoch 11/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0712\n",
      "Epoch 12/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0730\n",
      "Epoch 13/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0930 - val_loss: 0.0729\n",
      "Epoch 14/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0737\n",
      "Epoch 15/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0823 - val_loss: 0.0729\n",
      "Epoch 16/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 0.0736\n",
      "Epoch 17/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0728\n",
      "Epoch 18/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0728\n",
      "Epoch 19/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 20/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0793 - val_loss: 0.0736\n",
      "Epoch 21/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0733\n",
      "Epoch 22/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0736\n",
      "Epoch 23/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0906 - val_loss: 0.0731\n",
      "Epoch 24/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0725\n",
      "Epoch 25/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.0722\n",
      "Epoch 26/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0781 - val_loss: 0.0732\n",
      "Epoch 27/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0813 - val_loss: 0.0731\n",
      "Epoch 28/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0873 - val_loss: 0.0732\n",
      "Epoch 29/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0728\n",
      "Epoch 30/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0735\n",
      "Epoch 31/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0808 - val_loss: 0.0729\n",
      "Epoch 32/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0728\n",
      "Epoch 33/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0837 - val_loss: 0.0733\n",
      "Epoch 34/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0871 - val_loss: 0.0720\n",
      "Epoch 35/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: 0.0746\n",
      "Epoch 36/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0736\n",
      "Epoch 37/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0766 - val_loss: 0.0736\n",
      "Epoch 38/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0743\n",
      "Epoch 39/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0873 - val_loss: 0.0720\n",
      "Epoch 40/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0726\n",
      "Epoch 41/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0874 - val_loss: 0.0741\n",
      "Epoch 42/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0737 - val_loss: 0.0736\n",
      "Epoch 43/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0830 - val_loss: 0.0740\n",
      "Epoch 44/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0873 - val_loss: 0.0721\n",
      "Epoch 45/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0889 - val_loss: 0.0724\n",
      "Epoch 46/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0738\n",
      "Epoch 47/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0737\n",
      "Epoch 48/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0767 - val_loss: 0.0734\n",
      "Epoch 49/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0893 - val_loss: 0.0736\n",
      "Epoch 50/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0734\n",
      "Epoch 51/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0744\n",
      "Epoch 52/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0742\n",
      "Epoch 53/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0733\n",
      "Epoch 54/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0738\n",
      "Epoch 55/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0722\n",
      "Epoch 56/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0838 - val_loss: 0.0724\n",
      "Epoch 57/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0808 - val_loss: 0.0753\n",
      "Epoch 58/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0767 - val_loss: 0.0729\n",
      "Epoch 59/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0785 - val_loss: 0.0735\n",
      "Epoch 60/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.0736\n",
      "Epoch 61/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0730\n",
      "Epoch 62/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0845 - val_loss: 0.0726\n",
      "Epoch 63/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0798 - val_loss: 0.0728\n",
      "Epoch 64/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: 0.0739\n",
      "Epoch 65/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0846 - val_loss: 0.0727\n",
      "Epoch 66/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0736\n",
      "Epoch 67/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.0718\n",
      "Epoch 68/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0841 - val_loss: 0.0736\n",
      "Epoch 69/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0724\n",
      "Epoch 70/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0862 - val_loss: 0.0735\n",
      "Epoch 71/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0735\n",
      "Epoch 72/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0855 - val_loss: 0.0734\n",
      "Epoch 73/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0730\n",
      "Epoch 74/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0888 - val_loss: 0.0731\n",
      "Epoch 75/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0738 - val_loss: 0.0723\n",
      "Epoch 76/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0863 - val_loss: 0.0735\n",
      "Epoch 77/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0729\n",
      "Epoch 78/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0722\n",
      "Epoch 79/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0945 - val_loss: 0.0723\n",
      "Epoch 80/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0702 - val_loss: 0.0742\n",
      "Epoch 81/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0834 - val_loss: 0.0743\n",
      "Epoch 82/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0949 - val_loss: 0.0733\n",
      "Epoch 83/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0742 - val_loss: 0.0726\n",
      "Epoch 84/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0891 - val_loss: 0.0724\n",
      "Epoch 85/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0795 - val_loss: 0.0729\n",
      "Epoch 86/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0729\n",
      "Epoch 87/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0737\n",
      "Epoch 88/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0728\n",
      "Epoch 89/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0725\n",
      "Epoch 90/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0723\n",
      "Epoch 91/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.0727\n",
      "Epoch 92/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0719\n",
      "Epoch 93/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0875 - val_loss: 0.0732\n",
      "Epoch 94/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0831 - val_loss: 0.0730\n",
      "Epoch 95/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0736\n",
      "Epoch 96/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0846 - val_loss: 0.0728\n",
      "Epoch 97/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0801 - val_loss: 0.0724\n",
      "Epoch 98/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0725\n",
      "Epoch 99/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0727\n",
      "Epoch 100/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0735\n",
      "Epoch 101/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0725\n",
      "Epoch 102/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0729\n",
      "Epoch 103/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0787 - val_loss: 0.0732\n",
      "Epoch 104/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0864 - val_loss: 0.0734\n",
      "Epoch 105/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0777 - val_loss: 0.0733\n",
      "Epoch 106/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0897 - val_loss: 0.0727\n",
      "Epoch 107/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0871 - val_loss: 0.0726\n",
      "Epoch 108/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0885 - val_loss: 0.0725\n",
      "Epoch 109/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0805 - val_loss: 0.0726\n",
      "Epoch 110/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0722\n",
      "Epoch 111/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0729\n",
      "Epoch 112/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0803 - val_loss: 0.0728\n",
      "Epoch 113/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0758 - val_loss: 0.0729\n",
      "Epoch 114/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0732\n",
      "Epoch 115/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0730\n",
      "Epoch 116/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0840 - val_loss: 0.0721\n",
      "Epoch 117/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0938 - val_loss: 0.0725\n",
      "Epoch 118/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0879 - val_loss: 0.0728\n",
      "Epoch 119/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0823 - val_loss: 0.0735\n",
      "Epoch 120/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0729\n",
      "Epoch 121/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0733\n",
      "Epoch 122/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0896 - val_loss: 0.0726\n",
      "Epoch 123/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0855 - val_loss: 0.0727\n",
      "Epoch 124/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0938 - val_loss: 0.0725\n",
      "Epoch 125/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0773 - val_loss: 0.0728\n",
      "Epoch 126/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0731\n",
      "Epoch 127/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0977 - val_loss: 0.0734\n",
      "Epoch 128/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0763 - val_loss: 0.0735\n",
      "Epoch 129/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.0725\n",
      "Epoch 130/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0725\n",
      "Epoch 131/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0726\n",
      "Epoch 132/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0760 - val_loss: 0.0725\n",
      "Epoch 133/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0840 - val_loss: 0.0725\n",
      "Epoch 134/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0976 - val_loss: 0.0725\n",
      "Epoch 135/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0722\n",
      "Epoch 136/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0894 - val_loss: 0.0720\n",
      "Epoch 137/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0723\n",
      "Epoch 138/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0792 - val_loss: 0.0717\n",
      "Epoch 139/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0725\n",
      "Epoch 140/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0724\n",
      "Epoch 141/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0843 - val_loss: 0.0726\n",
      "Epoch 142/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0779 - val_loss: 0.0724\n",
      "Epoch 143/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0725\n",
      "Epoch 144/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0725\n",
      "Epoch 145/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0790 - val_loss: 0.0762\n",
      "Epoch 146/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0850 - val_loss: 0.0720\n",
      "Epoch 147/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0851 - val_loss: 0.0722\n",
      "Epoch 148/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0889 - val_loss: 0.0719\n",
      "Epoch 149/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0901 - val_loss: 0.0718\n",
      "Epoch 150/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0724\n",
      "Epoch 151/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0770 - val_loss: 0.0722\n",
      "Epoch 152/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0802 - val_loss: 0.0724\n",
      "Epoch 153/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0882 - val_loss: 0.0723\n",
      "Epoch 154/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0776 - val_loss: 0.0723\n",
      "Epoch 155/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0724\n",
      "Epoch 156/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0727\n",
      "Epoch 157/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0730\n",
      "Epoch 158/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 159/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0889 - val_loss: 0.0723\n",
      "Epoch 160/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0855 - val_loss: 0.0735\n",
      "Epoch 161/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0728\n",
      "Epoch 162/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0731\n",
      "Epoch 163/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0724\n",
      "Epoch 164/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0814 - val_loss: 0.0732\n",
      "Epoch 165/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0763 - val_loss: 0.0733\n",
      "Epoch 166/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0843 - val_loss: 0.0734\n",
      "Epoch 167/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0799 - val_loss: 0.0735\n",
      "Epoch 168/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0888 - val_loss: 0.0740\n",
      "Epoch 169/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0749 - val_loss: 0.0741\n",
      "Epoch 170/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.0745\n",
      "Epoch 171/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0804 - val_loss: 0.0737\n",
      "Epoch 172/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0851 - val_loss: 0.0740\n",
      "Epoch 173/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0730\n",
      "Epoch 174/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0914 - val_loss: 0.0735\n",
      "Epoch 175/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0777 - val_loss: 0.0738\n",
      "Epoch 176/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0837 - val_loss: 0.0823\n",
      "Epoch 177/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0727\n",
      "Epoch 178/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0756 - val_loss: 0.0730\n",
      "Epoch 179/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0890 - val_loss: 0.0728\n",
      "Epoch 180/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0808 - val_loss: 0.0734\n",
      "Epoch 181/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0976 - val_loss: 0.0737\n",
      "Epoch 182/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0736\n",
      "Epoch 183/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0737\n",
      "Epoch 184/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0733\n",
      "Epoch 185/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0734\n",
      "Epoch 186/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: 0.0729\n",
      "Epoch 187/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0735\n",
      "Epoch 188/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0821 - val_loss: 0.0733\n",
      "Epoch 189/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0732\n",
      "Epoch 190/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0834 - val_loss: 0.0726\n",
      "Epoch 191/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0727\n",
      "Epoch 192/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0903 - val_loss: 0.0732\n",
      "Epoch 193/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0724\n",
      "Epoch 194/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0728\n",
      "Epoch 195/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0723\n",
      "Epoch 196/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0839 - val_loss: 0.0722\n",
      "Epoch 197/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0798 - val_loss: 0.0723\n",
      "Epoch 198/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0723\n",
      "Epoch 199/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0873 - val_loss: 0.0713\n",
      "Epoch 200/200\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0875 - val_loss: 0.0719\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 42.2672 - val_loss: 0.1346\n",
      "Epoch 2/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8522 - val_loss: 0.0826\n",
      "Epoch 3/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1825 - val_loss: 0.0755\n",
      "Epoch 4/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1178 - val_loss: 0.0758\n",
      "Epoch 5/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.0753\n",
      "Epoch 6/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0725\n",
      "Epoch 7/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0835 - val_loss: 0.0722\n",
      "Epoch 8/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0737\n",
      "Epoch 9/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0964 - val_loss: 0.0722\n",
      "Epoch 10/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0820 - val_loss: 0.0719\n",
      "Epoch 11/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0718\n",
      "Epoch 12/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 0.0722\n",
      "Epoch 13/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0787 - val_loss: 0.0725\n",
      "Epoch 14/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0933 - val_loss: 0.0724\n",
      "Epoch 15/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0831 - val_loss: 0.0714\n",
      "Epoch 16/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0713\n",
      "Epoch 17/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0896 - val_loss: 0.0719\n",
      "Epoch 18/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0833 - val_loss: 0.0714\n",
      "Epoch 19/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 0.0714\n",
      "Epoch 20/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0797 - val_loss: 0.0713\n",
      "Epoch 21/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0786 - val_loss: 0.0709\n",
      "Epoch 22/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0778 - val_loss: 0.0709\n",
      "Epoch 23/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0905 - val_loss: 0.0732\n",
      "Epoch 24/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.0745\n",
      "Epoch 25/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0766 - val_loss: 0.0749\n",
      "Epoch 26/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0878 - val_loss: 0.0740\n",
      "Epoch 27/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0890 - val_loss: 0.0746\n",
      "Epoch 28/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0994 - val_loss: 0.0736\n",
      "Epoch 29/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0740\n",
      "Epoch 30/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0742\n",
      "Epoch 31/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0741\n",
      "Epoch 32/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0784 - val_loss: 0.0743\n",
      "Epoch 33/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0723\n",
      "Epoch 34/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0726\n",
      "Epoch 35/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0934 - val_loss: 0.0723\n",
      "Epoch 36/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0836 - val_loss: 0.0739\n",
      "Epoch 37/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0744\n",
      "Epoch 38/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.0732\n",
      "Epoch 39/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0729\n",
      "Epoch 40/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0915 - val_loss: 0.0723\n",
      "Epoch 41/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0736\n",
      "Epoch 42/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0724\n",
      "Epoch 43/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0726\n",
      "Epoch 44/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0726\n",
      "Epoch 45/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0773 - val_loss: 0.0744\n",
      "Epoch 46/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0895 - val_loss: 0.0737\n",
      "Epoch 47/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0837 - val_loss: 0.0720\n",
      "Epoch 48/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0866 - val_loss: 0.0719\n",
      "Epoch 49/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0880 - val_loss: 0.0732\n",
      "Epoch 50/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0765 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0785 - val_loss: 0.0727\n",
      "Epoch 52/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0903 - val_loss: 0.0728\n",
      "Epoch 53/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0727\n",
      "Epoch 54/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0724\n",
      "Epoch 55/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0855 - val_loss: 0.0740\n",
      "Epoch 56/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0731\n",
      "Epoch 57/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0863 - val_loss: 0.0736\n",
      "Epoch 58/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0786 - val_loss: 0.0729\n",
      "Epoch 59/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0871 - val_loss: 0.0726\n",
      "Epoch 60/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0727\n",
      "Epoch 61/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0837 - val_loss: 0.0728\n",
      "Epoch 62/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0806 - val_loss: 0.0719\n",
      "Epoch 63/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1053 - val_loss: 0.0717\n",
      "Epoch 64/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0730\n",
      "Epoch 65/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0728\n",
      "Epoch 66/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0859 - val_loss: 0.0726\n",
      "Epoch 67/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0724\n",
      "Epoch 68/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0726\n",
      "Epoch 69/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0823 - val_loss: 0.0727\n",
      "Epoch 70/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0721\n",
      "Epoch 71/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0841 - val_loss: 0.0728\n",
      "Epoch 72/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0727\n",
      "Epoch 73/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0726\n",
      "Epoch 74/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0722\n",
      "Epoch 75/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0763 - val_loss: 0.0770\n",
      "Epoch 76/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0814 - val_loss: 0.0734\n",
      "Epoch 77/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0724\n",
      "Epoch 78/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0722\n",
      "Epoch 79/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0718\n",
      "Epoch 80/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0727\n",
      "Epoch 81/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0737 - val_loss: 0.0731\n",
      "Epoch 82/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0843 - val_loss: 0.0728\n",
      "Epoch 83/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0720\n",
      "Epoch 84/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0732\n",
      "Epoch 85/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0728\n",
      "Epoch 86/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0728\n",
      "Epoch 87/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0847 - val_loss: 0.0720\n",
      "Epoch 88/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0903 - val_loss: 0.0718\n",
      "Epoch 89/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0880 - val_loss: 0.0722\n",
      "Epoch 90/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0709 - val_loss: 0.0725\n",
      "Epoch 91/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0920 - val_loss: 0.0717\n",
      "Epoch 92/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0759 - val_loss: 0.0732\n",
      "Epoch 93/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0772 - val_loss: 0.0735\n",
      "Epoch 94/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0845 - val_loss: 0.0732\n",
      "Epoch 95/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0739 - val_loss: 0.0747\n",
      "Epoch 96/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0898 - val_loss: 0.0741\n",
      "Epoch 97/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0792 - val_loss: 0.0726\n",
      "Epoch 98/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0881 - val_loss: 0.0712\n",
      "Epoch 99/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0821 - val_loss: 0.0750\n",
      "Epoch 100/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0736\n",
      "Epoch 101/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0861 - val_loss: 0.0727\n",
      "Epoch 102/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0726\n",
      "Epoch 103/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0728\n",
      "Epoch 104/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0900 - val_loss: 0.0729\n",
      "Epoch 105/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0761 - val_loss: 0.0724\n",
      "Epoch 106/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0901 - val_loss: 0.0729\n",
      "Epoch 107/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0734\n",
      "Epoch 108/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0727\n",
      "Epoch 109/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0727\n",
      "Epoch 110/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0866 - val_loss: 0.0727\n",
      "Epoch 111/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0804 - val_loss: 0.0731\n",
      "Epoch 112/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0779 - val_loss: 0.0736\n",
      "Epoch 113/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0916 - val_loss: 0.0719\n",
      "Epoch 114/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0737\n",
      "Epoch 115/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0815 - val_loss: 0.0726\n",
      "Epoch 116/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0719\n",
      "Epoch 117/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0721\n",
      "Epoch 118/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0728\n",
      "Epoch 119/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0726\n",
      "Epoch 120/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0807 - val_loss: 0.0732\n",
      "Epoch 121/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0852 - val_loss: 0.0731\n",
      "Epoch 122/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0722\n",
      "Epoch 123/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0723\n",
      "Epoch 124/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0725\n",
      "Epoch 125/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0729\n",
      "Epoch 126/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0921 - val_loss: 0.0724\n",
      "Epoch 127/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0877 - val_loss: 0.0721\n",
      "Epoch 128/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0718\n",
      "Epoch 129/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0787 - val_loss: 0.0724\n",
      "Epoch 130/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0756 - val_loss: 0.0721\n",
      "Epoch 131/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0908 - val_loss: 0.0716\n",
      "Epoch 132/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0819 - val_loss: 0.0721\n",
      "Epoch 133/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0717 - val_loss: 0.0720\n",
      "Epoch 134/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0802 - val_loss: 0.0724\n",
      "Epoch 135/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0728\n",
      "Epoch 136/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0717\n",
      "Epoch 137/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0752 - val_loss: 0.0730\n",
      "Epoch 138/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0769 - val_loss: 0.0732\n",
      "Epoch 139/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0870 - val_loss: 0.0717\n",
      "Epoch 140/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0930 - val_loss: 0.0721\n",
      "Epoch 141/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0738 - val_loss: 0.0719\n",
      "Epoch 142/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0792 - val_loss: 0.0729\n",
      "Epoch 143/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0837 - val_loss: 0.0727\n",
      "Epoch 144/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0715\n",
      "Epoch 145/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0721\n",
      "Epoch 146/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0719\n",
      "Epoch 147/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0861 - val_loss: 0.0720\n",
      "Epoch 148/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0724\n",
      "Epoch 149/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0716\n",
      "Epoch 150/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0724\n",
      "Epoch 151/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0725\n",
      "Epoch 152/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0712 - val_loss: 0.0725\n",
      "Epoch 153/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0729\n",
      "Epoch 154/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0777 - val_loss: 0.0716\n",
      "Epoch 155/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0721\n",
      "Epoch 156/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0881 - val_loss: 0.0714\n",
      "Epoch 157/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0722\n",
      "Epoch 158/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0848 - val_loss: 0.0714\n",
      "Epoch 159/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.0723\n",
      "Epoch 160/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0790 - val_loss: 0.0713\n",
      "Epoch 161/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0945 - val_loss: 0.0708\n",
      "Epoch 162/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0707\n",
      "Epoch 163/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0780 - val_loss: 0.0705\n",
      "Epoch 164/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0815 - val_loss: 0.0712\n",
      "Epoch 165/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0709\n",
      "Epoch 166/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0805 - val_loss: 0.0708\n",
      "Epoch 167/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0711\n",
      "Epoch 168/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0911 - val_loss: 0.0706\n",
      "Epoch 169/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0915 - val_loss: 0.0706\n",
      "Epoch 170/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0834 - val_loss: 0.0703\n",
      "Epoch 171/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0714\n",
      "Epoch 172/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0814 - val_loss: 0.0704\n",
      "Epoch 173/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0838 - val_loss: 0.0714\n",
      "Epoch 174/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0704 - val_loss: 0.0716\n",
      "Epoch 175/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0863 - val_loss: 0.0713\n",
      "Epoch 176/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0735 - val_loss: 0.0706\n",
      "Epoch 177/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0798 - val_loss: 0.0724\n",
      "Epoch 178/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0740 - val_loss: 0.0704\n",
      "Epoch 179/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0722\n",
      "Epoch 180/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0711\n",
      "Epoch 181/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0939 - val_loss: 0.0708\n",
      "Epoch 182/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0711\n",
      "Epoch 183/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0819 - val_loss: 0.0709\n",
      "Epoch 184/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0722\n",
      "Epoch 185/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0747 - val_loss: 0.0713\n",
      "Epoch 186/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0799 - val_loss: 0.0710\n",
      "Epoch 187/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0711\n",
      "Epoch 188/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0715\n",
      "Epoch 189/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.0713\n",
      "Epoch 190/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 191/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0839 - val_loss: 0.0717\n",
      "Epoch 192/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0714\n",
      "Epoch 193/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0709 - val_loss: 0.0709\n",
      "Epoch 194/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0764 - val_loss: 0.0710\n",
      "Epoch 195/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0724 - val_loss: 0.0716\n",
      "Epoch 196/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0783 - val_loss: 0.0711\n",
      "Epoch 197/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0708\n",
      "Epoch 198/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0708\n",
      "Epoch 199/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0730 - val_loss: 0.0708\n",
      "Epoch 200/200\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0730 - val_loss: 0.0708\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 35.3238 - val_loss: 0.1099\n",
      "Epoch 2/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7987 - val_loss: 0.0927\n",
      "Epoch 3/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6456 - val_loss: 0.0876\n",
      "Epoch 4/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3171 - val_loss: 0.0785\n",
      "Epoch 5/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2059 - val_loss: 0.0784\n",
      "Epoch 6/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1237 - val_loss: 0.0743\n",
      "Epoch 7/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.0728\n",
      "Epoch 8/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0916 - val_loss: 0.0721\n",
      "Epoch 9/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0715\n",
      "Epoch 10/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0802 - val_loss: 0.0712\n",
      "Epoch 11/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0746 - val_loss: 0.0716\n",
      "Epoch 12/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0715\n",
      "Epoch 13/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0922 - val_loss: 0.0710\n",
      "Epoch 14/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0842 - val_loss: 0.0717\n",
      "Epoch 15/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0708\n",
      "Epoch 16/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0874 - val_loss: 0.0716\n",
      "Epoch 17/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0799 - val_loss: 0.0715\n",
      "Epoch 18/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0852 - val_loss: 0.0705\n",
      "Epoch 19/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0709\n",
      "Epoch 20/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0805 - val_loss: 0.0736\n",
      "Epoch 21/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0756 - val_loss: 0.0733\n",
      "Epoch 22/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0813 - val_loss: 0.0731\n",
      "Epoch 23/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0861 - val_loss: 0.0733\n",
      "Epoch 24/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0851 - val_loss: 0.0730\n",
      "Epoch 25/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0729\n",
      "Epoch 26/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0871 - val_loss: 0.0728\n",
      "Epoch 27/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0957 - val_loss: 0.0728\n",
      "Epoch 28/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0833 - val_loss: 0.0728\n",
      "Epoch 29/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0831 - val_loss: 0.0727\n",
      "Epoch 30/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0762 - val_loss: 0.0727\n",
      "Epoch 31/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0725\n",
      "Epoch 32/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0868 - val_loss: 0.0721\n",
      "Epoch 33/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0903 - val_loss: 0.0722\n",
      "Epoch 34/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0728\n",
      "Epoch 35/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0919 - val_loss: 0.0732\n",
      "Epoch 36/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0708 - val_loss: 0.0731\n",
      "Epoch 37/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0842 - val_loss: 0.0721\n",
      "Epoch 38/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0792 - val_loss: 0.0736\n",
      "Epoch 39/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0724\n",
      "Epoch 40/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - val_loss: 0.0739\n",
      "Epoch 41/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0729\n",
      "Epoch 42/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0917 - val_loss: 0.0722\n",
      "Epoch 43/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0712\n",
      "Epoch 44/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0894 - val_loss: 0.0724\n",
      "Epoch 45/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0726\n",
      "Epoch 46/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0808 - val_loss: 0.0720\n",
      "Epoch 47/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: 0.0723\n",
      "Epoch 48/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0776 - val_loss: 0.0716\n",
      "Epoch 49/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0720\n",
      "Epoch 50/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 0.0723\n",
      "Epoch 51/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0810 - val_loss: 0.0737\n",
      "Epoch 52/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0759 - val_loss: 0.0726\n",
      "Epoch 53/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0767 - val_loss: 0.0716\n",
      "Epoch 54/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0800 - val_loss: 0.0718\n",
      "Epoch 55/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0814 - val_loss: 0.0725\n",
      "Epoch 56/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0847 - val_loss: 0.0719\n",
      "Epoch 57/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0747\n",
      "Epoch 58/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0983 - val_loss: 0.0720\n",
      "Epoch 59/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0724\n",
      "Epoch 60/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0818 - val_loss: 0.0720\n",
      "Epoch 61/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0818 - val_loss: 0.0724\n",
      "Epoch 62/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0798 - val_loss: 0.0720\n",
      "Epoch 63/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.0723\n",
      "Epoch 64/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0782 - val_loss: 0.0719\n",
      "Epoch 65/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0857 - val_loss: 0.0715\n",
      "Epoch 66/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0819 - val_loss: 0.0719\n",
      "Epoch 67/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0765 - val_loss: 0.0719\n",
      "Epoch 68/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0803 - val_loss: 0.0717\n",
      "Epoch 69/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0852 - val_loss: 0.0719\n",
      "Epoch 70/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0761 - val_loss: 0.0724\n",
      "Epoch 71/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0798 - val_loss: 0.0723\n",
      "Epoch 72/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0870 - val_loss: 0.0729\n",
      "Epoch 73/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0800 - val_loss: 0.0716\n",
      "Epoch 74/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0724\n",
      "Epoch 75/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0740\n",
      "Epoch 76/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0897 - val_loss: 0.0724\n",
      "Epoch 77/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0748 - val_loss: 0.0730\n",
      "Epoch 78/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0806 - val_loss: 0.0734\n",
      "Epoch 79/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0717\n",
      "Epoch 80/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0836 - val_loss: 0.0723\n",
      "Epoch 81/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0725\n",
      "Epoch 82/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0836 - val_loss: 0.0721\n",
      "Epoch 83/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0893 - val_loss: 0.0717\n",
      "Epoch 84/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0845 - val_loss: 0.0736\n",
      "Epoch 85/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0877 - val_loss: 0.0719\n",
      "Epoch 86/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0725\n",
      "Epoch 87/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0816 - val_loss: 0.0725\n",
      "Epoch 88/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.0726\n",
      "Epoch 89/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0796 - val_loss: 0.0722\n",
      "Epoch 90/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0880 - val_loss: 0.0724\n",
      "Epoch 91/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0791 - val_loss: 0.0731\n",
      "Epoch 92/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0720\n",
      "Epoch 93/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - val_loss: 0.0722\n",
      "Epoch 94/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0727\n",
      "Epoch 95/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0720\n",
      "Epoch 96/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0764 - val_loss: 0.0725\n",
      "Epoch 97/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0772 - val_loss: 0.0721\n",
      "Epoch 98/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0842 - val_loss: 0.0727\n",
      "Epoch 99/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0885 - val_loss: 0.0734\n",
      "Epoch 100/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0724\n",
      "Epoch 101/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0812 - val_loss: 0.0739\n",
      "Epoch 102/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0884 - val_loss: 0.0728\n",
      "Epoch 103/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0825 - val_loss: 0.0729\n",
      "Epoch 104/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0791 - val_loss: 0.0725\n",
      "Epoch 105/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0916 - val_loss: 0.0721\n",
      "Epoch 106/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0787 - val_loss: 0.0717\n",
      "Epoch 107/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0939 - val_loss: 0.0727\n",
      "Epoch 108/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0958 - val_loss: 0.0717\n",
      "Epoch 109/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0770 - val_loss: 0.0725\n",
      "Epoch 110/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0731\n",
      "Epoch 111/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - val_loss: 0.0741\n",
      "Epoch 112/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0801 - val_loss: 0.0724\n",
      "Epoch 113/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0726\n",
      "Epoch 114/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0912 - val_loss: 0.0735\n",
      "Epoch 115/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0813 - val_loss: 0.0725\n",
      "Epoch 116/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0858 - val_loss: 0.0732\n",
      "Epoch 117/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.0724\n",
      "Epoch 118/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0850 - val_loss: 0.0725\n",
      "Epoch 119/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0799 - val_loss: 0.0731\n",
      "Epoch 120/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0863 - val_loss: 0.0722\n",
      "Epoch 121/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0791 - val_loss: 0.0723\n",
      "Epoch 122/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0862 - val_loss: 0.0724\n",
      "Epoch 123/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0720 - val_loss: 0.0728\n",
      "Epoch 124/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0869 - val_loss: 0.0731\n",
      "Epoch 125/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0802 - val_loss: 0.0728\n",
      "Epoch 126/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0885 - val_loss: 0.0727\n",
      "Epoch 127/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0726\n",
      "Epoch 128/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0722\n",
      "Epoch 129/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0856 - val_loss: 0.0721\n",
      "Epoch 130/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0727\n",
      "Epoch 131/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0726\n",
      "Epoch 132/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0849 - val_loss: 0.0725\n",
      "Epoch 133/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0784 - val_loss: 0.0724\n",
      "Epoch 134/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0920 - val_loss: 0.0723\n",
      "Epoch 135/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0773 - val_loss: 0.0721\n",
      "Epoch 136/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0744 - val_loss: 0.0732\n",
      "Epoch 137/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0774 - val_loss: 0.0723\n",
      "Epoch 138/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0717 - val_loss: 0.0728\n",
      "Epoch 139/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0686 - val_loss: 0.0727\n",
      "Epoch 140/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0765 - val_loss: 0.0720\n",
      "Epoch 141/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0854 - val_loss: 0.0727\n",
      "Epoch 142/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0871 - val_loss: 0.0724\n",
      "Epoch 143/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0839 - val_loss: 0.0730\n",
      "Epoch 144/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0860 - val_loss: 0.0723\n",
      "Epoch 145/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0839 - val_loss: 0.0721\n",
      "Epoch 146/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0715\n",
      "Epoch 147/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0808 - val_loss: 0.0722\n",
      "Epoch 148/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0798 - val_loss: 0.0720\n",
      "Epoch 149/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0904 - val_loss: 0.0722\n",
      "Epoch 150/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0781 - val_loss: 0.0731\n",
      "Epoch 151/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0868 - val_loss: 0.0728\n",
      "Epoch 152/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0785 - val_loss: 0.0720\n",
      "Epoch 153/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.0730\n",
      "Epoch 154/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0898 - val_loss: 0.0718\n",
      "Epoch 155/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0770 - val_loss: 0.0721\n",
      "Epoch 156/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0812 - val_loss: 0.0726\n",
      "Epoch 157/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0719\n",
      "Epoch 158/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0840 - val_loss: 0.0720\n",
      "Epoch 159/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - val_loss: 0.0716\n",
      "Epoch 160/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0835 - val_loss: 0.0718\n",
      "Epoch 161/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0875 - val_loss: 0.0720\n",
      "Epoch 162/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0726\n",
      "Epoch 163/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0800 - val_loss: 0.0716\n",
      "Epoch 164/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0908 - val_loss: 0.0730\n",
      "Epoch 165/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0795 - val_loss: 0.0719\n",
      "Epoch 166/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0737 - val_loss: 0.0709\n",
      "Epoch 167/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0878 - val_loss: 0.0719\n",
      "Epoch 168/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.0713\n",
      "Epoch 169/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0714\n",
      "Epoch 170/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0795 - val_loss: 0.0724\n",
      "Epoch 171/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0864 - val_loss: 0.0719\n",
      "Epoch 172/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0957 - val_loss: 0.0712\n",
      "Epoch 173/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.0718\n",
      "Epoch 174/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0768 - val_loss: 0.0724\n",
      "Epoch 175/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0722\n",
      "Epoch 176/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0794 - val_loss: 0.0714\n",
      "Epoch 177/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0819 - val_loss: 0.0716\n",
      "Epoch 178/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0752 - val_loss: 0.0720\n",
      "Epoch 179/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0713\n",
      "Epoch 180/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0792 - val_loss: 0.0718\n",
      "Epoch 181/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0821 - val_loss: 0.0712\n",
      "Epoch 182/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0717\n",
      "Epoch 183/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0875 - val_loss: 0.0718\n",
      "Epoch 184/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0723\n",
      "Epoch 185/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0779 - val_loss: 0.0718\n",
      "Epoch 186/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0813 - val_loss: 0.0721\n",
      "Epoch 187/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0811 - val_loss: 0.0721\n",
      "Epoch 188/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0718\n",
      "Epoch 189/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0839 - val_loss: 0.0712\n",
      "Epoch 190/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0719\n",
      "Epoch 191/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0719\n",
      "Epoch 192/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.0718\n",
      "Epoch 193/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0778 - val_loss: 0.0721\n",
      "Epoch 194/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0722\n",
      "Epoch 195/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0893 - val_loss: 0.0715\n",
      "Epoch 196/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0862 - val_loss: 0.0719\n",
      "Epoch 197/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0715\n",
      "Epoch 198/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0795 - val_loss: 0.0713\n",
      "Epoch 199/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0823 - val_loss: 0.0709\n",
      "Epoch 200/200\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0781 - val_loss: 0.0710\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 59.7384 - val_loss: 0.1272\n",
      "Epoch 2/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1262 - val_loss: 0.1432\n",
      "Epoch 3/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7163 - val_loss: 0.1177\n",
      "Epoch 4/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4416 - val_loss: 0.0770\n",
      "Epoch 5/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2651 - val_loss: 0.0757\n",
      "Epoch 6/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2107 - val_loss: 0.0755\n",
      "Epoch 7/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1757 - val_loss: 0.0741\n",
      "Epoch 8/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1664 - val_loss: 0.0732\n",
      "Epoch 9/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1218 - val_loss: 0.0724\n",
      "Epoch 10/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1236 - val_loss: 0.0721\n",
      "Epoch 11/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1082 - val_loss: 0.0728\n",
      "Epoch 12/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1023 - val_loss: 0.0732\n",
      "Epoch 13/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0907 - val_loss: 0.0727\n",
      "Epoch 14/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0922 - val_loss: 0.0730\n",
      "Epoch 15/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0885 - val_loss: 0.0718\n",
      "Epoch 16/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0876 - val_loss: 0.0718\n",
      "Epoch 17/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0778 - val_loss: 0.0723\n",
      "Epoch 18/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0823 - val_loss: 0.0724\n",
      "Epoch 19/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0896 - val_loss: 0.0708\n",
      "Epoch 20/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0760 - val_loss: 0.0711\n",
      "Epoch 21/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0802 - val_loss: 0.0704\n",
      "Epoch 22/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0917 - val_loss: 0.0703\n",
      "Epoch 23/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0718 - val_loss: 0.0725\n",
      "Epoch 24/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0837 - val_loss: 0.0701\n",
      "Epoch 25/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0917 - val_loss: 0.0708\n",
      "Epoch 26/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0814 - val_loss: 0.0706\n",
      "Epoch 27/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0827 - val_loss: 0.0705\n",
      "Epoch 28/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0872 - val_loss: 0.0704\n",
      "Epoch 29/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0701\n",
      "Epoch 30/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0747 - val_loss: 0.0706\n",
      "Epoch 31/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0778 - val_loss: 0.0710\n",
      "Epoch 32/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0865 - val_loss: 0.0708\n",
      "Epoch 33/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.0706\n",
      "Epoch 34/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0844 - val_loss: 0.0712\n",
      "Epoch 35/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0839 - val_loss: 0.0737\n",
      "Epoch 36/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0849 - val_loss: 0.0738\n",
      "Epoch 37/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0818 - val_loss: 0.0734\n",
      "Epoch 38/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0738\n",
      "Epoch 39/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0857 - val_loss: 0.0730\n",
      "Epoch 40/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0817 - val_loss: 0.0727\n",
      "Epoch 41/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.0733\n",
      "Epoch 42/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0751 - val_loss: 0.0732\n",
      "Epoch 43/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0851 - val_loss: 0.0730\n",
      "Epoch 44/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0898 - val_loss: 0.0726\n",
      "Epoch 45/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0818 - val_loss: 0.0732\n",
      "Epoch 46/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0956 - val_loss: 0.0730\n",
      "Epoch 47/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0866 - val_loss: 0.0732\n",
      "Epoch 48/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0799 - val_loss: 0.0727\n",
      "Epoch 49/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0888 - val_loss: 0.0729\n",
      "Epoch 50/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0775 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0846 - val_loss: 0.0725\n",
      "Epoch 52/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0770 - val_loss: 0.0725\n",
      "Epoch 53/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0781 - val_loss: 0.0729\n",
      "Epoch 54/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.0726\n",
      "Epoch 55/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0777 - val_loss: 0.0729\n",
      "Epoch 56/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0893 - val_loss: 0.0723\n",
      "Epoch 57/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0743 - val_loss: 0.0723\n",
      "Epoch 58/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0856 - val_loss: 0.0728\n",
      "Epoch 59/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0883 - val_loss: 0.0722\n",
      "Epoch 60/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0722\n",
      "Epoch 61/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0856 - val_loss: 0.0726\n",
      "Epoch 62/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0915 - val_loss: 0.0724\n",
      "Epoch 63/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0772 - val_loss: 0.0716\n",
      "Epoch 64/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0843 - val_loss: 0.0718\n",
      "Epoch 65/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0804 - val_loss: 0.0718\n",
      "Epoch 66/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0868 - val_loss: 0.0722\n",
      "Epoch 67/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0760 - val_loss: 0.0721\n",
      "Epoch 68/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.0722\n",
      "Epoch 69/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0802 - val_loss: 0.0717\n",
      "Epoch 70/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0784 - val_loss: 0.0726\n",
      "Epoch 71/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0859 - val_loss: 0.0724\n",
      "Epoch 72/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0832 - val_loss: 0.0721\n",
      "Epoch 73/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0892 - val_loss: 0.0728\n",
      "Epoch 74/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0808 - val_loss: 0.0722\n",
      "Epoch 75/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0720\n",
      "Epoch 76/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0803 - val_loss: 0.0721\n",
      "Epoch 77/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0780 - val_loss: 0.0718\n",
      "Epoch 78/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0806 - val_loss: 0.0727\n",
      "Epoch 79/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0951 - val_loss: 0.0712\n",
      "Epoch 80/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.0727\n",
      "Epoch 81/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0851 - val_loss: 0.0720\n",
      "Epoch 82/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0810 - val_loss: 0.0722\n",
      "Epoch 83/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0920 - val_loss: 0.0721\n",
      "Epoch 84/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0811 - val_loss: 0.0717\n",
      "Epoch 85/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.0722\n",
      "Epoch 86/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 0.0727\n",
      "Epoch 87/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0845 - val_loss: 0.0719\n",
      "Epoch 88/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0834 - val_loss: 0.0716\n",
      "Epoch 89/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0814 - val_loss: 0.0718\n",
      "Epoch 90/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0732\n",
      "Epoch 91/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0799 - val_loss: 0.0721\n",
      "Epoch 92/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0848 - val_loss: 0.0718\n",
      "Epoch 93/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0716 - val_loss: 0.0723\n",
      "Epoch 94/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0857 - val_loss: 0.0726\n",
      "Epoch 95/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0839 - val_loss: 0.0723\n",
      "Epoch 96/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0960 - val_loss: 0.0727\n",
      "Epoch 97/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0758 - val_loss: 0.0732\n",
      "Epoch 98/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0801 - val_loss: 0.0719\n",
      "Epoch 99/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0762 - val_loss: 0.0720\n",
      "Epoch 100/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0789 - val_loss: 0.0721\n",
      "Epoch 101/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: 0.0715\n",
      "Epoch 102/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0808 - val_loss: 0.0716\n",
      "Epoch 103/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0855 - val_loss: 0.0721\n",
      "Epoch 104/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0882 - val_loss: 0.0723\n",
      "Epoch 105/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0817 - val_loss: 0.0723\n",
      "Epoch 106/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0782 - val_loss: 0.0728\n",
      "Epoch 107/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0874 - val_loss: 0.0716\n",
      "Epoch 108/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0864 - val_loss: 0.0717\n",
      "Epoch 109/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0890 - val_loss: 0.0721\n",
      "Epoch 110/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0822 - val_loss: 0.0718\n",
      "Epoch 111/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0810 - val_loss: 0.0727\n",
      "Epoch 112/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0827 - val_loss: 0.0725\n",
      "Epoch 113/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0939 - val_loss: 0.0722\n",
      "Epoch 114/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0817 - val_loss: 0.0725\n",
      "Epoch 115/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0772 - val_loss: 0.0727\n",
      "Epoch 116/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0768 - val_loss: 0.0725\n",
      "Epoch 117/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0776 - val_loss: 0.0725\n",
      "Epoch 118/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0773 - val_loss: 0.0712\n",
      "Epoch 119/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0822 - val_loss: 0.0720\n",
      "Epoch 120/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0912 - val_loss: 0.0729\n",
      "Epoch 121/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0751 - val_loss: 0.0721\n",
      "Epoch 122/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0843 - val_loss: 0.0726\n",
      "Epoch 123/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0730\n",
      "Epoch 124/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0847 - val_loss: 0.0720\n",
      "Epoch 125/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0859 - val_loss: 0.0719\n",
      "Epoch 126/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0722\n",
      "Epoch 127/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0909 - val_loss: 0.0712\n",
      "Epoch 128/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0912 - val_loss: 0.0724\n",
      "Epoch 129/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1634s\u001b[0m 26s/step - loss: 0.0785 - val_loss: 0.0725\n",
      "Epoch 130/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0910 - val_loss: 0.0720\n",
      "Epoch 131/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0964 - val_loss: 0.0716\n",
      "Epoch 132/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0849 - val_loss: 0.0723\n",
      "Epoch 133/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0910 - val_loss: 0.0714\n",
      "Epoch 134/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 0.0826 - val_loss: 0.0717\n",
      "Epoch 135/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.0756 - val_loss: 0.0726\n",
      "Epoch 136/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0795 - val_loss: 0.0715\n",
      "Epoch 137/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0823 - val_loss: 0.0719\n",
      "Epoch 138/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.0777 - val_loss: 0.0723\n",
      "Epoch 139/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - loss: 0.0942 - val_loss: 0.0725\n",
      "Epoch 140/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - loss: 0.0803 - val_loss: 0.0728\n",
      "Epoch 141/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0828 - val_loss: 0.0725\n",
      "Epoch 142/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0796 - val_loss: 0.0732\n",
      "Epoch 143/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0814 - val_loss: 0.0725\n",
      "Epoch 144/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0827 - val_loss: 0.0711\n",
      "Epoch 145/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 146/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0880 - val_loss: 0.0725\n",
      "Epoch 147/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0797 - val_loss: 0.0721\n",
      "Epoch 148/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0813 - val_loss: 0.0717\n",
      "Epoch 149/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0825 - val_loss: 0.0729\n",
      "Epoch 150/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0764 - val_loss: 0.0715\n",
      "Epoch 151/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0798 - val_loss: 0.0728\n",
      "Epoch 152/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0887 - val_loss: 0.0723\n",
      "Epoch 153/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0749 - val_loss: 0.0723\n",
      "Epoch 154/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 155/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0860 - val_loss: 0.0715\n",
      "Epoch 156/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0740 - val_loss: 0.0716\n",
      "Epoch 157/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0902 - val_loss: 0.0711\n",
      "Epoch 158/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0805 - val_loss: 0.0718\n",
      "Epoch 159/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0890 - val_loss: 0.0722\n",
      "Epoch 160/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0726\n",
      "Epoch 161/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0789 - val_loss: 0.0727\n",
      "Epoch 162/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0853 - val_loss: 0.0713\n",
      "Epoch 163/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0855 - val_loss: 0.0714\n",
      "Epoch 164/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0814 - val_loss: 0.0725\n",
      "Epoch 165/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0771 - val_loss: 0.0722\n",
      "Epoch 166/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0771 - val_loss: 0.0718\n",
      "Epoch 167/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0852 - val_loss: 0.0718\n",
      "Epoch 168/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0760 - val_loss: 0.0722\n",
      "Epoch 169/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0799 - val_loss: 0.0714\n",
      "Epoch 170/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0819 - val_loss: 0.0713\n",
      "Epoch 171/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0768 - val_loss: 0.0726\n",
      "Epoch 172/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0759 - val_loss: 0.0719\n",
      "Epoch 173/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.0739\n",
      "Epoch 174/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0837 - val_loss: 0.0716\n",
      "Epoch 175/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0809 - val_loss: 0.0715\n",
      "Epoch 176/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0717\n",
      "Epoch 177/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0792 - val_loss: 0.0721\n",
      "Epoch 178/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0774 - val_loss: 0.0720\n",
      "Epoch 179/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0962 - val_loss: 0.0716\n",
      "Epoch 180/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0866 - val_loss: 0.0715\n",
      "Epoch 181/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0840 - val_loss: 0.0724\n",
      "Epoch 182/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0836 - val_loss: 0.0717\n",
      "Epoch 183/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0813 - val_loss: 0.0710\n",
      "Epoch 184/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0830 - val_loss: 0.0719\n",
      "Epoch 185/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0871 - val_loss: 0.0715\n",
      "Epoch 186/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0787 - val_loss: 0.0724\n",
      "Epoch 187/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.0713\n",
      "Epoch 188/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0884 - val_loss: 0.0717\n",
      "Epoch 189/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0828 - val_loss: 0.0715\n",
      "Epoch 190/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0819 - val_loss: 0.0710\n",
      "Epoch 191/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0872 - val_loss: 0.0719\n",
      "Epoch 192/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0808 - val_loss: 0.0711\n",
      "Epoch 193/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0794 - val_loss: 0.0715\n",
      "Epoch 194/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0862 - val_loss: 0.0717\n",
      "Epoch 195/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0856 - val_loss: 0.0721\n",
      "Epoch 196/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0849 - val_loss: 0.0716\n",
      "Epoch 197/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0776 - val_loss: 0.0713\n",
      "Epoch 198/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0845 - val_loss: 0.0717\n",
      "Epoch 199/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 0.0712\n",
      "Epoch 200/200\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0804 - val_loss: 0.0716\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 105.4401 - val_loss: 0.1456\n",
      "Epoch 2/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2634 - val_loss: 0.1058\n",
      "Epoch 3/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5141 - val_loss: 0.1415\n",
      "Epoch 4/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9261 - val_loss: 0.0843\n",
      "Epoch 5/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5959 - val_loss: 0.1018\n",
      "Epoch 6/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4447 - val_loss: 0.0847\n",
      "Epoch 7/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3250 - val_loss: 0.0858\n",
      "Epoch 8/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2577 - val_loss: 0.0773\n",
      "Epoch 9/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2333 - val_loss: 0.0765\n",
      "Epoch 10/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1848 - val_loss: 0.0740\n",
      "Epoch 11/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1590 - val_loss: 0.0761\n",
      "Epoch 12/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1502 - val_loss: 0.0788\n",
      "Epoch 13/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1284 - val_loss: 0.0727\n",
      "Epoch 14/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1038 - val_loss: 0.0728\n",
      "Epoch 15/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1110 - val_loss: 0.0717\n",
      "Epoch 16/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0987 - val_loss: 0.0744\n",
      "Epoch 17/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0898 - val_loss: 0.0724\n",
      "Epoch 18/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0920 - val_loss: 0.0724\n",
      "Epoch 19/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0878 - val_loss: 0.0717\n",
      "Epoch 20/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 21/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0885 - val_loss: 0.0725\n",
      "Epoch 22/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0884 - val_loss: 0.0726\n",
      "Epoch 23/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0887 - val_loss: 0.0718\n",
      "Epoch 24/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0745 - val_loss: 0.0728\n",
      "Epoch 25/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0828 - val_loss: 0.0714\n",
      "Epoch 26/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0787 - val_loss: 0.0712\n",
      "Epoch 27/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0710\n",
      "Epoch 28/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0711\n",
      "Epoch 29/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0762 - val_loss: 0.0712\n",
      "Epoch 30/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0738 - val_loss: 0.0716\n",
      "Epoch 31/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.0708\n",
      "Epoch 32/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0940 - val_loss: 0.0713\n",
      "Epoch 33/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0732\n",
      "Epoch 34/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0805 - val_loss: 0.0729\n",
      "Epoch 35/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0818 - val_loss: 0.0711\n",
      "Epoch 36/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0715\n",
      "Epoch 37/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0846 - val_loss: 0.0716\n",
      "Epoch 38/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0819 - val_loss: 0.0739\n",
      "Epoch 39/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0777 - val_loss: 0.0736\n",
      "Epoch 40/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0733\n",
      "Epoch 41/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0875 - val_loss: 0.0733\n",
      "Epoch 42/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0735\n",
      "Epoch 43/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0788 - val_loss: 0.0733\n",
      "Epoch 44/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0817 - val_loss: 0.0734\n",
      "Epoch 45/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0760 - val_loss: 0.0730\n",
      "Epoch 46/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0877 - val_loss: 0.0730\n",
      "Epoch 47/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0822 - val_loss: 0.0730\n",
      "Epoch 48/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0781 - val_loss: 0.0729\n",
      "Epoch 49/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0761 - val_loss: 0.0732\n",
      "Epoch 50/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0863 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0781 - val_loss: 0.0725\n",
      "Epoch 52/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.0724\n",
      "Epoch 53/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0726\n",
      "Epoch 54/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0780 - val_loss: 0.0730\n",
      "Epoch 55/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0911 - val_loss: 0.0727\n",
      "Epoch 56/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0726\n",
      "Epoch 57/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0814 - val_loss: 0.0723\n",
      "Epoch 58/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0924 - val_loss: 0.0723\n",
      "Epoch 59/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0723\n",
      "Epoch 60/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0920 - val_loss: 0.0723\n",
      "Epoch 61/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0782 - val_loss: 0.0724\n",
      "Epoch 62/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0813 - val_loss: 0.0723\n",
      "Epoch 63/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0882 - val_loss: 0.0724\n",
      "Epoch 64/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0868 - val_loss: 0.0720\n",
      "Epoch 65/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0765 - val_loss: 0.0722\n",
      "Epoch 66/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0827 - val_loss: 0.0725\n",
      "Epoch 67/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - val_loss: 0.0734\n",
      "Epoch 68/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0763 - val_loss: 0.0721\n",
      "Epoch 69/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0752 - val_loss: 0.0736\n",
      "Epoch 70/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0791 - val_loss: 0.0724\n",
      "Epoch 71/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.0719\n",
      "Epoch 72/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0887 - val_loss: 0.0718\n",
      "Epoch 73/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0861 - val_loss: 0.0726\n",
      "Epoch 74/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0865 - val_loss: 0.0727\n",
      "Epoch 75/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0781 - val_loss: 0.0723\n",
      "Epoch 76/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0859 - val_loss: 0.0717\n",
      "Epoch 77/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0810 - val_loss: 0.0718\n",
      "Epoch 78/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0917 - val_loss: 0.0719\n",
      "Epoch 79/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0853 - val_loss: 0.0720\n",
      "Epoch 80/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0813 - val_loss: 0.0722\n",
      "Epoch 81/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0784 - val_loss: 0.0722\n",
      "Epoch 82/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0714\n",
      "Epoch 83/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0881 - val_loss: 0.0725\n",
      "Epoch 84/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0810 - val_loss: 0.0717\n",
      "Epoch 85/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0782 - val_loss: 0.0720\n",
      "Epoch 86/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0804 - val_loss: 0.0723\n",
      "Epoch 87/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0886 - val_loss: 0.0711\n",
      "Epoch 88/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0777 - val_loss: 0.0723\n",
      "Epoch 89/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0806 - val_loss: 0.0731\n",
      "Epoch 90/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0798 - val_loss: 0.0721\n",
      "Epoch 91/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0909 - val_loss: 0.0725\n",
      "Epoch 92/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0811 - val_loss: 0.0720\n",
      "Epoch 93/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0712\n",
      "Epoch 94/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0873 - val_loss: 0.0721\n",
      "Epoch 95/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0836 - val_loss: 0.0726\n",
      "Epoch 96/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0764 - val_loss: 0.0721\n",
      "Epoch 97/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0722\n",
      "Epoch 98/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0797 - val_loss: 0.0719\n",
      "Epoch 99/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.0719\n",
      "Epoch 100/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0810 - val_loss: 0.0717\n",
      "Epoch 101/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0908 - val_loss: 0.0712\n",
      "Epoch 102/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0809 - val_loss: 0.0718\n",
      "Epoch 103/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0818 - val_loss: 0.0721\n",
      "Epoch 104/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0756 - val_loss: 0.0724\n",
      "Epoch 105/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0792 - val_loss: 0.0725\n",
      "Epoch 106/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.0718\n",
      "Epoch 107/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0714\n",
      "Epoch 108/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0766 - val_loss: 0.0719\n",
      "Epoch 109/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0810 - val_loss: 0.0716\n",
      "Epoch 110/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0793 - val_loss: 0.0720\n",
      "Epoch 111/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0859 - val_loss: 0.0721\n",
      "Epoch 112/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0860 - val_loss: 0.0721\n",
      "Epoch 113/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - val_loss: 0.0719\n",
      "Epoch 114/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.0715\n",
      "Epoch 115/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0885 - val_loss: 0.0716\n",
      "Epoch 116/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0893 - val_loss: 0.0716\n",
      "Epoch 117/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0868 - val_loss: 0.0716\n",
      "Epoch 118/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0774 - val_loss: 0.0717\n",
      "Epoch 119/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0846 - val_loss: 0.0708\n",
      "Epoch 120/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0873 - val_loss: 0.0723\n",
      "Epoch 121/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0714\n",
      "Epoch 122/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0881 - val_loss: 0.0720\n",
      "Epoch 123/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.0707\n",
      "Epoch 124/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0799 - val_loss: 0.0711\n",
      "Epoch 125/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0847 - val_loss: 0.0710\n",
      "Epoch 126/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0849 - val_loss: 0.0719\n",
      "Epoch 127/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - val_loss: 0.0715\n",
      "Epoch 128/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0825 - val_loss: 0.0721\n",
      "Epoch 129/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - val_loss: 0.0720\n",
      "Epoch 130/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0873 - val_loss: 0.0716\n",
      "Epoch 131/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0875 - val_loss: 0.0723\n",
      "Epoch 132/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0834 - val_loss: 0.0725\n",
      "Epoch 133/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0789 - val_loss: 0.0713\n",
      "Epoch 134/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0720\n",
      "Epoch 135/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - val_loss: 0.0714\n",
      "Epoch 136/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0788 - val_loss: 0.0723\n",
      "Epoch 137/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0758 - val_loss: 0.0710\n",
      "Epoch 138/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0880 - val_loss: 0.0711\n",
      "Epoch 139/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0921 - val_loss: 0.0713\n",
      "Epoch 140/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0717\n",
      "Epoch 141/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0807 - val_loss: 0.0707\n",
      "Epoch 142/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: 0.0713\n",
      "Epoch 143/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0848 - val_loss: 0.0715\n",
      "Epoch 144/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0720\n",
      "Epoch 145/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0777 - val_loss: 0.0766\n",
      "Epoch 146/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0861 - val_loss: 0.0723\n",
      "Epoch 147/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0917 - val_loss: 0.0717\n",
      "Epoch 148/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0736 - val_loss: 0.0721\n",
      "Epoch 149/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0866 - val_loss: 0.0721\n",
      "Epoch 150/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0792 - val_loss: 0.0711\n",
      "Epoch 151/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0882 - val_loss: 0.0716\n",
      "Epoch 152/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.0715\n",
      "Epoch 153/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0858 - val_loss: 0.0720\n",
      "Epoch 154/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0857 - val_loss: 0.0718\n",
      "Epoch 155/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0838 - val_loss: 0.0711\n",
      "Epoch 156/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0736 - val_loss: 0.0723\n",
      "Epoch 157/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0785 - val_loss: 0.0712\n",
      "Epoch 158/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0861 - val_loss: 0.0726\n",
      "Epoch 159/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0867 - val_loss: 0.0717\n",
      "Epoch 160/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0749 - val_loss: 0.0708\n",
      "Epoch 161/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0763 - val_loss: 0.0720\n",
      "Epoch 162/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0833 - val_loss: 0.0723\n",
      "Epoch 163/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0746 - val_loss: 0.0718\n",
      "Epoch 164/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0856 - val_loss: 0.0729\n",
      "Epoch 165/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0790 - val_loss: 0.0720\n",
      "Epoch 166/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0711\n",
      "Epoch 167/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0814 - val_loss: 0.0718\n",
      "Epoch 168/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0750 - val_loss: 0.0717\n",
      "Epoch 169/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0745 - val_loss: 0.0720\n",
      "Epoch 170/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0831 - val_loss: 0.0714\n",
      "Epoch 171/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 0.0708\n",
      "Epoch 172/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0806 - val_loss: 0.0712\n",
      "Epoch 173/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0806 - val_loss: 0.0716\n",
      "Epoch 174/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 175/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0872 - val_loss: 0.0726\n",
      "Epoch 176/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0850 - val_loss: 0.0720\n",
      "Epoch 177/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0857 - val_loss: 0.0716\n",
      "Epoch 178/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0722\n",
      "Epoch 179/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.0729\n",
      "Epoch 180/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0875 - val_loss: 0.0718\n",
      "Epoch 181/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0815 - val_loss: 0.0707\n",
      "Epoch 182/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0921 - val_loss: 0.0722\n",
      "Epoch 183/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0712\n",
      "Epoch 184/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0719\n",
      "Epoch 185/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0709\n",
      "Epoch 186/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0973\n",
      "Epoch 187/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0820 - val_loss: 0.0724\n",
      "Epoch 188/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0717\n",
      "Epoch 189/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0753 - val_loss: 0.0715\n",
      "Epoch 190/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0834 - val_loss: 0.0710\n",
      "Epoch 191/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0858 - val_loss: 0.0714\n",
      "Epoch 192/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0838 - val_loss: 0.0707\n",
      "Epoch 193/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0716\n",
      "Epoch 194/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0709\n",
      "Epoch 195/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0798 - val_loss: 0.0749\n",
      "Epoch 196/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0767 - val_loss: 0.0721\n",
      "Epoch 197/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0765 - val_loss: 0.0717\n",
      "Epoch 198/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0723\n",
      "Epoch 199/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0818 - val_loss: 0.0714\n",
      "Epoch 200/200\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0729 - val_loss: 0.0720\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 220.9115 - val_loss: 0.2303\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2927 - val_loss: 0.1124\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3054 - val_loss: 0.1008\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9408 - val_loss: 0.0929\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2423 - val_loss: 0.1246\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9699 - val_loss: 0.0848\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6417 - val_loss: 0.0868\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4818 - val_loss: 0.0887\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3274 - val_loss: 0.0838\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2336 - val_loss: 0.0813\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1450 - val_loss: 0.0806\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1320 - val_loss: 0.0773\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1043 - val_loss: 0.0781\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0977 - val_loss: 0.0774\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0964 - val_loss: 0.0774\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0780 - val_loss: 0.0765\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1030 - val_loss: 0.0754\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0934 - val_loss: 0.0747\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0874 - val_loss: 0.0746\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0881 - val_loss: 0.0744\n",
      "Epoch 21/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0741\n",
      "Epoch 22/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0882 - val_loss: 0.0743\n",
      "Epoch 23/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.0724\n",
      "Epoch 24/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0804 - val_loss: 0.0728\n",
      "Epoch 25/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0836 - val_loss: 0.0726\n",
      "Epoch 26/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0744 - val_loss: 0.0719\n",
      "Epoch 27/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0924 - val_loss: 0.0723\n",
      "Epoch 28/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0930 - val_loss: 0.0718\n",
      "Epoch 29/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0848 - val_loss: 0.0718\n",
      "Epoch 30/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0725\n",
      "Epoch 31/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0715\n",
      "Epoch 32/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0873 - val_loss: 0.0712\n",
      "Epoch 33/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0765 - val_loss: 0.0729\n",
      "Epoch 34/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 35/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0831 - val_loss: 0.0713\n",
      "Epoch 36/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0815 - val_loss: 0.0718\n",
      "Epoch 37/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0742 - val_loss: 0.0710\n",
      "Epoch 38/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - val_loss: 0.0714\n",
      "Epoch 39/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0836 - val_loss: 0.0710\n",
      "Epoch 41/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0810 - val_loss: 0.0712\n",
      "Epoch 42/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0838 - val_loss: 0.0717\n",
      "Epoch 43/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0708\n",
      "Epoch 44/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0805 - val_loss: 0.0715\n",
      "Epoch 45/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0840 - val_loss: 0.0710\n",
      "Epoch 46/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0828 - val_loss: 0.0719\n",
      "Epoch 47/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0805 - val_loss: 0.0711\n",
      "Epoch 48/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0709\n",
      "Epoch 49/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0740 - val_loss: 0.0715\n",
      "Epoch 50/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0809 - val_loss: 0.0712\n",
      "Epoch 51/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0771 - val_loss: 0.0734\n",
      "Epoch 52/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0712\n",
      "Epoch 53/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0803 - val_loss: 0.0708\n",
      "Epoch 54/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 55/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0795 - val_loss: 0.0722\n",
      "Epoch 56/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0817 - val_loss: 0.0712\n",
      "Epoch 57/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0801 - val_loss: 0.0708\n",
      "Epoch 58/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0808 - val_loss: 0.0717\n",
      "Epoch 59/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0727 - val_loss: 0.0737\n",
      "Epoch 60/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0849 - val_loss: 0.0708\n",
      "Epoch 61/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0878 - val_loss: 0.0710\n",
      "Epoch 62/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0816 - val_loss: 0.0718\n",
      "Epoch 63/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0781 - val_loss: 0.0715\n",
      "Epoch 64/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0846 - val_loss: 0.0708\n",
      "Epoch 65/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0852 - val_loss: 0.0707\n",
      "Epoch 66/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0916 - val_loss: 0.0730\n",
      "Epoch 67/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0918 - val_loss: 0.0728\n",
      "Epoch 68/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0832 - val_loss: 0.0724\n",
      "Epoch 69/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0830 - val_loss: 0.0729\n",
      "Epoch 70/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0733\n",
      "Epoch 71/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0943 - val_loss: 0.0724\n",
      "Epoch 72/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0871 - val_loss: 0.0720\n",
      "Epoch 73/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0810 - val_loss: 0.0722\n",
      "Epoch 74/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: 0.0727\n",
      "Epoch 75/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0771 - val_loss: 0.0723\n",
      "Epoch 76/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0724\n",
      "Epoch 77/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0832 - val_loss: 0.0723\n",
      "Epoch 78/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 79/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0849 - val_loss: 0.0725\n",
      "Epoch 80/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0861 - val_loss: 0.0722\n",
      "Epoch 81/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0794 - val_loss: 0.0718\n",
      "Epoch 82/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0886 - val_loss: 0.0719\n",
      "Epoch 83/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0813 - val_loss: 0.0726\n",
      "Epoch 84/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0865 - val_loss: 0.0720\n",
      "Epoch 85/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0877 - val_loss: 0.0723\n",
      "Epoch 86/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0838 - val_loss: 0.0724\n",
      "Epoch 87/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0877 - val_loss: 0.0720\n",
      "Epoch 88/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0885 - val_loss: 0.0719\n",
      "Epoch 89/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0893 - val_loss: 0.0722\n",
      "Epoch 90/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0806 - val_loss: 0.0719\n",
      "Epoch 91/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0877 - val_loss: 0.0720\n",
      "Epoch 92/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0719\n",
      "Epoch 93/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0809 - val_loss: 0.0717\n",
      "Epoch 94/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0813 - val_loss: 0.0723\n",
      "Epoch 95/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0823 - val_loss: 0.0726\n",
      "Epoch 96/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0822 - val_loss: 0.0724\n",
      "Epoch 97/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0726\n",
      "Epoch 98/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0724\n",
      "Epoch 99/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0816 - val_loss: 0.0723\n",
      "Epoch 100/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0805 - val_loss: 0.0724\n",
      "Epoch 101/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - val_loss: 0.0720\n",
      "Epoch 102/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0722\n",
      "Epoch 103/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0799 - val_loss: 0.0717\n",
      "Epoch 104/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0718\n",
      "Epoch 105/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0862 - val_loss: 0.0719\n",
      "Epoch 106/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0883 - val_loss: 0.0726\n",
      "Epoch 107/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0728\n",
      "Epoch 108/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0728\n",
      "Epoch 109/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0726\n",
      "Epoch 110/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0844 - val_loss: 0.0721\n",
      "Epoch 111/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 0.0722\n",
      "Epoch 112/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0890 - val_loss: 0.0726\n",
      "Epoch 113/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - val_loss: 0.0726\n",
      "Epoch 114/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0724\n",
      "Epoch 115/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 116/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0761 - val_loss: 0.0723\n",
      "Epoch 117/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0868 - val_loss: 0.0723\n",
      "Epoch 118/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0823 - val_loss: 0.0722\n",
      "Epoch 119/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0833 - val_loss: 0.0723\n",
      "Epoch 120/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0852 - val_loss: 0.0722\n",
      "Epoch 121/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 122/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0770 - val_loss: 0.0724\n",
      "Epoch 123/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.0719\n",
      "Epoch 124/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.0716\n",
      "Epoch 125/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0769 - val_loss: 0.0719\n",
      "Epoch 126/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0715\n",
      "Epoch 127/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.0721\n",
      "Epoch 128/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0792 - val_loss: 0.0722\n",
      "Epoch 129/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0830 - val_loss: 0.0723\n",
      "Epoch 130/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0876 - val_loss: 0.0720\n",
      "Epoch 131/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0881 - val_loss: 0.0718\n",
      "Epoch 132/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0879 - val_loss: 0.0723\n",
      "Epoch 133/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0883 - val_loss: 0.0727\n",
      "Epoch 134/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0720\n",
      "Epoch 135/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - val_loss: 0.0718\n",
      "Epoch 136/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0827 - val_loss: 0.0726\n",
      "Epoch 137/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0879 - val_loss: 0.0721\n",
      "Epoch 138/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0878 - val_loss: 0.0717\n",
      "Epoch 139/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0779 - val_loss: 0.0721\n",
      "Epoch 140/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0761 - val_loss: 0.0719\n",
      "Epoch 141/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0852 - val_loss: 0.0721\n",
      "Epoch 142/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0777 - val_loss: 0.0721\n",
      "Epoch 143/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0780 - val_loss: 0.0721\n",
      "Epoch 144/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0877 - val_loss: 0.0721\n",
      "Epoch 145/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0801 - val_loss: 0.0719\n",
      "Epoch 146/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0838 - val_loss: 0.0720\n",
      "Epoch 147/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0784 - val_loss: 0.0716\n",
      "Epoch 148/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0872 - val_loss: 0.0730\n",
      "Epoch 149/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0773 - val_loss: 0.0723\n",
      "Epoch 150/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0986 - val_loss: 0.0722\n",
      "Epoch 151/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0855 - val_loss: 0.0718\n",
      "Epoch 152/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0809 - val_loss: 0.0719\n",
      "Epoch 153/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0820 - val_loss: 0.0718\n",
      "Epoch 154/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0819 - val_loss: 0.0717\n",
      "Epoch 155/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0815 - val_loss: 0.0719\n",
      "Epoch 156/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0820 - val_loss: 0.0719\n",
      "Epoch 157/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0723\n",
      "Epoch 158/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - val_loss: 0.0717\n",
      "Epoch 159/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0775 - val_loss: 0.0717\n",
      "Epoch 160/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - val_loss: 0.0717\n",
      "Epoch 161/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0881 - val_loss: 0.0714\n",
      "Epoch 162/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0875 - val_loss: 0.0721\n",
      "Epoch 163/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0801 - val_loss: 0.0720\n",
      "Epoch 164/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0774 - val_loss: 0.0731\n",
      "Epoch 165/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0728\n",
      "Epoch 166/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - val_loss: 0.0719\n",
      "Epoch 167/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0788 - val_loss: 0.0721\n",
      "Epoch 168/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0873 - val_loss: 0.0714\n",
      "Epoch 169/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0778 - val_loss: 0.0721\n",
      "Epoch 170/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0896 - val_loss: 0.0719\n",
      "Epoch 171/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0791 - val_loss: 0.0729\n",
      "Epoch 172/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0773 - val_loss: 0.0719\n",
      "Epoch 173/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0768 - val_loss: 0.0721\n",
      "Epoch 174/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0719\n",
      "Epoch 175/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 176/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0775 - val_loss: 0.0718\n",
      "Epoch 177/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0790 - val_loss: 0.0720\n",
      "Epoch 178/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0792 - val_loss: 0.0724\n",
      "Epoch 179/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0759 - val_loss: 0.0718\n",
      "Epoch 180/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0796 - val_loss: 0.0718\n",
      "Epoch 181/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0847 - val_loss: 0.0715\n",
      "Epoch 182/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1007 - val_loss: 0.0716\n",
      "Epoch 183/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0825 - val_loss: 0.0713\n",
      "Epoch 184/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0876 - val_loss: 0.0714\n",
      "Epoch 185/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0832 - val_loss: 0.0716\n",
      "Epoch 186/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0765 - val_loss: 0.0719\n",
      "Epoch 187/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0795 - val_loss: 0.0716\n",
      "Epoch 188/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0862 - val_loss: 0.0713\n",
      "Epoch 189/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.0717\n",
      "Epoch 190/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0879 - val_loss: 0.0720\n",
      "Epoch 191/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.0716\n",
      "Epoch 192/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0918 - val_loss: 0.0720\n",
      "Epoch 193/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0783 - val_loss: 0.0721\n",
      "Epoch 194/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0808 - val_loss: 0.0720\n",
      "Epoch 195/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0703 - val_loss: 0.0727\n",
      "Epoch 196/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0767 - val_loss: 0.0716\n",
      "Epoch 197/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0822 - val_loss: 0.0719\n",
      "Epoch 198/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0814 - val_loss: 0.0715\n",
      "Epoch 199/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0871 - val_loss: 0.0721\n",
      "Epoch 200/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.0719\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 277.3543 - val_loss: 0.3068\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0644 - val_loss: 0.5318\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2989 - val_loss: 0.1465\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9433 - val_loss: 0.1014\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5932 - val_loss: 0.1051\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1815 - val_loss: 0.0937\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9248 - val_loss: 0.0909\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8844 - val_loss: 0.1182\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6454 - val_loss: 0.1092\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6377 - val_loss: 0.0830\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5150 - val_loss: 0.0897\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4183 - val_loss: 0.0822\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4287 - val_loss: 0.0788\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3508 - val_loss: 0.0799\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3401 - val_loss: 0.0766\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3262 - val_loss: 0.0768\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2773 - val_loss: 0.0755\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2897 - val_loss: 0.0748\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2263 - val_loss: 0.0752\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1991 - val_loss: 0.0818\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1928 - val_loss: 0.0742\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1699 - val_loss: 0.0731\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1540 - val_loss: 0.0727\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1325 - val_loss: 0.0720\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1102 - val_loss: 0.0720\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1125 - val_loss: 0.0714\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1048 - val_loss: 0.0714\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0922 - val_loss: 0.0715\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0940 - val_loss: 0.0710\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0901 - val_loss: 0.0711\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0851 - val_loss: 0.0714\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0717\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - val_loss: 0.0719\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0840 - val_loss: 0.0714\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.0714\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0868 - val_loss: 0.0719\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0721\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0949 - val_loss: 0.0717\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0854 - val_loss: 0.0717\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0717\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0770 - val_loss: 0.0718\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.0718\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0884 - val_loss: 0.0715\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0865 - val_loss: 0.0713\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - val_loss: 0.0718\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0884 - val_loss: 0.0712\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0807 - val_loss: 0.0712\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0868 - val_loss: 0.0717\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0754 - val_loss: 0.0717\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0854 - val_loss: 0.0714\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0866 - val_loss: 0.0718\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0715\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0712\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0805 - val_loss: 0.0707\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0809 - val_loss: 0.0710\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.0713\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0832 - val_loss: 0.0716\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0890 - val_loss: 0.0714\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0885 - val_loss: 0.0712\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0838 - val_loss: 0.0718\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 0.0717\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0888 - val_loss: 0.0711\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0800 - val_loss: 0.0718\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0829 - val_loss: 0.0714\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.0717\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0806 - val_loss: 0.0710\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0716\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0909 - val_loss: 0.0714\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0854 - val_loss: 0.0714\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0813 - val_loss: 0.0710\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.0717\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0844 - val_loss: 0.0711\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0896 - val_loss: 0.0714\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0710\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0891 - val_loss: 0.0713\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0823 - val_loss: 0.0714\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0880 - val_loss: 0.0709\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0809 - val_loss: 0.0713\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0712\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0762 - val_loss: 0.0717\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0840 - val_loss: 0.0714\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0846 - val_loss: 0.0713\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0709\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0756 - val_loss: 0.0712\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0866 - val_loss: 0.0712\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0865 - val_loss: 0.0711\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0855 - val_loss: 0.0712\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0715\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0717\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0844 - val_loss: 0.0711\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0767 - val_loss: 0.0713\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0711\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0759 - val_loss: 0.0712\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0898 - val_loss: 0.0711\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 0.0714\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0828 - val_loss: 0.0711\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0804 - val_loss: 0.0712\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0811 - val_loss: 0.0711\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: 0.0706\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0815 - val_loss: 0.0710\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0902 - val_loss: 0.0713\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0832 - val_loss: 0.0714\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0758 - val_loss: 0.0715\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0776 - val_loss: 0.0712\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0859 - val_loss: 0.0715\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0861 - val_loss: 0.0709\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0836 - val_loss: 0.0715\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0711\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0801 - val_loss: 0.0717\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0842 - val_loss: 0.0711\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0713\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - val_loss: 0.0715\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0765 - val_loss: 0.0717\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0708\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0734 - val_loss: 0.0711\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0883 - val_loss: 0.0708\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0822 - val_loss: 0.0713\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0803 - val_loss: 0.0710\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 0.0713\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0757 - val_loss: 0.0711\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0794 - val_loss: 0.0706\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0811 - val_loss: 0.0717\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0867 - val_loss: 0.0706\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0779 - val_loss: 0.0710\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0735 - val_loss: 0.0709\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0783 - val_loss: 0.0706\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0836 - val_loss: 0.0713\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0896 - val_loss: 0.0718\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0901 - val_loss: 0.0706\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0821 - val_loss: 0.0708\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0898 - val_loss: 0.0709\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0829 - val_loss: 0.0710\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.0719\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0915 - val_loss: 0.0710\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0804 - val_loss: 0.0706\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0755 - val_loss: 0.0714\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0709\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0810 - val_loss: 0.0710\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0824 - val_loss: 0.0712\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.0715\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0796 - val_loss: 0.0711\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0708\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0879 - val_loss: 0.0706\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0759 - val_loss: 0.0708\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0829 - val_loss: 0.0708\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0733 - val_loss: 0.0707\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - val_loss: 0.0714\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0724 - val_loss: 0.0726\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0805 - val_loss: 0.0710\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0858 - val_loss: 0.0709\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - val_loss: 0.0714\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0747 - val_loss: 0.0720\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0758 - val_loss: 0.0717\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0801 - val_loss: 0.0710\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0851 - val_loss: 0.0708\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0800 - val_loss: 0.0713\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793 - val_loss: 0.0707\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.0705\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0835 - val_loss: 0.0711\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0774 - val_loss: 0.0711\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0735 - val_loss: 0.0712\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - val_loss: 0.0706\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - val_loss: 0.0711\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - val_loss: 0.0713\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0811 - val_loss: 0.0710\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0843 - val_loss: 0.0710\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0822 - val_loss: 0.0708\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0789 - val_loss: 0.0709\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0768 - val_loss: 0.0711\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0716\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0797 - val_loss: 0.0712\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0741 - val_loss: 0.0711\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.0716\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0792 - val_loss: 0.0716\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0708\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0892 - val_loss: 0.0707\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0789 - val_loss: 0.0712\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0786 - val_loss: 0.0712\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0852 - val_loss: 0.0710\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0777 - val_loss: 0.0711\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0825 - val_loss: 0.0712\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0850 - val_loss: 0.0716\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0768 - val_loss: 0.0718\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0802 - val_loss: 0.0707\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0829 - val_loss: 0.0713\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0800 - val_loss: 0.0720\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0786 - val_loss: 0.0710\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0778 - val_loss: 0.0710\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.0703\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0903 - val_loss: 0.0705\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - val_loss: 0.0711\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0802 - val_loss: 0.0714\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0706\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - val_loss: 0.0712\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0806 - val_loss: 0.0706\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0808 - val_loss: 0.0718\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - val_loss: 0.0708\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - val_loss: 0.0708\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0815 - val_loss: 0.0705\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0774 - val_loss: 0.0707\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 45.4537 - val_loss: 0.1986\n",
      "Epoch 2/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4808 - val_loss: 0.2742\n",
      "Epoch 3/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4780 - val_loss: 0.2086\n",
      "Epoch 4/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8907 - val_loss: 0.0994\n",
      "Epoch 5/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5432 - val_loss: 0.0889\n",
      "Epoch 6/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4363 - val_loss: 0.0880\n",
      "Epoch 7/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2794 - val_loss: 0.0802\n",
      "Epoch 8/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2300 - val_loss: 0.0781\n",
      "Epoch 9/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2027 - val_loss: 0.0781\n",
      "Epoch 10/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1498 - val_loss: 0.0804\n",
      "Epoch 11/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1378 - val_loss: 0.0773\n",
      "Epoch 12/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1167 - val_loss: 0.0746\n",
      "Epoch 13/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1108 - val_loss: 0.0756\n",
      "Epoch 14/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0989 - val_loss: 0.0734\n",
      "Epoch 15/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0971 - val_loss: 0.0733\n",
      "Epoch 16/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0890 - val_loss: 0.0735\n",
      "Epoch 17/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0863 - val_loss: 0.0727\n",
      "Epoch 18/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0799 - val_loss: 0.0723\n",
      "Epoch 19/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0905 - val_loss: 0.0713\n",
      "Epoch 20/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0863 - val_loss: 0.0722\n",
      "Epoch 21/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 22/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0722\n",
      "Epoch 23/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0886 - val_loss: 0.0716\n",
      "Epoch 24/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0824 - val_loss: 0.0716\n",
      "Epoch 25/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0903 - val_loss: 0.0709\n",
      "Epoch 26/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0877 - val_loss: 0.0711\n",
      "Epoch 27/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0744 - val_loss: 0.0714\n",
      "Epoch 28/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0873 - val_loss: 0.0715\n",
      "Epoch 29/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0763 - val_loss: 0.0714\n",
      "Epoch 30/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0809 - val_loss: 0.0716\n",
      "Epoch 31/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0788 - val_loss: 0.0715\n",
      "Epoch 32/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0718\n",
      "Epoch 33/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0828 - val_loss: 0.0713\n",
      "Epoch 34/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0765 - val_loss: 0.0717\n",
      "Epoch 35/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0763 - val_loss: 0.0708\n",
      "Epoch 36/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0797 - val_loss: 0.0725\n",
      "Epoch 37/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0841 - val_loss: 0.0708\n",
      "Epoch 38/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0790 - val_loss: 0.0708\n",
      "Epoch 39/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0854 - val_loss: 0.0702\n",
      "Epoch 40/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0909 - val_loss: 0.0705\n",
      "Epoch 41/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0803 - val_loss: 0.0708\n",
      "Epoch 42/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0829 - val_loss: 0.0706\n",
      "Epoch 43/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0837 - val_loss: 0.0707\n",
      "Epoch 44/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0743 - val_loss: 0.0705\n",
      "Epoch 45/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0781 - val_loss: 0.0704\n",
      "Epoch 46/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0909 - val_loss: 0.0707\n",
      "Epoch 47/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0811 - val_loss: 0.0705\n",
      "Epoch 48/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0865 - val_loss: 0.0704\n",
      "Epoch 49/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0816 - val_loss: 0.0705\n",
      "Epoch 50/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0906 - val_loss: 0.0703\n",
      "Epoch 51/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0759 - val_loss: 0.0758\n",
      "Epoch 52/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835 - val_loss: 0.0731\n",
      "Epoch 53/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0855 - val_loss: 0.0731\n",
      "Epoch 54/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0865 - val_loss: 0.0733\n",
      "Epoch 55/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - val_loss: 0.0731\n",
      "Epoch 56/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0789 - val_loss: 0.0729\n",
      "Epoch 57/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0890 - val_loss: 0.0728\n",
      "Epoch 58/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0905 - val_loss: 0.0733\n",
      "Epoch 59/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0830 - val_loss: 0.0732\n",
      "Epoch 60/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0862 - val_loss: 0.0728\n",
      "Epoch 61/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0776 - val_loss: 0.0729\n",
      "Epoch 62/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0843 - val_loss: 0.0730\n",
      "Epoch 63/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0863 - val_loss: 0.0732\n",
      "Epoch 64/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0865 - val_loss: 0.0728\n",
      "Epoch 65/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0797 - val_loss: 0.0727\n",
      "Epoch 66/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0743 - val_loss: 0.0728\n",
      "Epoch 67/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0786 - val_loss: 0.0728\n",
      "Epoch 68/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0811 - val_loss: 0.0727\n",
      "Epoch 69/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0805 - val_loss: 0.0727\n",
      "Epoch 70/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0773 - val_loss: 0.0728\n",
      "Epoch 71/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0878 - val_loss: 0.0733\n",
      "Epoch 72/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0815 - val_loss: 0.0728\n",
      "Epoch 73/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0757 - val_loss: 0.0727\n",
      "Epoch 74/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0802 - val_loss: 0.0728\n",
      "Epoch 75/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0876 - val_loss: 0.0726\n",
      "Epoch 76/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - val_loss: 0.0726\n",
      "Epoch 77/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0772 - val_loss: 0.0728\n",
      "Epoch 78/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0904 - val_loss: 0.0733\n",
      "Epoch 79/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0945 - val_loss: 0.0730\n",
      "Epoch 80/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0855 - val_loss: 0.0730\n",
      "Epoch 81/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0759 - val_loss: 0.0727\n",
      "Epoch 82/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0794 - val_loss: 0.0732\n",
      "Epoch 83/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0883 - val_loss: 0.0725\n",
      "Epoch 84/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0848 - val_loss: 0.0730\n",
      "Epoch 85/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.0724\n",
      "Epoch 86/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0728\n",
      "Epoch 87/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 88/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0850 - val_loss: 0.0724\n",
      "Epoch 89/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0756 - val_loss: 0.0726\n",
      "Epoch 90/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - val_loss: 0.0722\n",
      "Epoch 91/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0727\n",
      "Epoch 92/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0789 - val_loss: 0.0723\n",
      "Epoch 93/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0803 - val_loss: 0.0722\n",
      "Epoch 94/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 0.0722\n",
      "Epoch 95/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - val_loss: 0.0720\n",
      "Epoch 96/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.0731\n",
      "Epoch 97/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - val_loss: 0.0723\n",
      "Epoch 98/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0889 - val_loss: 0.0721\n",
      "Epoch 99/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0788 - val_loss: 0.0720\n",
      "Epoch 100/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0845 - val_loss: 0.0719\n",
      "Epoch 101/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - val_loss: 0.0720\n",
      "Epoch 102/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0893 - val_loss: 0.0728\n",
      "Epoch 103/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0823 - val_loss: 0.0719\n",
      "Epoch 104/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0761 - val_loss: 0.0721\n",
      "Epoch 105/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0798 - val_loss: 0.0719\n",
      "Epoch 106/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0854 - val_loss: 0.0719\n",
      "Epoch 107/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0837 - val_loss: 0.0727\n",
      "Epoch 108/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0879 - val_loss: 0.0720\n",
      "Epoch 109/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0815 - val_loss: 0.0717\n",
      "Epoch 110/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0821 - val_loss: 0.0718\n",
      "Epoch 111/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0927 - val_loss: 0.0733\n",
      "Epoch 112/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0720\n",
      "Epoch 113/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0852 - val_loss: 0.0725\n",
      "Epoch 114/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0772 - val_loss: 0.0720\n",
      "Epoch 115/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0872 - val_loss: 0.0720\n",
      "Epoch 116/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0775 - val_loss: 0.0722\n",
      "Epoch 117/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0837 - val_loss: 0.0721\n",
      "Epoch 118/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0855 - val_loss: 0.0720\n",
      "Epoch 119/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - val_loss: 0.0715\n",
      "Epoch 120/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0808 - val_loss: 0.0739\n",
      "Epoch 121/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0903 - val_loss: 0.0723\n",
      "Epoch 122/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0779 - val_loss: 0.0722\n",
      "Epoch 123/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0874 - val_loss: 0.0723\n",
      "Epoch 124/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0793 - val_loss: 0.0715\n",
      "Epoch 125/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0744 - val_loss: 0.0725\n",
      "Epoch 126/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0786 - val_loss: 0.0715\n",
      "Epoch 127/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0857 - val_loss: 0.0725\n",
      "Epoch 128/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0789 - val_loss: 0.0726\n",
      "Epoch 129/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - val_loss: 0.0716\n",
      "Epoch 130/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0889 - val_loss: 0.0713\n",
      "Epoch 131/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0922 - val_loss: 0.0720\n",
      "Epoch 132/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 0.0729\n",
      "Epoch 133/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0748 - val_loss: 0.0721\n",
      "Epoch 134/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0791 - val_loss: 0.0713\n",
      "Epoch 135/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0806 - val_loss: 0.0719\n",
      "Epoch 136/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0818 - val_loss: 0.0720\n",
      "Epoch 137/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0747 - val_loss: 0.0714\n",
      "Epoch 138/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - val_loss: 0.0715\n",
      "Epoch 139/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0889 - val_loss: 0.0714\n",
      "Epoch 140/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0801 - val_loss: 0.0751\n",
      "Epoch 141/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0802 - val_loss: 0.0718\n",
      "Epoch 142/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0809 - val_loss: 0.0722\n",
      "Epoch 143/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0796 - val_loss: 0.0726\n",
      "Epoch 144/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0833 - val_loss: 0.0716\n",
      "Epoch 145/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0751 - val_loss: 0.0714\n",
      "Epoch 146/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - val_loss: 0.0717\n",
      "Epoch 147/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0823 - val_loss: 0.0725\n",
      "Epoch 148/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0747 - val_loss: 0.0723\n",
      "Epoch 149/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0811 - val_loss: 0.0713\n",
      "Epoch 150/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0818 - val_loss: 0.0712\n",
      "Epoch 151/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0881 - val_loss: 0.0721\n",
      "Epoch 152/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0858 - val_loss: 0.0712\n",
      "Epoch 153/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0840 - val_loss: 0.0736\n",
      "Epoch 154/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0811 - val_loss: 0.0720\n",
      "Epoch 155/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0844 - val_loss: 0.0803\n",
      "Epoch 156/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0847 - val_loss: 0.0713\n",
      "Epoch 157/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - val_loss: 0.0718\n",
      "Epoch 158/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0763 - val_loss: 0.0714\n",
      "Epoch 159/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0867 - val_loss: 0.0713\n",
      "Epoch 160/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0852 - val_loss: 0.0715\n",
      "Epoch 161/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0766 - val_loss: 0.0726\n",
      "Epoch 162/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0815 - val_loss: 0.0728\n",
      "Epoch 163/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0771 - val_loss: 0.0719\n",
      "Epoch 164/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0796 - val_loss: 0.1241\n",
      "Epoch 165/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0952 - val_loss: 0.0731\n",
      "Epoch 166/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - val_loss: 0.0729\n",
      "Epoch 167/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0874 - val_loss: 0.0726\n",
      "Epoch 168/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0839 - val_loss: 0.0723\n",
      "Epoch 169/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0772 - val_loss: 0.0714\n",
      "Epoch 170/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0812 - val_loss: 0.0725\n",
      "Epoch 171/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0810 - val_loss: 0.0720\n",
      "Epoch 172/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0820 - val_loss: 0.0715\n",
      "Epoch 173/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0820 - val_loss: 0.0710\n",
      "Epoch 174/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0940 - val_loss: 0.0727\n",
      "Epoch 175/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0809 - val_loss: 0.0721\n",
      "Epoch 176/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0771 - val_loss: 0.0712\n",
      "Epoch 177/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0787 - val_loss: 0.0802\n",
      "Epoch 178/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - val_loss: 0.0717\n",
      "Epoch 179/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0845 - val_loss: 0.0723\n",
      "Epoch 180/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0792 - val_loss: 0.0713\n",
      "Epoch 181/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0781 - val_loss: 0.0720\n",
      "Epoch 182/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0831 - val_loss: 0.0710\n",
      "Epoch 183/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0855 - val_loss: 0.0714\n",
      "Epoch 184/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0784 - val_loss: 0.0715\n",
      "Epoch 185/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - val_loss: 0.0710\n",
      "Epoch 186/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0877 - val_loss: 0.0712\n",
      "Epoch 187/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0817 - val_loss: 0.0718\n",
      "Epoch 188/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0835 - val_loss: 0.0717\n",
      "Epoch 189/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0853 - val_loss: 0.0711\n",
      "Epoch 190/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0820 - val_loss: 0.0716\n",
      "Epoch 191/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0807 - val_loss: 0.0712\n",
      "Epoch 192/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827 - val_loss: 0.0724\n",
      "Epoch 193/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0850 - val_loss: 0.0716\n",
      "Epoch 194/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0790 - val_loss: 0.0715\n",
      "Epoch 195/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0847 - val_loss: 0.0724\n",
      "Epoch 196/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0861 - val_loss: 0.0729\n",
      "Epoch 197/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0749 - val_loss: 0.0965\n",
      "Epoch 198/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0824 - val_loss: 0.0728\n",
      "Epoch 199/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0808 - val_loss: 0.0726\n",
      "Epoch 200/200\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0800 - val_loss: 0.0725\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 46.1427 - val_loss: 1.7971\n",
      "Epoch 2/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.7333 - val_loss: 0.3690\n",
      "Epoch 3/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6674 - val_loss: 0.1623\n",
      "Epoch 4/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0107 - val_loss: 0.0910\n",
      "Epoch 5/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5904 - val_loss: 0.0837\n",
      "Epoch 6/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3720 - val_loss: 0.0843\n",
      "Epoch 7/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2816 - val_loss: 0.0810\n",
      "Epoch 8/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2116 - val_loss: 0.0850\n",
      "Epoch 9/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1728 - val_loss: 0.0816\n",
      "Epoch 10/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1341 - val_loss: 0.0810\n",
      "Epoch 11/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1223 - val_loss: 0.0798\n",
      "Epoch 12/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1161 - val_loss: 0.0774\n",
      "Epoch 13/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0947 - val_loss: 0.0767\n",
      "Epoch 14/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1022 - val_loss: 0.0767\n",
      "Epoch 15/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0934 - val_loss: 0.0760\n",
      "Epoch 16/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0813 - val_loss: 0.0750\n",
      "Epoch 17/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0819 - val_loss: 0.0744\n",
      "Epoch 18/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0884 - val_loss: 0.0739\n",
      "Epoch 19/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0734\n",
      "Epoch 20/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0854 - val_loss: 0.0725\n",
      "Epoch 21/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0822 - val_loss: 0.0732\n",
      "Epoch 22/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0785 - val_loss: 0.0733\n",
      "Epoch 23/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0840 - val_loss: 0.0735\n",
      "Epoch 24/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0832 - val_loss: 0.0731\n",
      "Epoch 25/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0727 - val_loss: 0.0730\n",
      "Epoch 26/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0821 - val_loss: 0.0728\n",
      "Epoch 27/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0805 - val_loss: 0.0730\n",
      "Epoch 28/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0891 - val_loss: 0.0737\n",
      "Epoch 29/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0874 - val_loss: 0.0730\n",
      "Epoch 30/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0896 - val_loss: 0.0732\n",
      "Epoch 31/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0776 - val_loss: 0.0729\n",
      "Epoch 32/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0936 - val_loss: 0.0729\n",
      "Epoch 33/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0951 - val_loss: 0.0727\n",
      "Epoch 34/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - val_loss: 0.0727\n",
      "Epoch 35/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0800 - val_loss: 0.0726\n",
      "Epoch 36/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0870 - val_loss: 0.0730\n",
      "Epoch 37/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0831 - val_loss: 0.0729\n",
      "Epoch 38/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0847 - val_loss: 0.0728\n",
      "Epoch 39/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0855 - val_loss: 0.0725\n",
      "Epoch 40/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0728\n",
      "Epoch 41/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0712 - val_loss: 0.0726\n",
      "Epoch 42/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0902 - val_loss: 0.0730\n",
      "Epoch 43/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0766 - val_loss: 0.0726\n",
      "Epoch 44/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0823 - val_loss: 0.0726\n",
      "Epoch 45/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0928 - val_loss: 0.0724\n",
      "Epoch 46/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0857 - val_loss: 0.0733\n",
      "Epoch 47/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0792 - val_loss: 0.0728\n",
      "Epoch 48/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0776 - val_loss: 0.0727\n",
      "Epoch 49/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0854 - val_loss: 0.0728\n",
      "Epoch 50/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0843 - val_loss: 0.0729\n",
      "Epoch 51/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0725\n",
      "Epoch 52/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.0727\n",
      "Epoch 53/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0872 - val_loss: 0.0726\n",
      "Epoch 54/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0725\n",
      "Epoch 55/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0827 - val_loss: 0.0724\n",
      "Epoch 56/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0808 - val_loss: 0.0723\n",
      "Epoch 57/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0754 - val_loss: 0.0728\n",
      "Epoch 58/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0857 - val_loss: 0.0724\n",
      "Epoch 59/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0832 - val_loss: 0.0724\n",
      "Epoch 60/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0752 - val_loss: 0.0724\n",
      "Epoch 61/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0911 - val_loss: 0.0724\n",
      "Epoch 62/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0889 - val_loss: 0.0725\n",
      "Epoch 63/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0728\n",
      "Epoch 64/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0839 - val_loss: 0.0724\n",
      "Epoch 65/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0917 - val_loss: 0.0727\n",
      "Epoch 66/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0761 - val_loss: 0.0721\n",
      "Epoch 67/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0913 - val_loss: 0.0722\n",
      "Epoch 68/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0850 - val_loss: 0.0720\n",
      "Epoch 69/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0833 - val_loss: 0.0725\n",
      "Epoch 70/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0796 - val_loss: 0.0720\n",
      "Epoch 71/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0791 - val_loss: 0.0722\n",
      "Epoch 72/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0752 - val_loss: 0.0722\n",
      "Epoch 73/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0789 - val_loss: 0.0719\n",
      "Epoch 74/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0806 - val_loss: 0.0723\n",
      "Epoch 75/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0887 - val_loss: 0.0722\n",
      "Epoch 76/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0866 - val_loss: 0.0721\n",
      "Epoch 77/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0776 - val_loss: 0.0720\n",
      "Epoch 78/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0857 - val_loss: 0.0720\n",
      "Epoch 79/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0722\n",
      "Epoch 80/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0931 - val_loss: 0.0721\n",
      "Epoch 81/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0869 - val_loss: 0.0719\n",
      "Epoch 82/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0738 - val_loss: 0.0720\n",
      "Epoch 83/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0822 - val_loss: 0.0717\n",
      "Epoch 84/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0724\n",
      "Epoch 85/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0893 - val_loss: 0.0717\n",
      "Epoch 86/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0781 - val_loss: 0.0716\n",
      "Epoch 87/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835 - val_loss: 0.0717\n",
      "Epoch 88/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0851 - val_loss: 0.0718\n",
      "Epoch 89/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0716 - val_loss: 0.0718\n",
      "Epoch 90/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0842 - val_loss: 0.0716\n",
      "Epoch 91/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0807 - val_loss: 0.0717\n",
      "Epoch 92/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0716\n",
      "Epoch 93/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0773 - val_loss: 0.0717\n",
      "Epoch 94/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0789 - val_loss: 0.0719\n",
      "Epoch 95/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0845 - val_loss: 0.0716\n",
      "Epoch 96/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0862 - val_loss: 0.0720\n",
      "Epoch 97/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0777 - val_loss: 0.0718\n",
      "Epoch 98/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0807 - val_loss: 0.0720\n",
      "Epoch 99/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0823 - val_loss: 0.0719\n",
      "Epoch 100/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0825 - val_loss: 0.0723\n",
      "Epoch 101/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0845 - val_loss: 0.0715\n",
      "Epoch 102/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0851 - val_loss: 0.0714\n",
      "Epoch 103/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0789 - val_loss: 0.0711\n",
      "Epoch 104/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0768 - val_loss: 0.0714\n",
      "Epoch 105/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0812 - val_loss: 0.0710\n",
      "Epoch 106/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0884 - val_loss: 0.0712\n",
      "Epoch 107/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0777 - val_loss: 0.0723\n",
      "Epoch 108/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0813 - val_loss: 0.0711\n",
      "Epoch 109/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 110/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0780 - val_loss: 0.0716\n",
      "Epoch 111/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - val_loss: 0.0711\n",
      "Epoch 112/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0901 - val_loss: 0.0712\n",
      "Epoch 113/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 114/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0882 - val_loss: 0.0718\n",
      "Epoch 115/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835 - val_loss: 0.0715\n",
      "Epoch 116/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0890 - val_loss: 0.0719\n",
      "Epoch 117/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0738 - val_loss: 0.0712\n",
      "Epoch 118/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0774 - val_loss: 0.0708\n",
      "Epoch 119/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0760 - val_loss: 0.0719\n",
      "Epoch 120/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0789 - val_loss: 0.0720\n",
      "Epoch 121/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0768 - val_loss: 0.0711\n",
      "Epoch 122/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0826 - val_loss: 0.0716\n",
      "Epoch 123/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0763 - val_loss: 0.0714\n",
      "Epoch 124/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0842 - val_loss: 0.0711\n",
      "Epoch 125/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 126/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0848 - val_loss: 0.0714\n",
      "Epoch 127/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0787 - val_loss: 0.0711\n",
      "Epoch 128/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0818 - val_loss: 0.0709\n",
      "Epoch 129/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0841 - val_loss: 0.0714\n",
      "Epoch 130/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0785 - val_loss: 0.0711\n",
      "Epoch 131/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0762 - val_loss: 0.0713\n",
      "Epoch 132/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - val_loss: 0.0710\n",
      "Epoch 133/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0816 - val_loss: 0.0708\n",
      "Epoch 134/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0808 - val_loss: 0.0713\n",
      "Epoch 135/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0872 - val_loss: 0.0706\n",
      "Epoch 136/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0923 - val_loss: 0.0709\n",
      "Epoch 137/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0827 - val_loss: 0.0712\n",
      "Epoch 138/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0797 - val_loss: 0.0718\n",
      "Epoch 139/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835 - val_loss: 0.0707\n",
      "Epoch 140/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0781 - val_loss: 0.0714\n",
      "Epoch 141/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0819 - val_loss: 0.0712\n",
      "Epoch 142/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0742 - val_loss: 0.0708\n",
      "Epoch 143/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0858 - val_loss: 0.0709\n",
      "Epoch 144/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0795 - val_loss: 0.0710\n",
      "Epoch 145/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0801 - val_loss: 0.0711\n",
      "Epoch 146/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0779 - val_loss: 0.0721\n",
      "Epoch 147/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0870 - val_loss: 0.0708\n",
      "Epoch 148/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0858 - val_loss: 0.0710\n",
      "Epoch 149/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0822 - val_loss: 0.0708\n",
      "Epoch 150/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0845 - val_loss: 0.0711\n",
      "Epoch 151/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0812 - val_loss: 0.0710\n",
      "Epoch 152/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0895 - val_loss: 0.0709\n",
      "Epoch 153/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0819 - val_loss: 0.0708\n",
      "Epoch 154/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0796 - val_loss: 0.0709\n",
      "Epoch 155/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0829 - val_loss: 0.0712\n",
      "Epoch 156/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0795 - val_loss: 0.0716\n",
      "Epoch 157/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0708\n",
      "Epoch 158/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0785 - val_loss: 0.0710\n",
      "Epoch 159/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0790 - val_loss: 0.0706\n",
      "Epoch 160/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0803 - val_loss: 0.0710\n",
      "Epoch 161/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0782 - val_loss: 0.0708\n",
      "Epoch 162/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0744 - val_loss: 0.0717\n",
      "Epoch 163/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0837 - val_loss: 0.0712\n",
      "Epoch 164/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0848 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0816 - val_loss: 0.0733\n",
      "Epoch 166/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0781 - val_loss: 0.0714\n",
      "Epoch 167/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0890 - val_loss: 0.0707\n",
      "Epoch 168/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0805 - val_loss: 0.0713\n",
      "Epoch 169/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0798 - val_loss: 0.0712\n",
      "Epoch 170/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0958 - val_loss: 0.0709\n",
      "Epoch 171/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0848 - val_loss: 0.0715\n",
      "Epoch 172/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0812 - val_loss: 0.0706\n",
      "Epoch 173/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0879 - val_loss: 0.0710\n",
      "Epoch 174/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0867 - val_loss: 0.0709\n",
      "Epoch 175/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0749 - val_loss: 0.0709\n",
      "Epoch 176/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0777 - val_loss: 0.0708\n",
      "Epoch 177/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0802 - val_loss: 0.0705\n",
      "Epoch 178/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0755 - val_loss: 0.0718\n",
      "Epoch 179/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0861 - val_loss: 0.0717\n",
      "Epoch 180/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0854 - val_loss: 0.0712\n",
      "Epoch 181/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0799 - val_loss: 0.0709\n",
      "Epoch 182/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0900 - val_loss: 0.0709\n",
      "Epoch 183/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0799 - val_loss: 0.0713\n",
      "Epoch 184/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0922 - val_loss: 0.0708\n",
      "Epoch 185/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0838 - val_loss: 0.0709\n",
      "Epoch 186/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0775 - val_loss: 0.0719\n",
      "Epoch 187/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0813 - val_loss: 0.0713\n",
      "Epoch 188/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0751 - val_loss: 0.0706\n",
      "Epoch 189/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0775 - val_loss: 0.0710\n",
      "Epoch 190/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0846 - val_loss: 0.0708\n",
      "Epoch 191/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0771 - val_loss: 0.0712\n",
      "Epoch 192/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0767 - val_loss: 0.0710\n",
      "Epoch 193/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0825 - val_loss: 0.0714\n",
      "Epoch 194/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0919 - val_loss: 0.0714\n",
      "Epoch 195/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0865 - val_loss: 0.0707\n",
      "Epoch 196/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0859 - val_loss: 0.0714\n",
      "Epoch 197/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0784 - val_loss: 0.0713\n",
      "Epoch 198/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0791 - val_loss: 0.0715\n",
      "Epoch 199/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0862 - val_loss: 0.0706\n",
      "Epoch 200/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0808 - val_loss: 0.0712\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batch size:      RMSE\n",
      "0             5  0.074760\n",
      "1            10  0.072428\n",
      "2            15  0.070417\n",
      "3            20  0.071927\n",
      "4            25  0.070802\n",
      "5            50  0.071041\n",
      "6            75  0.071631\n",
      "7           100  0.072007\n",
      "8           125  0.071942\n",
      "9           150  0.070741\n",
      "10          175  0.072496\n",
      "11          200  0.071182\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los RMSE calculados\n",
    "rmse_train_values = []\n",
    "rmse_test_values = []\n",
    "batch_size = [5,10,15,20,25, 50, 75, 100, 125, 150, 175,200] \n",
    "for i in  batch_size:\n",
    "    # Crear el modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # Capa de entrada\n",
    "    model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "    # Capa oculta\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    # Capa de salida (un solo valor para el coeficiente phi)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    #model.compile(optimizer='RMSprop', loss='mean_squared_error')\n",
    "    model.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=i, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Realizar predicciones\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # Asegrate de que ambos son vectores 1D\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_train.flatten()\n",
    "\n",
    "    if len(y_train.shape) > 1:\n",
    "        y_train = y_train.flatten()\n",
    "\n",
    "    if len(y_pred_train.shape) > 1:\n",
    "        y_pred_train = y_pred_test.flatten()\n",
    "\n",
    "    if len(y_test.shape) > 1:\n",
    "        y_test = y_test.flatten()\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    rmse_train_values.append(mse_train)\n",
    "    rmse_test_values.append(mse_test)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.plot(batch_size, rmse_train_values, marker='o', color='b', label='Entrenamiento')\n",
    "plt.plot(batch_size, rmse_test_values, marker='o', color='r', label='Prueba')\n",
    "plt.title('RMSE vs batch size')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(pd.DataFrame({\"batch size:\":batch_size,\n",
    "                    \"RMSE\":rmse_test_values}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo con el 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el `optimizer` para ver como cambia el Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 111.2012 - val_loss: 0.3069\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.5426 - val_loss: 0.1161\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7465 - val_loss: 0.0918\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.4681 - val_loss: 0.1322\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3080 - val_loss: 0.0924\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.2049 - val_loss: 0.0811\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1417 - val_loss: 0.0869\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1211 - val_loss: 0.0772\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0980 - val_loss: 0.0780\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0917 - val_loss: 0.0743\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0828 - val_loss: 0.0730\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0896 - val_loss: 0.0736\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0875 - val_loss: 0.0718\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0867 - val_loss: 0.0713\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0843 - val_loss: 0.0742\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0845 - val_loss: 0.0716\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0816 - val_loss: 0.0716\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0831 - val_loss: 0.0712\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0885 - val_loss: 0.0713\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0807 - val_loss: 0.0716\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0882 - val_loss: 0.0704\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0808 - val_loss: 0.0720\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0806 - val_loss: 0.0712\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0772 - val_loss: 0.0717\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0896 - val_loss: 0.0709\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0802 - val_loss: 0.0711\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0827 - val_loss: 0.0722\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0803 - val_loss: 0.0720\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0803 - val_loss: 0.0708\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0794 - val_loss: 0.0710\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0916 - val_loss: 0.0706\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0875 - val_loss: 0.0702\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0816 - val_loss: 0.0706\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0826 - val_loss: 0.0707\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0793 - val_loss: 0.0721\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0781 - val_loss: 0.0703\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0821 - val_loss: 0.0700\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0813 - val_loss: 0.0700\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0818 - val_loss: 0.0701\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0750 - val_loss: 0.0703\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0736 - val_loss: 0.0705\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0816 - val_loss: 0.0708\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0797 - val_loss: 0.0726\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0798 - val_loss: 0.0722\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0757 - val_loss: 0.0746\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0795 - val_loss: 0.0704\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0812 - val_loss: 0.0700\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0823 - val_loss: 0.0704\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0773 - val_loss: 0.0701\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0846 - val_loss: 0.0702\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0822 - val_loss: 0.0723\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0810 - val_loss: 0.0724\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0803 - val_loss: 0.0728\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0817 - val_loss: 0.0725\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0962 - val_loss: 0.0723\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0833 - val_loss: 0.0719\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0854 - val_loss: 0.0718\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0819 - val_loss: 0.0729\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0917 - val_loss: 0.0721\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0823 - val_loss: 0.0726\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0798 - val_loss: 0.0727\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0853 - val_loss: 0.0722\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0828 - val_loss: 0.0718\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0828 - val_loss: 0.0718\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0822 - val_loss: 0.0728\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0778 - val_loss: 0.0721\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0783 - val_loss: 0.0733\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0786 - val_loss: 0.0733\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0853 - val_loss: 0.0717\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0770 - val_loss: 0.0731\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0847 - val_loss: 0.0726\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0844 - val_loss: 0.0723\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0861 - val_loss: 0.0717\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0751 - val_loss: 0.0731\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0838 - val_loss: 0.0718\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0760 - val_loss: 0.0720\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0890 - val_loss: 0.0721\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0762 - val_loss: 0.0722\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0851 - val_loss: 0.0726\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0829 - val_loss: 0.0722\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0798 - val_loss: 0.0726\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0872 - val_loss: 0.0723\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0837 - val_loss: 0.0725\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0827 - val_loss: 0.0718\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0895 - val_loss: 0.0717\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0858 - val_loss: 0.0722\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0831 - val_loss: 0.0724\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0837 - val_loss: 0.0716\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0853 - val_loss: 0.0718\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0818 - val_loss: 0.0720\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0947 - val_loss: 0.0719\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0831 - val_loss: 0.0721\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0859 - val_loss: 0.0718\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0882 - val_loss: 0.0719\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0859 - val_loss: 0.0717\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0818 - val_loss: 0.0719\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0826 - val_loss: 0.0710\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0860 - val_loss: 0.0720\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0883 - val_loss: 0.0718\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0813 - val_loss: 0.0720\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0847 - val_loss: 0.0721\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0788 - val_loss: 0.0729\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0835 - val_loss: 0.0717\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0797 - val_loss: 0.0716\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0795 - val_loss: 0.0723\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0813 - val_loss: 0.0715\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0816 - val_loss: 0.0719\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0772 - val_loss: 0.0718\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0760 - val_loss: 0.0718\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0827 - val_loss: 0.0725\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0838 - val_loss: 0.0721\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0748 - val_loss: 0.0725\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0784 - val_loss: 0.0718\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0938 - val_loss: 0.0754\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1278 - val_loss: 0.1495\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0959 - val_loss: 0.0721\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0848 - val_loss: 0.0713\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0815 - val_loss: 0.0719\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0784 - val_loss: 0.0716\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0864 - val_loss: 0.0723\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0743 - val_loss: 0.0739\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0836 - val_loss: 0.0722\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0799 - val_loss: 0.0721\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0867 - val_loss: 0.0714\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0740 - val_loss: 0.0722\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0784 - val_loss: 0.0716\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0799 - val_loss: 0.0724\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0838 - val_loss: 0.0727\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0795 - val_loss: 0.0718\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0895 - val_loss: 0.0720\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0852 - val_loss: 0.0718\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1098 - val_loss: 0.0787\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.7879 - val_loss: 0.0734\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0844 - val_loss: 0.0731\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0898 - val_loss: 0.0727\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0810 - val_loss: 0.0727\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0783 - val_loss: 0.0728\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0838 - val_loss: 0.0720\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0804 - val_loss: 0.0723\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0836 - val_loss: 0.0719\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0779 - val_loss: 0.0713\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0802 - val_loss: 0.0712\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0884 - val_loss: 0.0714\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0709 - val_loss: 0.0713\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0796 - val_loss: 0.0724\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0837 - val_loss: 0.0712\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0758 - val_loss: 0.0717\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0771 - val_loss: 0.0718\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0815 - val_loss: 0.0717\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0819 - val_loss: 0.0714\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0825 - val_loss: 0.0712\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0764 - val_loss: 0.0713\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0793 - val_loss: 0.0715\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0757 - val_loss: 0.0721\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0870 - val_loss: 0.0715\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0860 - val_loss: 0.0725\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0740 - val_loss: 0.0725\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0792 - val_loss: 0.0719\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0712\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0782 - val_loss: 0.0719\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0858 - val_loss: 0.0708\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0796 - val_loss: 0.0713\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0835 - val_loss: 0.0711\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0845 - val_loss: 0.0710\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0777 - val_loss: 0.0713\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0847 - val_loss: 0.0709\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0830 - val_loss: 0.0710\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0803 - val_loss: 0.0711\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0842 - val_loss: 0.0716\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0794 - val_loss: 0.0712\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0768 - val_loss: 0.0713\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0770 - val_loss: 0.0726\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0770 - val_loss: 0.0716\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0826 - val_loss: 0.0708\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0825 - val_loss: 0.0719\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0724 - val_loss: 0.0715\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0876 - val_loss: 0.0716\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0780 - val_loss: 0.0712\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0756 - val_loss: 0.0705\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0850 - val_loss: 0.0713\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0805 - val_loss: 0.0716\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0837 - val_loss: 0.0706\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0847 - val_loss: 0.0704\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0747 - val_loss: 0.0711\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0788 - val_loss: 0.0707\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0856 - val_loss: 0.0711\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0885 - val_loss: 0.0713\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0714\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0853 - val_loss: 0.0714\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0718 - val_loss: 0.0723\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0780 - val_loss: 0.0717\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0763 - val_loss: 0.0712\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0721 - val_loss: 0.0708\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0793 - val_loss: 0.0713\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0737 - val_loss: 0.0721\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0852 - val_loss: 0.0710\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0886 - val_loss: 0.0706\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0862 - val_loss: 0.0704\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0814 - val_loss: 0.0709\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2065.3926 - val_loss: 12.4775\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.6657 - val_loss: 0.1412\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.7570 - val_loss: 0.0921\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7001 - val_loss: 0.0864\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.6481 - val_loss: 0.0902\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1619 - val_loss: 0.0791\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.4235 - val_loss: 0.0823\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0970 - val_loss: 0.0733\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0856 - val_loss: 0.0739\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0837 - val_loss: 0.0729\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0863 - val_loss: 0.0774\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0891 - val_loss: 0.0741\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0750 - val_loss: 0.0741\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1671 - val_loss: 0.0738\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0856 - val_loss: 0.0739\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0810 - val_loss: 0.0739\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0797 - val_loss: 0.0741\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0968 - val_loss: 0.0744\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0879 - val_loss: 0.0770\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0802 - val_loss: 0.0751\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0803 - val_loss: 0.0742\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0894 - val_loss: 0.0741\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0880 - val_loss: 0.0747\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0807 - val_loss: 0.3694\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1368 - val_loss: 0.0738\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0809 - val_loss: 0.0737\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0760 - val_loss: 0.0745\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0818 - val_loss: 0.0742\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0794 - val_loss: 0.0737\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0810 - val_loss: 0.0740\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0854 - val_loss: 0.0743\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0775 - val_loss: 0.0745\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0797 - val_loss: 0.0743\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0908 - val_loss: 0.0744\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0822 - val_loss: 0.0742\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0809 - val_loss: 0.0741\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0902 - val_loss: 0.0730\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0881 - val_loss: 0.0736\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0739\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0942 - val_loss: 1.1377\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.2655 - val_loss: 0.0738\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0871 - val_loss: 0.0733\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0782 - val_loss: 0.0766\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0878 - val_loss: 0.0751\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0849 - val_loss: 0.0729\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0855 - val_loss: 0.0735\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0760 - val_loss: 0.0741\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0921 - val_loss: 0.0730\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0834 - val_loss: 0.0731\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0822 - val_loss: 0.0732\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0804 - val_loss: 0.0730\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0806 - val_loss: 0.0745\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0845 - val_loss: 0.0746\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0784 - val_loss: 0.0743\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0822 - val_loss: 0.0744\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0809 - val_loss: 0.0746\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0942 - val_loss: 0.0739\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0767 - val_loss: 0.0736\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0832 - val_loss: 0.0740\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0838 - val_loss: 0.0735\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0793 - val_loss: 0.0754\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0856 - val_loss: 0.0733\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0834 - val_loss: 0.0729\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0826 - val_loss: 0.0733\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0744 - val_loss: 0.0731\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0811 - val_loss: 0.0733\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0938 - val_loss: 0.0732\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0898 - val_loss: 0.0731\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0816 - val_loss: 0.0732\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0835 - val_loss: 0.0729\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0925 - val_loss: 0.0728\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0792 - val_loss: 0.0725\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0753 - val_loss: 0.0729\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0782 - val_loss: 0.0729\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0848 - val_loss: 0.0728\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0846 - val_loss: 0.0736\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0821 - val_loss: 0.0739\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0856 - val_loss: 0.0744\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0848 - val_loss: 0.0737\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0808 - val_loss: 0.0726\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0951 - val_loss: 0.0723\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0816 - val_loss: 0.0729\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0869 - val_loss: 0.0730\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0904 - val_loss: 0.0742\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0904 - val_loss: 0.0721\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0876 - val_loss: 0.0727\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0877 - val_loss: 0.0723\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0865 - val_loss: 0.0730\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0811 - val_loss: 0.0718\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0958 - val_loss: 0.0725\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0820 - val_loss: 0.0721\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0813 - val_loss: 0.0724\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0792 - val_loss: 0.0722\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0909 - val_loss: 0.0726\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0910 - val_loss: 0.0727\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0860 - val_loss: 0.0721\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0977 - val_loss: 0.0724\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0817 - val_loss: 0.0724\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0924 - val_loss: 0.0721\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0837 - val_loss: 0.0726\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0864 - val_loss: 0.0726\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0879 - val_loss: 0.0717\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0853 - val_loss: 0.0724\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0808 - val_loss: 0.0723\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0836 - val_loss: 0.0730\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0768 - val_loss: 0.0736\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0869 - val_loss: 0.0727\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0822 - val_loss: 0.0729\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0826 - val_loss: 0.0734\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0852 - val_loss: 0.0726\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0824 - val_loss: 0.0725\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0777 - val_loss: 0.0730\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0771 - val_loss: 0.0731\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0759 - val_loss: 0.0729\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0829 - val_loss: 0.0731\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0828 - val_loss: 0.0741\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0793 - val_loss: 0.0734\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0839 - val_loss: 0.0729\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0843 - val_loss: 0.0731\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0971 - val_loss: 0.0728\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0823 - val_loss: 0.0733\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0857 - val_loss: 0.0726\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0869 - val_loss: 0.0726\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0797 - val_loss: 0.0730\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0928 - val_loss: 0.0728\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0834 - val_loss: 0.0737\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0942 - val_loss: 0.0732\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0775 - val_loss: 0.0736\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0929 - val_loss: 0.0730\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0842 - val_loss: 0.0730\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0861 - val_loss: 0.0734\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0844 - val_loss: 0.0732\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0751 - val_loss: 0.0731\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0827 - val_loss: 0.0727\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0795 - val_loss: 0.0721\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0854 - val_loss: 0.0723\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0926 - val_loss: 0.0722\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0907 - val_loss: 0.0721\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0880 - val_loss: 0.0723\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0829 - val_loss: 0.0748\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0767 - val_loss: 0.0726\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0795 - val_loss: 0.0731\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0824 - val_loss: 0.0728\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0791 - val_loss: 0.0729\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0770 - val_loss: 0.0722\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0824 - val_loss: 0.0736\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0853 - val_loss: 0.0725\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0765 - val_loss: 0.0747\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1210 - val_loss: 0.0725\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0805 - val_loss: 0.0724\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0775 - val_loss: 0.0727\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0905 - val_loss: 0.0721\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0870 - val_loss: 0.0721\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0865 - val_loss: 0.0724\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0816 - val_loss: 0.0727\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0864 - val_loss: 0.0718\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0836 - val_loss: 0.0717\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0837 - val_loss: 0.0722\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0846 - val_loss: 0.0723\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0879 - val_loss: 0.0728\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0804 - val_loss: 0.0750\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0906 - val_loss: 0.0752\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0882 - val_loss: 0.0723\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0780 - val_loss: 0.0724\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0872 - val_loss: 0.0718\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0814 - val_loss: 0.0727\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0772 - val_loss: 0.0724\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0767 - val_loss: 0.0723\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0791 - val_loss: 0.0724\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0856 - val_loss: 0.0717\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0818 - val_loss: 0.0720\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0793 - val_loss: 0.0734\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0873 - val_loss: 0.0729\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0770 - val_loss: 0.0717\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0784 - val_loss: 0.0718\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0863 - val_loss: 0.0723\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0803 - val_loss: 0.0719\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0871 - val_loss: 0.0734\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0846 - val_loss: 0.0719\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0804 - val_loss: 0.0729\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1019 - val_loss: 0.0723\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0804 - val_loss: 0.0727\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0778 - val_loss: 0.0726\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0874 - val_loss: 0.0722\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0829 - val_loss: 0.0750\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0844 - val_loss: 0.0729\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0792 - val_loss: 0.0724\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0812 - val_loss: 0.0724\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0877 - val_loss: 0.0724\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0869 - val_loss: 0.0724\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0729 - val_loss: 0.0729\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0828 - val_loss: 0.0721\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0835 - val_loss: 0.0718\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0879 - val_loss: 0.0719\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0811 - val_loss: 0.0724\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0781 - val_loss: 0.0721\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0923 - val_loss: 0.0721\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0864 - val_loss: 0.0720\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0811 - val_loss: 0.0720\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0822 - val_loss: 0.0721\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 124.0597 - val_loss: 0.1575\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.8139 - val_loss: 0.1840\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.8530 - val_loss: 0.1291\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5623 - val_loss: 0.1103\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.4643 - val_loss: 0.1096\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.3295 - val_loss: 0.0847\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.3159 - val_loss: 0.0906\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2795 - val_loss: 0.0814\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.2080 - val_loss: 0.0806\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1686 - val_loss: 0.0801\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1432 - val_loss: 0.0770\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1224 - val_loss: 0.0771\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1029 - val_loss: 0.0749\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0896 - val_loss: 0.0750\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0858 - val_loss: 0.0739\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0829 - val_loss: 0.0731\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0801 - val_loss: 0.0720\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0832 - val_loss: 0.0712\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0778 - val_loss: 0.0720\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0760 - val_loss: 0.0713\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0754 - val_loss: 0.0703\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0911 - val_loss: 0.0707\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0843 - val_loss: 0.0706\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0882 - val_loss: 0.0708\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0807 - val_loss: 0.0713\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0806 - val_loss: 0.0713\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0758 - val_loss: 0.0704\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0699 - val_loss: 0.0724\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0871 - val_loss: 0.0706\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0799 - val_loss: 0.0703\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0881 - val_loss: 0.0702\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0870 - val_loss: 0.0707\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0805 - val_loss: 0.0703\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0788 - val_loss: 0.0699\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0804 - val_loss: 0.0701\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0830 - val_loss: 0.0701\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0745 - val_loss: 0.0704\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0835 - val_loss: 0.0704\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0870 - val_loss: 0.0704\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0815 - val_loss: 0.0712\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0786 - val_loss: 0.0698\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0802 - val_loss: 0.0701\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0704\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0799 - val_loss: 0.0700\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0777 - val_loss: 0.0699\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0798 - val_loss: 0.0717\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0766 - val_loss: 0.0707\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0790 - val_loss: 0.0704\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0833 - val_loss: 0.0699\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0742 - val_loss: 0.0701\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0829 - val_loss: 0.0709\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0870 - val_loss: 0.0706\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0797 - val_loss: 0.0704\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0841 - val_loss: 0.0697\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0848 - val_loss: 0.0697\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0751 - val_loss: 0.0702\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0849 - val_loss: 0.0702\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0796 - val_loss: 0.0699\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0917 - val_loss: 0.0702\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0819 - val_loss: 0.0697\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0803 - val_loss: 0.0703\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0841 - val_loss: 0.0707\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0815 - val_loss: 0.0705\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0815 - val_loss: 0.0698\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0838 - val_loss: 0.0709\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0777 - val_loss: 0.0705\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0845 - val_loss: 0.0703\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0782 - val_loss: 0.0710\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0842 - val_loss: 0.0701\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0778 - val_loss: 0.0702\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0835 - val_loss: 0.0699\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0770 - val_loss: 0.0701\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0782 - val_loss: 0.0713\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0868 - val_loss: 0.0702\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0794 - val_loss: 0.0701\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0959 - val_loss: 0.0703\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0934 - val_loss: 0.0702\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0754 - val_loss: 0.0712\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0822 - val_loss: 0.0694\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0841 - val_loss: 0.0715\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0819 - val_loss: 0.0699\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0841 - val_loss: 0.0696\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0752 - val_loss: 0.0703\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0717 - val_loss: 0.0709\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0717\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0851 - val_loss: 0.0700\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0766 - val_loss: 0.0702\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0813 - val_loss: 0.0708\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0845 - val_loss: 0.0705\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0732 - val_loss: 0.0712\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0809 - val_loss: 0.0704\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0766 - val_loss: 0.0697\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0810 - val_loss: 0.0719\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0880 - val_loss: 0.0704\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0842 - val_loss: 0.0699\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0896 - val_loss: 0.0705\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0807 - val_loss: 0.0710\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0758 - val_loss: 0.0700\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0818 - val_loss: 0.0756\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0828 - val_loss: 0.0723\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0836 - val_loss: 0.0717\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0807 - val_loss: 0.0729\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0797 - val_loss: 0.0722\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0760 - val_loss: 0.0722\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0851 - val_loss: 0.0718\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0808 - val_loss: 0.0717\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0783 - val_loss: 0.0729\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0817 - val_loss: 0.0726\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0802 - val_loss: 0.0723\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0853 - val_loss: 0.0720\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0863 - val_loss: 0.0720\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0779 - val_loss: 0.0722\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0810 - val_loss: 0.0721\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0881 - val_loss: 0.0715\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0781 - val_loss: 0.0715\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0777 - val_loss: 0.0717\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0832 - val_loss: 0.0716\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0870 - val_loss: 0.0722\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0727 - val_loss: 0.0731\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0718\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0814 - val_loss: 0.0719\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0812 - val_loss: 0.0715\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0845 - val_loss: 0.0715\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0745 - val_loss: 0.0719\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0839 - val_loss: 0.0718\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0816 - val_loss: 0.0719\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0821 - val_loss: 0.0720\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0782 - val_loss: 0.0719\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0767 - val_loss: 0.0703\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0860 - val_loss: 0.0702\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0813 - val_loss: 0.0709\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0846 - val_loss: 0.0701\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0818 - val_loss: 0.0701\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0788 - val_loss: 0.0712\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0833 - val_loss: 0.0710\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0753 - val_loss: 0.0703\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0809 - val_loss: 0.0707\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0915 - val_loss: 0.0698\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0829 - val_loss: 0.0701\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0783 - val_loss: 0.0706\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0775 - val_loss: 0.0697\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0807 - val_loss: 0.0703\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0781 - val_loss: 0.0706\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0853 - val_loss: 0.0709\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0803 - val_loss: 0.0695\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0844 - val_loss: 0.0705\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0755 - val_loss: 0.0701\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0710\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0875 - val_loss: 0.0698\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0807 - val_loss: 0.0697\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0873 - val_loss: 0.0697\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0803 - val_loss: 0.0699\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0881 - val_loss: 0.0697\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0872 - val_loss: 0.0708\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0818 - val_loss: 0.0708\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0720\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0847 - val_loss: 0.0703\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0802 - val_loss: 0.0699\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0770 - val_loss: 0.0713\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0818 - val_loss: 0.0715\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0776 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0780 - val_loss: 0.0733\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0812 - val_loss: 0.0700\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0870 - val_loss: 0.0710\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0796 - val_loss: 0.0720\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0872 - val_loss: 0.0710\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0771 - val_loss: 0.0702\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0844 - val_loss: 0.0717\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0784 - val_loss: 0.0713\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0781 - val_loss: 0.0721\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0875 - val_loss: 0.0706\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0816 - val_loss: 0.0701\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0853 - val_loss: 0.0716\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0843 - val_loss: 0.0709\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0815 - val_loss: 0.0704\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0785 - val_loss: 0.0705\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0834 - val_loss: 0.0722\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0842 - val_loss: 0.0729\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0822 - val_loss: 0.0722\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0789 - val_loss: 0.0720\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0849 - val_loss: 0.0724\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0856 - val_loss: 0.0721\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0800 - val_loss: 0.0734\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0901 - val_loss: 0.0721\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0904 - val_loss: 0.0717\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0724\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0870 - val_loss: 0.0720\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0737 - val_loss: 0.0727\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0838 - val_loss: 0.0720\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0790 - val_loss: 0.0723\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0835 - val_loss: 0.0720\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0814 - val_loss: 0.0715\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0756 - val_loss: 0.0724\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0747 - val_loss: 0.0730\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0852 - val_loss: 0.0720\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0887 - val_loss: 0.0715\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      " \n",
      "Nadam: \n",
      " - Entrenamiento: 0.08084028816472374 \n",
      " - Testeo: 0.07089220807413\n",
      " \n",
      "RMSprop: \n",
      " - Entrenamiento: 0.08190275558394063 \n",
      " - Testeo: 0.07205538138811159\n",
      " \n",
      "adam: \n",
      " - Entrenamiento: 0.08136891479475647 \n",
      " - Testeo: 0.07152866758414081\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dense(1, activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model1.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model1.predict(X_train)\n",
    "y_pred_test = model1.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train_Nadam = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train_Nadam = np.sqrt(mse_train_Nadam)\n",
    "mse_test_Nadam = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test_Nadam = np.sqrt(mse_test_Nadam)\n",
    " \n",
    "\n",
    "# Crear el modelo\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model2.add(Dense(246, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "\n",
    "model2.compile(optimizer='RMSprop', loss='mean_squared_error')\n",
    "history = model2.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model2.predict(X_train)\n",
    "y_pred_test = model2.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train_RMSprop = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train_RMSprop = np.sqrt(mse_train_RMSprop)\n",
    "mse_test_RMSprop = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test_RMSprop = np.sqrt(mse_test_RMSprop)\n",
    "\n",
    "# Crear el modelo\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model3.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model3.predict(X_train)\n",
    "y_pred_test = model3.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train_adam = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train_adam = np.sqrt(mse_train_adam)\n",
    "mse_test_adam = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test_adam = np.sqrt(mse_test_adam)\n",
    "\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print(\"Nadam:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train_Nadam}\",'\\n',\n",
    "      f\"- Testeo: {mse_test_Nadam}\")\n",
    "print(' ')\n",
    "print(\"RMSprop:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train_RMSprop}\",'\\n',\n",
    "      f\"- Testeo: {mse_test_RMSprop}\")\n",
    "print(' ')\n",
    "print(\"adam:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train_adam}\",'\\n',\n",
    "      f\"- Testeo: {mse_test_adam}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo con Nadam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el `nmero de capas ocultas` para ver como se modifica el Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 230.1562 - val_loss: 0.4624\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24.0725 - val_loss: 0.2470\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2521 - val_loss: 0.1406\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9773 - val_loss: 0.1152\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4064 - val_loss: 0.0891\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1842 - val_loss: 0.0817\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1445 - val_loss: 0.0825\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1204 - val_loss: 0.0818\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1082 - val_loss: 0.0820\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1000 - val_loss: 0.0817\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0946 - val_loss: 0.0817\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0933 - val_loss: 0.0826\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0976 - val_loss: 0.0821\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0893 - val_loss: 0.0814\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0938 - val_loss: 0.0813\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0914 - val_loss: 0.0813\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0983 - val_loss: 0.0807\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0882 - val_loss: 0.0817\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0871 - val_loss: 0.0804\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0904 - val_loss: 0.0808\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0872 - val_loss: 0.0802\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0868 - val_loss: 0.0814\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0928 - val_loss: 0.0797\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0895 - val_loss: 0.0799\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0932 - val_loss: 0.0800\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0871 - val_loss: 0.0797\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0921 - val_loss: 0.0787\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0932 - val_loss: 0.0790\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0773 - val_loss: 0.0789\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0930 - val_loss: 0.0789\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0913 - val_loss: 0.0790\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0891 - val_loss: 0.0791\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0795 - val_loss: 0.0811\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0878 - val_loss: 0.0784\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0892 - val_loss: 0.0778\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0825 - val_loss: 0.0781\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0921 - val_loss: 0.0768\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0907 - val_loss: 0.0764\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0847 - val_loss: 0.0773\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0800 - val_loss: 0.0768\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0958 - val_loss: 0.0765\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0766\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0772 - val_loss: 0.0759\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0819 - val_loss: 0.0754\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0810 - val_loss: 0.0759\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0909 - val_loss: 0.0758\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0882 - val_loss: 0.0759\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0897 - val_loss: 0.0749\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0812 - val_loss: 0.0742\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0878 - val_loss: 0.0743\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0831 - val_loss: 0.0738\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0833 - val_loss: 0.0737\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0815 - val_loss: 0.0752\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0841 - val_loss: 0.0738\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0756 - val_loss: 0.0740\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0751 - val_loss: 0.0733\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0803 - val_loss: 0.0727\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0899 - val_loss: 0.0731\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0843 - val_loss: 0.0726\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0828 - val_loss: 0.0728\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0793 - val_loss: 0.0731\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0788 - val_loss: 0.0723\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0771 - val_loss: 0.0731\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0872 - val_loss: 0.0730\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0718\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0855 - val_loss: 0.0712\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0823 - val_loss: 0.0753\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0770 - val_loss: 0.0732\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0882 - val_loss: 0.0724\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0731 - val_loss: 0.0710\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0769 - val_loss: 0.0708\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0808 - val_loss: 0.0701\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0770 - val_loss: 0.0703\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0825 - val_loss: 0.0704\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0821 - val_loss: 0.0707\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0854 - val_loss: 0.0702\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0808 - val_loss: 0.0708\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0739 - val_loss: 0.0712\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0809 - val_loss: 0.0706\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0765 - val_loss: 0.0703\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0774 - val_loss: 0.0701\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0827 - val_loss: 0.0699\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0718 - val_loss: 0.0702\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0753 - val_loss: 0.1001\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0864 - val_loss: 0.0725\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0868 - val_loss: 0.0719\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0817 - val_loss: 0.0712\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0714 - val_loss: 0.0711\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0706\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0857 - val_loss: 0.0713\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0846 - val_loss: 0.0706\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0832 - val_loss: 0.0712\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0773 - val_loss: 0.0706\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0786 - val_loss: 0.0707\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0815 - val_loss: 0.0705\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0827 - val_loss: 0.0709\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0844 - val_loss: 0.0701\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0912 - val_loss: 0.0704\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0805 - val_loss: 0.0712\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0790 - val_loss: 0.0704\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0831 - val_loss: 0.0701\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0746 - val_loss: 0.0707\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0775 - val_loss: 0.0701\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0753 - val_loss: 0.0703\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0781 - val_loss: 0.0705\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0804 - val_loss: 0.0700\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0802 - val_loss: 0.0704\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0795 - val_loss: 0.0704\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0840 - val_loss: 0.0700\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0826 - val_loss: 0.0704\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0727 - val_loss: 0.0707\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0829 - val_loss: 0.0700\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0660 - val_loss: 0.0710\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0759 - val_loss: 0.0708\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0702\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0735 - val_loss: 0.0708\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0837 - val_loss: 0.0707\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0792 - val_loss: 0.0702\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0844 - val_loss: 0.0702\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0778 - val_loss: 0.0706\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0798 - val_loss: 0.0704\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0775 - val_loss: 0.0705\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0898 - val_loss: 0.0699\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0780 - val_loss: 0.0701\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0833 - val_loss: 0.0704\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0780 - val_loss: 0.0707\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0774 - val_loss: 0.0703\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0810 - val_loss: 0.0700\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0794 - val_loss: 0.0703\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0840 - val_loss: 0.0701\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0826 - val_loss: 0.0701\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0699\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0809 - val_loss: 0.0708\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0820 - val_loss: 0.0701\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0809 - val_loss: 0.0703\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0800 - val_loss: 0.0709\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0836 - val_loss: 0.0702\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0920 - val_loss: 0.0707\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0778 - val_loss: 0.0701\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0815 - val_loss: 0.0703\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0772 - val_loss: 0.0701\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0880 - val_loss: 0.0706\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0800 - val_loss: 0.0705\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0870 - val_loss: 0.0705\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0856 - val_loss: 0.0704\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0837 - val_loss: 0.0704\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0756 - val_loss: 0.0705\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0774 - val_loss: 0.0706\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0769 - val_loss: 0.0703\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0910 - val_loss: 0.0708\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0806 - val_loss: 0.0706\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0831 - val_loss: 0.0707\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0798 - val_loss: 0.0702\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0781 - val_loss: 0.0707\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0872 - val_loss: 0.0705\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0810 - val_loss: 0.0703\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0758 - val_loss: 0.0699\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0844 - val_loss: 0.0704\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0742 - val_loss: 0.0721\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0831 - val_loss: 0.0707\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0753 - val_loss: 0.0702\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0851 - val_loss: 0.0703\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0816 - val_loss: 0.0702\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0754 - val_loss: 0.0704\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0708\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0882 - val_loss: 0.0700\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0802 - val_loss: 0.0706\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0748 - val_loss: 0.0707\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0805 - val_loss: 0.0702\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0714 - val_loss: 0.0703\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0765 - val_loss: 0.0723\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0710\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0766 - val_loss: 0.0706\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0810 - val_loss: 0.0705\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0783 - val_loss: 0.0704\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0778 - val_loss: 0.0707\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0856 - val_loss: 0.0705\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0786 - val_loss: 0.0706\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0802 - val_loss: 0.0703\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0794 - val_loss: 0.0703\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0752 - val_loss: 0.0710\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0804 - val_loss: 0.0705\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0713 - val_loss: 0.0710\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0785 - val_loss: 0.0704\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0810 - val_loss: 0.0704\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0757 - val_loss: 0.0714\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0726 - val_loss: 0.0715\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0834 - val_loss: 0.0709\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0800 - val_loss: 0.0715\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0798 - val_loss: 0.0708\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0767 - val_loss: 0.0710\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0787 - val_loss: 0.0705\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0704 - val_loss: 0.0710\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0801 - val_loss: 0.0707\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0760 - val_loss: 0.0704\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0852 - val_loss: 0.0704\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0734 - val_loss: 0.0723\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0775 - val_loss: 0.0713\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0963 - val_loss: 0.0705\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 109.3703 - val_loss: 0.5492\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.8138 - val_loss: 0.1607\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.9049 - val_loss: 0.1005\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.3153 - val_loss: 0.0836\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1401 - val_loss: 0.0816\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1078 - val_loss: 0.0770\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0867 - val_loss: 0.0757\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0778 - val_loss: 0.0739\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0759 - val_loss: 0.0747\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0808 - val_loss: 0.0722\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0835 - val_loss: 0.0724\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0777 - val_loss: 0.0724\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0803 - val_loss: 0.0710\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0848 - val_loss: 0.0712\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0816 - val_loss: 0.0709\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0814 - val_loss: 0.0722\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0789 - val_loss: 0.0720\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0713\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0715\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0817 - val_loss: 0.0708\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0852 - val_loss: 0.0721\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0890 - val_loss: 0.0714\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0881 - val_loss: 0.0717\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0786 - val_loss: 0.0705\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0849 - val_loss: 0.0709\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0802 - val_loss: 0.0731\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0709\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0707\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0761 - val_loss: 0.0705\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0737\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0814 - val_loss: 0.0731\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0887 - val_loss: 0.0727\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0825 - val_loss: 0.0734\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0882 - val_loss: 0.0725\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0889 - val_loss: 0.0729\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0772 - val_loss: 0.0726\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0858 - val_loss: 0.0727\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0885 - val_loss: 0.0727\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0889 - val_loss: 0.0728\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0821 - val_loss: 0.0726\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0920 - val_loss: 0.0726\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0881 - val_loss: 0.0723\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0868 - val_loss: 0.0724\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0808 - val_loss: 0.0725\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0776 - val_loss: 0.0726\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0790 - val_loss: 0.0727\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0851 - val_loss: 0.0730\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0883 - val_loss: 0.0724\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0954 - val_loss: 0.0725\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0827 - val_loss: 0.0724\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0848 - val_loss: 0.0722\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0818 - val_loss: 0.0725\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0751 - val_loss: 0.0734\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0812 - val_loss: 0.0723\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0860 - val_loss: 0.0724\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0862 - val_loss: 0.0722\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0784 - val_loss: 0.0722\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0849 - val_loss: 0.0723\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0827 - val_loss: 0.0725\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0817 - val_loss: 0.0721\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0750 - val_loss: 0.0722\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0808 - val_loss: 0.0728\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0848 - val_loss: 0.0724\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0763 - val_loss: 0.0722\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0793 - val_loss: 0.0722\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0816 - val_loss: 0.0723\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0731 - val_loss: 0.0732\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0828 - val_loss: 0.0722\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0852 - val_loss: 0.0723\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0839 - val_loss: 0.0723\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0840 - val_loss: 0.0720\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0866 - val_loss: 0.0730\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0845 - val_loss: 0.0720\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0906 - val_loss: 0.0720\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0753 - val_loss: 0.0720\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0812 - val_loss: 0.0727\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0718\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0799 - val_loss: 0.0724\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0817 - val_loss: 0.0720\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0857 - val_loss: 0.0722\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0786 - val_loss: 0.0718\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0813 - val_loss: 0.0724\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0809 - val_loss: 0.0717\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0848 - val_loss: 0.0728\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0873 - val_loss: 0.0719\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0832 - val_loss: 0.0720\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0826 - val_loss: 0.0717\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0847 - val_loss: 0.0715\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0818 - val_loss: 0.0715\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0869 - val_loss: 0.0719\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0853 - val_loss: 0.0718\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0897 - val_loss: 0.0716\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0812 - val_loss: 0.0713\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0791 - val_loss: 0.0712\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0796 - val_loss: 0.0713\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0816 - val_loss: 0.0729\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0748 - val_loss: 0.0726\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0718\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0714\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0834 - val_loss: 0.0718\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0855 - val_loss: 0.0713\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0745 - val_loss: 0.0713\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0896 - val_loss: 0.0710\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0832 - val_loss: 0.0719\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0771 - val_loss: 0.0713\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0792 - val_loss: 0.0714\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0815 - val_loss: 0.0717\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0712\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0859 - val_loss: 0.0725\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0808 - val_loss: 0.0712\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0852 - val_loss: 0.0717\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0822 - val_loss: 0.0716\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0863 - val_loss: 0.0710\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0784 - val_loss: 0.0709\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0715\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0858 - val_loss: 0.0710\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0784 - val_loss: 0.0708\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0845 - val_loss: 0.0712\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0712 - val_loss: 0.0710\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0737 - val_loss: 0.0711\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0872 - val_loss: 0.0719\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0710\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0859 - val_loss: 0.0713\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0764 - val_loss: 0.0720\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0817 - val_loss: 0.0708\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0776 - val_loss: 0.0717\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0817 - val_loss: 0.0721\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0768 - val_loss: 0.0712\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0793 - val_loss: 0.0714\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0805 - val_loss: 0.0713\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0798 - val_loss: 0.0712\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0828 - val_loss: 0.0711\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0732 - val_loss: 0.0721\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0931 - val_loss: 0.0717\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0826 - val_loss: 0.0717\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0802 - val_loss: 0.0709\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0784 - val_loss: 0.0726\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0826 - val_loss: 0.0713\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0730 - val_loss: 0.0722\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0844 - val_loss: 0.0715\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0794 - val_loss: 0.0716\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0772 - val_loss: 0.0714\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0845 - val_loss: 0.0706\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0847 - val_loss: 0.0722\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0878 - val_loss: 0.0717\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0866 - val_loss: 0.0722\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0771 - val_loss: 0.0706\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0796 - val_loss: 0.0722\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0710\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0813 - val_loss: 0.0712\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0806 - val_loss: 0.0709\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0837 - val_loss: 0.0713\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0728\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0818 - val_loss: 0.0711\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0837 - val_loss: 0.0707\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0770 - val_loss: 0.0706\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0861 - val_loss: 0.0709\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0810 - val_loss: 0.0704\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0831 - val_loss: 0.0711\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0710\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0768 - val_loss: 0.0710\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0787 - val_loss: 0.0716\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0817 - val_loss: 0.0714\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0754 - val_loss: 0.0719\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0856 - val_loss: 0.0715\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0826 - val_loss: 0.0723\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0908 - val_loss: 0.0718\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0901 - val_loss: 0.0719\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0804 - val_loss: 0.0709\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0797 - val_loss: 0.0715\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0798 - val_loss: 0.0711\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0780 - val_loss: 0.0715\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0794 - val_loss: 0.0708\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0770 - val_loss: 0.0719\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0783 - val_loss: 0.0712\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0786 - val_loss: 0.0708\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0854 - val_loss: 0.0709\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0746 - val_loss: 0.0725\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0775 - val_loss: 0.0715\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0758 - val_loss: 0.0714\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0838 - val_loss: 0.0715\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0832 - val_loss: 0.0750\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0780 - val_loss: 0.0726\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0755 - val_loss: 0.0721\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0717\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0824 - val_loss: 0.0719\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0738 - val_loss: 0.0718\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0815 - val_loss: 0.0719\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0826 - val_loss: 0.0721\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0767 - val_loss: 0.0722\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0816 - val_loss: 0.0716\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0805 - val_loss: 0.0711\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0892 - val_loss: 0.0714\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0782 - val_loss: 0.0720\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0801 - val_loss: 0.0707\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0792 - val_loss: 0.0708\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0847 - val_loss: 0.0712\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0809 - val_loss: 0.0713\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0854 - val_loss: 0.0710\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 52.2972 - val_loss: 0.0873\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.6619 - val_loss: 0.0951\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.6141 - val_loss: 0.1106\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.3798 - val_loss: 0.1408\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2254 - val_loss: 0.1233\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1778 - val_loss: 0.0897\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1386 - val_loss: 0.0825\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1342 - val_loss: 0.0802\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1081 - val_loss: 0.0771\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0971 - val_loss: 0.0761\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0868 - val_loss: 0.0743\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0860 - val_loss: 0.0740\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0881 - val_loss: 0.0723\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0854 - val_loss: 0.0739\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0935 - val_loss: 0.0734\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0910 - val_loss: 0.0707\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0855 - val_loss: 0.0713\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0795 - val_loss: 0.0728\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0772 - val_loss: 0.0710\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0883 - val_loss: 0.0709\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0806 - val_loss: 0.0708\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0710\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0779 - val_loss: 0.0708\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0900 - val_loss: 0.0704\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0782 - val_loss: 0.0715\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0793 - val_loss: 0.0707\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0744 - val_loss: 0.0706\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0831 - val_loss: 0.0704\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0774 - val_loss: 0.0706\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0829 - val_loss: 0.0706\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0777 - val_loss: 0.0712\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0774 - val_loss: 0.0712\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0866 - val_loss: 0.0707\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0814 - val_loss: 0.0708\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0815 - val_loss: 0.0719\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0793 - val_loss: 0.0710\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0810 - val_loss: 0.0708\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0913 - val_loss: 0.0704\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0749 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0842 - val_loss: 0.0704\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0837 - val_loss: 0.0708\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0791 - val_loss: 0.0706\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0833 - val_loss: 0.0703\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0826 - val_loss: 0.0710\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0869 - val_loss: 0.0709\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0759 - val_loss: 0.0747\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0736 - val_loss: 0.0736\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0779 - val_loss: 0.0739\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0869 - val_loss: 0.0736\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0754 - val_loss: 0.0736\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0836 - val_loss: 0.0732\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0866 - val_loss: 0.0731\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0879 - val_loss: 0.0732\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0788 - val_loss: 0.0735\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0772 - val_loss: 0.0731\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0758 - val_loss: 0.0731\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0848 - val_loss: 0.0729\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0869 - val_loss: 0.0729\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0729 - val_loss: 0.0730\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0768 - val_loss: 0.0732\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0821 - val_loss: 0.0733\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0849 - val_loss: 0.0731\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0757 - val_loss: 0.0730\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0869 - val_loss: 0.0732\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0784 - val_loss: 0.0731\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0864 - val_loss: 0.0737\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0775 - val_loss: 0.0738\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0815 - val_loss: 0.0728\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0883 - val_loss: 0.0730\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0808 - val_loss: 0.0732\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0846 - val_loss: 0.0728\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0769 - val_loss: 0.0731\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0731\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0873 - val_loss: 0.0729\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0956 - val_loss: 0.0731\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0843 - val_loss: 0.0729\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0828 - val_loss: 0.0730\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0800 - val_loss: 0.0730\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0826 - val_loss: 0.0728\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0715 - val_loss: 0.0738\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0846 - val_loss: 0.0728\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0845 - val_loss: 0.0728\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0888 - val_loss: 0.0728\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0848 - val_loss: 0.0731\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0854 - val_loss: 0.0730\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0829 - val_loss: 0.0727\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0820 - val_loss: 0.0725\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0825 - val_loss: 0.0732\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0893 - val_loss: 0.0727\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0848 - val_loss: 0.0729\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0797 - val_loss: 0.0729\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0933 - val_loss: 0.0723\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0838 - val_loss: 0.0723\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0900 - val_loss: 0.0740\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0909 - val_loss: 0.0731\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0873 - val_loss: 0.0727\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0821 - val_loss: 0.0732\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0825 - val_loss: 0.0726\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0730\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0863 - val_loss: 0.0732\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0822 - val_loss: 0.0728\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0799 - val_loss: 0.0728\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0817 - val_loss: 0.0738\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0888 - val_loss: 0.0732\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0833 - val_loss: 0.0727\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0849 - val_loss: 0.0729\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0839 - val_loss: 0.0721\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0797 - val_loss: 0.0723\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0797 - val_loss: 0.0730\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0860 - val_loss: 0.0727\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0847 - val_loss: 0.0730\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0876 - val_loss: 0.0724\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0816 - val_loss: 0.0729\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0802 - val_loss: 0.0726\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0862 - val_loss: 0.0721\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0801 - val_loss: 0.0725\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0764 - val_loss: 0.0722\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0759 - val_loss: 0.0724\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0800 - val_loss: 0.0723\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0826 - val_loss: 0.0720\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0809 - val_loss: 0.0724\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0787 - val_loss: 0.0722\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0855 - val_loss: 0.0721\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0909 - val_loss: 0.0719\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0817 - val_loss: 0.0720\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0778 - val_loss: 0.0722\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0814 - val_loss: 0.0723\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0912 - val_loss: 0.0724\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0864 - val_loss: 0.0726\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0826 - val_loss: 0.0732\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0837 - val_loss: 0.0719\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0742 - val_loss: 0.0719\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0857 - val_loss: 0.0722\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0868 - val_loss: 0.0724\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0786 - val_loss: 0.0722\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0836 - val_loss: 0.0732\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0786 - val_loss: 0.0725\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0817 - val_loss: 0.0730\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0886 - val_loss: 0.0733\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0802 - val_loss: 0.0726\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0783 - val_loss: 0.0723\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0797 - val_loss: 0.0728\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0825 - val_loss: 0.0721\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0849 - val_loss: 0.0721\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0738 - val_loss: 0.0722\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0888 - val_loss: 0.0738\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0872 - val_loss: 0.0723\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0831 - val_loss: 0.0721\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0809 - val_loss: 0.0725\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0803 - val_loss: 0.0723\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0830 - val_loss: 0.0725\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0799 - val_loss: 0.0721\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0906 - val_loss: 0.0730\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0876 - val_loss: 0.0728\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0789 - val_loss: 0.0726\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0808 - val_loss: 0.0728\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0740 - val_loss: 0.0724\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0880 - val_loss: 0.0729\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0832 - val_loss: 0.0723\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0903 - val_loss: 0.0722\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0795 - val_loss: 0.0720\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0802 - val_loss: 0.0717\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0847 - val_loss: 0.0715\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0779 - val_loss: 0.0720\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0780 - val_loss: 0.0726\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0876 - val_loss: 0.0725\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0839 - val_loss: 0.0713\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0799 - val_loss: 0.0730\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0943 - val_loss: 0.0715\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0862 - val_loss: 0.0731\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0887 - val_loss: 0.0728\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0871 - val_loss: 0.0720\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0885 - val_loss: 0.0720\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0807 - val_loss: 0.0716\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0810 - val_loss: 0.0719\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0742 - val_loss: 0.0718\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0815 - val_loss: 0.0722\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0801 - val_loss: 0.0720\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0818 - val_loss: 0.0722\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0901 - val_loss: 0.0711\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0889 - val_loss: 0.0715\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0816 - val_loss: 0.0712\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0829 - val_loss: 0.0723\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0795 - val_loss: 0.0711\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0856 - val_loss: 0.0726\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0822 - val_loss: 0.0721\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0842 - val_loss: 0.0729\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0887 - val_loss: 0.0726\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0833 - val_loss: 0.0728\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0845 - val_loss: 0.0727\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0866 - val_loss: 0.0724\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0860 - val_loss: 0.0730\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0861 - val_loss: 0.0734\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0812 - val_loss: 0.0727\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0856 - val_loss: 0.0724\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0895 - val_loss: 0.0723\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0862 - val_loss: 0.0722\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0870 - val_loss: 0.0722\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0827 - val_loss: 0.0730\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 36.1249 - val_loss: 0.1141\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.6436 - val_loss: 0.1160\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.2928 - val_loss: 0.0989\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.2061 - val_loss: 0.0818\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1511 - val_loss: 0.0800\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1359 - val_loss: 0.0798\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1151 - val_loss: 0.0773\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1020 - val_loss: 0.0760\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0931 - val_loss: 0.0734\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0909 - val_loss: 0.0721\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0901 - val_loss: 0.0714\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0840 - val_loss: 0.0705\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0818 - val_loss: 0.0706\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0835 - val_loss: 0.0711\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0776 - val_loss: 0.0703\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0790 - val_loss: 0.0703\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0914 - val_loss: 0.0704\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0829 - val_loss: 0.0700\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0887 - val_loss: 0.0708\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0886 - val_loss: 0.0702\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0901 - val_loss: 0.0704\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0799 - val_loss: 0.0701\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0716 - val_loss: 0.0699\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0875 - val_loss: 0.0698\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0795 - val_loss: 0.0701\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0831 - val_loss: 0.0704\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0728 - val_loss: 0.0703\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0793 - val_loss: 0.0700\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0787 - val_loss: 0.0703\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0814 - val_loss: 0.0706\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0839 - val_loss: 0.0703\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0840 - val_loss: 0.0706\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0726 - val_loss: 0.0701\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0867 - val_loss: 0.0703\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0714 - val_loss: 0.0704\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0837 - val_loss: 0.0704\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0785 - val_loss: 0.0700\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0765 - val_loss: 0.0710\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0857 - val_loss: 0.0707\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0807 - val_loss: 0.0733\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0828 - val_loss: 0.0702\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0907 - val_loss: 0.0705\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0797 - val_loss: 0.0703\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0802 - val_loss: 0.0698\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0855 - val_loss: 0.0708\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0864 - val_loss: 0.0706\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0770 - val_loss: 0.0703\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0856 - val_loss: 0.0713\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0743 - val_loss: 0.0704\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0803 - val_loss: 0.0705\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0829 - val_loss: 0.0728\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0840 - val_loss: 0.0707\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0837 - val_loss: 0.0706\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0816 - val_loss: 0.0719\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0844 - val_loss: 0.0716\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0797 - val_loss: 0.0699\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0835 - val_loss: 0.0698\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0788 - val_loss: 0.0702\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0758 - val_loss: 0.0711\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0766 - val_loss: 0.0702\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0791 - val_loss: 0.0699\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0791 - val_loss: 0.0703\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0851 - val_loss: 0.0707\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0933 - val_loss: 0.0706\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0769 - val_loss: 0.0700\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0847 - val_loss: 0.0698\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0757 - val_loss: 0.0703\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0782 - val_loss: 0.0698\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0787 - val_loss: 0.0697\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0886 - val_loss: 0.0700\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0779 - val_loss: 0.0695\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0723 - val_loss: 0.0696\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0774 - val_loss: 0.0699\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0856 - val_loss: 0.0699\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0852 - val_loss: 0.0696\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0753 - val_loss: 0.0702\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0848 - val_loss: 0.0695\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0784 - val_loss: 0.0698\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0822 - val_loss: 0.0694\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0742 - val_loss: 0.0707\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0791 - val_loss: 0.0703\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0795 - val_loss: 0.0709\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0796 - val_loss: 0.0696\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0785 - val_loss: 0.0707\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0920 - val_loss: 0.0701\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0771 - val_loss: 0.0700\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0820 - val_loss: 0.0697\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0784 - val_loss: 0.0699\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0826 - val_loss: 0.0699\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0881 - val_loss: 0.0703\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0842 - val_loss: 0.0695\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0732 - val_loss: 0.0700\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0687 - val_loss: 0.0698\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0930 - val_loss: 0.0696\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0838 - val_loss: 0.0695\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0798 - val_loss: 0.0718\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0808 - val_loss: 0.0713\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0796 - val_loss: 0.0696\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0793 - val_loss: 0.0701\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0828 - val_loss: 0.0696\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0853 - val_loss: 0.0695\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0800 - val_loss: 0.0702\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0844 - val_loss: 0.0709\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0829 - val_loss: 0.0695\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0794 - val_loss: 0.0699\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0803 - val_loss: 0.0704\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0812 - val_loss: 0.0705\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0857 - val_loss: 0.0698\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0738 - val_loss: 0.0707\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0832 - val_loss: 0.0697\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0792 - val_loss: 0.0703\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0870 - val_loss: 0.0698\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0789 - val_loss: 0.0713\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0844 - val_loss: 0.0701\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0800 - val_loss: 0.0702\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0762 - val_loss: 0.0701\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0831 - val_loss: 0.0730\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0757 - val_loss: 0.0697\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0866 - val_loss: 0.0694\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0785 - val_loss: 0.0738\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0884 - val_loss: 0.0696\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0803 - val_loss: 0.0698\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0782 - val_loss: 0.0700\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0894 - val_loss: 0.0695\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0841 - val_loss: 0.0717\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0775 - val_loss: 0.0720\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0861 - val_loss: 0.0720\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0897 - val_loss: 0.0716\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0916 - val_loss: 0.0721\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0894 - val_loss: 0.0721\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0850 - val_loss: 0.0724\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0778 - val_loss: 0.0723\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0947 - val_loss: 0.0724\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0885 - val_loss: 0.0721\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0805 - val_loss: 0.0721\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0862 - val_loss: 0.0720\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0810 - val_loss: 0.0725\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0816 - val_loss: 0.0721\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0755 - val_loss: 0.0724\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0799 - val_loss: 0.0717\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0842 - val_loss: 0.0720\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0803 - val_loss: 0.0719\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0752 - val_loss: 0.0722\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0867 - val_loss: 0.0719\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0777 - val_loss: 0.0724\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0836 - val_loss: 0.0722\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0833 - val_loss: 0.0720\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0777 - val_loss: 0.0719\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0835 - val_loss: 0.0721\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0903 - val_loss: 0.0719\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0792 - val_loss: 0.0721\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0966 - val_loss: 0.0721\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0796 - val_loss: 0.0719\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0813 - val_loss: 0.0727\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0828 - val_loss: 0.0719\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0841 - val_loss: 0.0710\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0881 - val_loss: 0.0724\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0826 - val_loss: 0.0705\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0791 - val_loss: 0.0703\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0833 - val_loss: 0.0701\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0830 - val_loss: 0.0707\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0883 - val_loss: 0.0702\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0883 - val_loss: 0.0703\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0805 - val_loss: 0.0706\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0850 - val_loss: 0.0700\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0819 - val_loss: 0.0699\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0856 - val_loss: 0.0715\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0798 - val_loss: 0.0706\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0772 - val_loss: 0.0699\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0770 - val_loss: 0.0712\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0829 - val_loss: 0.0700\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0808 - val_loss: 0.0703\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0803 - val_loss: 0.0701\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0721 - val_loss: 0.0707\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0770 - val_loss: 0.0697\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0825 - val_loss: 0.0711\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0831 - val_loss: 0.0708\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0794 - val_loss: 0.0716\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0802 - val_loss: 0.0725\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0783 - val_loss: 0.0729\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0853 - val_loss: 0.0725\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0824 - val_loss: 0.0722\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0765 - val_loss: 0.0724\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0799 - val_loss: 0.0720\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0871 - val_loss: 0.0725\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0859 - val_loss: 0.0721\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0868 - val_loss: 0.0721\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0818 - val_loss: 0.0719\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0866 - val_loss: 0.0725\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0822 - val_loss: 0.0729\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0832 - val_loss: 0.0723\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0832 - val_loss: 0.0723\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0930 - val_loss: 0.0722\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0872 - val_loss: 0.0728\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0827 - val_loss: 0.0723\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0761 - val_loss: 0.0725\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0878 - val_loss: 0.0723\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0777 - val_loss: 0.0725\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0880 - val_loss: 0.0722\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0798 - val_loss: 0.0720\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 44.0423 - val_loss: 0.1141\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6581 - val_loss: 0.0927\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3131 - val_loss: 0.0955\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.2214 - val_loss: 0.0962\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1778 - val_loss: 0.0841\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1470 - val_loss: 0.0805\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1291 - val_loss: 0.0773\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1068 - val_loss: 0.0748\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0946 - val_loss: 0.0732\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0951 - val_loss: 0.0726\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0906 - val_loss: 0.0722\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0906 - val_loss: 0.0720\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0923 - val_loss: 0.0717\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0821 - val_loss: 0.0721\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0896 - val_loss: 0.0713\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0810 - val_loss: 0.0709\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0848 - val_loss: 0.0709\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0854 - val_loss: 0.0707\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0753 - val_loss: 0.0709\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0872 - val_loss: 0.0717\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0720 - val_loss: 0.0711\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0849 - val_loss: 0.0711\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0900 - val_loss: 0.0712\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0866 - val_loss: 0.0709\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0824 - val_loss: 0.0717\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0852 - val_loss: 0.0710\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0889 - val_loss: 0.0705\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0753 - val_loss: 0.0712\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0835 - val_loss: 0.0707\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0743 - val_loss: 0.0717\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0786 - val_loss: 0.0715\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0835 - val_loss: 0.0713\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0816 - val_loss: 0.0710\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0873 - val_loss: 0.0708\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0743 - val_loss: 0.0707\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0794 - val_loss: 0.0711\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0795 - val_loss: 0.0712\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0760 - val_loss: 0.0705\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0847 - val_loss: 0.0703\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0791 - val_loss: 0.0702\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0836 - val_loss: 0.0705\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0766 - val_loss: 0.0706\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0842 - val_loss: 0.0707\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0874 - val_loss: 0.0703\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0806 - val_loss: 0.0705\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0775 - val_loss: 0.0708\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0818 - val_loss: 0.0705\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0734 - val_loss: 0.0711\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0817 - val_loss: 0.0705\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0813 - val_loss: 0.0704\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0829 - val_loss: 0.0702\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0796 - val_loss: 0.0705\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0734 - val_loss: 0.0709\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0764 - val_loss: 0.0710\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0777 - val_loss: 0.0714\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0788 - val_loss: 0.0707\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0851 - val_loss: 0.0701\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0798 - val_loss: 0.0704\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0822 - val_loss: 0.0702\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0796 - val_loss: 0.0702\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0751 - val_loss: 0.0706\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0763 - val_loss: 0.0706\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0783 - val_loss: 0.0708\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0776 - val_loss: 0.0709\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0919 - val_loss: 0.0702\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0855 - val_loss: 0.0703\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0827 - val_loss: 0.0702\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0883 - val_loss: 0.0705\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0886 - val_loss: 0.0702\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0898 - val_loss: 0.0703\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0831 - val_loss: 0.0701\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0754 - val_loss: 0.0701\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0814 - val_loss: 0.0706\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0802 - val_loss: 0.0707\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0813 - val_loss: 0.0710\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0913 - val_loss: 0.0704\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0816 - val_loss: 0.0705\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0764 - val_loss: 0.0707\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0853 - val_loss: 0.0705\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0772 - val_loss: 0.0702\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0857 - val_loss: 0.0702\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0781 - val_loss: 0.0701\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0750 - val_loss: 0.0703\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0849 - val_loss: 0.0703\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0730 - val_loss: 0.0704\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0773 - val_loss: 0.0698\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0765 - val_loss: 0.0702\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0832 - val_loss: 0.0698\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0916 - val_loss: 0.0699\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0786 - val_loss: 0.0698\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0733 - val_loss: 0.0700\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0793 - val_loss: 0.0702\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0826 - val_loss: 0.0701\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0818 - val_loss: 0.0697\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0791 - val_loss: 0.0705\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0841 - val_loss: 0.0704\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0819 - val_loss: 0.0698\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0938 - val_loss: 0.0700\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0863 - val_loss: 0.0702\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0857 - val_loss: 0.0701\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0800 - val_loss: 0.0704\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0857 - val_loss: 0.0709\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0823 - val_loss: 0.0709\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0853 - val_loss: 0.0706\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0860 - val_loss: 0.0708\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0871 - val_loss: 0.0705\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0769 - val_loss: 0.0702\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0807 - val_loss: 0.0705\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0871 - val_loss: 0.0706\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0720 - val_loss: 0.0708\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0812 - val_loss: 0.0703\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0754 - val_loss: 0.0706\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0791 - val_loss: 0.0711\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0774 - val_loss: 0.0711\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0771 - val_loss: 0.0705\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0931 - val_loss: 0.0709\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0792 - val_loss: 0.0706\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0797 - val_loss: 0.0702\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0868 - val_loss: 0.0708\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0777 - val_loss: 0.0708\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0714 - val_loss: 0.0721\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0752 - val_loss: 0.0707\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0767 - val_loss: 0.0715\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0874 - val_loss: 0.0713\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0878 - val_loss: 0.0709\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0756 - val_loss: 0.0717\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0784 - val_loss: 0.0720\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0813 - val_loss: 0.0708\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0758 - val_loss: 0.0702\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0790 - val_loss: 0.0702\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0841 - val_loss: 0.0714\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0795 - val_loss: 0.0706\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0881 - val_loss: 0.0703\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0894 - val_loss: 0.0706\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0801 - val_loss: 0.0716\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0776 - val_loss: 0.0705\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0782 - val_loss: 0.0709\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0840 - val_loss: 0.0713\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0835 - val_loss: 0.0711\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0846 - val_loss: 0.0702\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0784 - val_loss: 0.0705\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0912 - val_loss: 0.0723\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0800 - val_loss: 0.0705\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0838 - val_loss: 0.0703\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0790 - val_loss: 0.0702\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0803 - val_loss: 0.0710\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0801 - val_loss: 0.0702\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0781 - val_loss: 0.0707\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0866 - val_loss: 0.0720\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0877 - val_loss: 0.0700\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0826 - val_loss: 0.0712\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0884 - val_loss: 0.0700\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0777 - val_loss: 0.0697\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0836 - val_loss: 0.0699\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0914 - val_loss: 0.0703\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0879 - val_loss: 0.0709\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0767 - val_loss: 0.0701\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0800 - val_loss: 0.0696\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0844 - val_loss: 0.0698\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0800 - val_loss: 0.0711\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0836 - val_loss: 0.0710\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0797 - val_loss: 0.0701\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0729 - val_loss: 0.0701\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0862 - val_loss: 0.0700\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0803 - val_loss: 0.0711\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0872 - val_loss: 0.0714\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0887 - val_loss: 0.0721\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0872 - val_loss: 0.0718\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0805 - val_loss: 0.0717\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0837 - val_loss: 0.0718\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0857 - val_loss: 0.0715\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0824 - val_loss: 0.0716\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0795 - val_loss: 0.0713\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0762 - val_loss: 0.0713\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0791 - val_loss: 0.0714\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0783 - val_loss: 0.0715\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0837 - val_loss: 0.0721\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0855 - val_loss: 0.0715\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0854 - val_loss: 0.0727\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0870 - val_loss: 0.0716\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0923 - val_loss: 0.0718\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0805 - val_loss: 0.0713\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0872 - val_loss: 0.0718\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0871 - val_loss: 0.0717\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0813 - val_loss: 0.0713\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0815 - val_loss: 0.0709\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0831 - val_loss: 0.0712\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0841 - val_loss: 0.0711\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0815 - val_loss: 0.0704\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0811 - val_loss: 0.0718\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0866 - val_loss: 0.0711\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0759 - val_loss: 0.0713\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0782 - val_loss: 0.0713\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0824 - val_loss: 0.0712\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0859 - val_loss: 0.0715\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0768 - val_loss: 0.0721\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0777 - val_loss: 0.0717\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0823 - val_loss: 0.0717\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0797 - val_loss: 0.0714\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0872 - val_loss: 0.0717\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 18.8738 - val_loss: 0.0926\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.3545 - val_loss: 0.0869\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1699 - val_loss: 0.0819\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1635 - val_loss: 0.0804\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1260 - val_loss: 0.0772\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1145 - val_loss: 0.0739\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0991 - val_loss: 0.0730\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0882 - val_loss: 0.0725\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0936 - val_loss: 0.0730\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0902 - val_loss: 0.0712\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0856 - val_loss: 0.0713\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0888 - val_loss: 0.0710\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0847 - val_loss: 0.0706\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0866 - val_loss: 0.0703\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0860 - val_loss: 0.0709\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0953 - val_loss: 0.0709\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0864 - val_loss: 0.0716\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0776 - val_loss: 0.0716\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0856 - val_loss: 0.0703\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0786 - val_loss: 0.0709\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0836 - val_loss: 0.0708\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0861 - val_loss: 0.0708\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0849 - val_loss: 0.0709\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0796 - val_loss: 0.0707\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0895 - val_loss: 0.0710\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0813 - val_loss: 0.0705\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0755 - val_loss: 0.0710\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0867 - val_loss: 0.0709\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0916 - val_loss: 0.0706\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0858 - val_loss: 0.0709\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0864 - val_loss: 0.0712\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0867 - val_loss: 0.0711\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0802 - val_loss: 0.0707\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0918 - val_loss: 0.0706\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0767 - val_loss: 0.0704\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0789 - val_loss: 0.0707\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0777 - val_loss: 0.0710\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0813 - val_loss: 0.0707\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0818 - val_loss: 0.0706\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0735 - val_loss: 0.0708\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0853 - val_loss: 0.0704\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0745 - val_loss: 0.0707\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0786 - val_loss: 0.0708\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0767 - val_loss: 0.0703\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0880 - val_loss: 0.0704\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0761 - val_loss: 0.0704\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0911 - val_loss: 0.0708\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0788 - val_loss: 0.0707\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0835 - val_loss: 0.0714\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0829 - val_loss: 0.0705\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0839 - val_loss: 0.0710\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0783 - val_loss: 0.0703\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0818 - val_loss: 0.0710\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0777 - val_loss: 0.0702\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0772 - val_loss: 0.0705\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0815 - val_loss: 0.0706\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0809 - val_loss: 0.0704\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0800 - val_loss: 0.0701\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0804 - val_loss: 0.0705\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0863 - val_loss: 0.0702\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0720 - val_loss: 0.0703\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0868 - val_loss: 0.0707\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0815 - val_loss: 0.0704\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0812 - val_loss: 0.0704\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0856 - val_loss: 0.0701\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0851 - val_loss: 0.0703\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0893 - val_loss: 0.0706\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0813 - val_loss: 0.0701\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0684 - val_loss: 0.0704\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0860 - val_loss: 0.0704\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0870 - val_loss: 0.0701\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0876 - val_loss: 0.0705\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0821 - val_loss: 0.0704\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0866 - val_loss: 0.0703\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0830 - val_loss: 0.0704\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0860 - val_loss: 0.0705\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0792 - val_loss: 0.0704\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0861 - val_loss: 0.0702\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0864 - val_loss: 0.0705\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0765 - val_loss: 0.0711\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0692 - val_loss: 0.0707\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0782 - val_loss: 0.0702\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0769 - val_loss: 0.0706\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0825 - val_loss: 0.0703\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0810 - val_loss: 0.0701\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0807 - val_loss: 0.0704\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0900 - val_loss: 0.0701\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0763 - val_loss: 0.0701\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0693 - val_loss: 0.0713\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0861 - val_loss: 0.0704\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0895 - val_loss: 0.0712\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0854 - val_loss: 0.0703\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0910 - val_loss: 0.0706\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0878 - val_loss: 0.0704\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0811 - val_loss: 0.0713\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0797 - val_loss: 0.0711\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0800 - val_loss: 0.0714\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0848 - val_loss: 0.0706\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0789 - val_loss: 0.0709\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0837 - val_loss: 0.0706\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0876 - val_loss: 0.0705\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0820 - val_loss: 0.0704\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0813 - val_loss: 0.0708\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0776 - val_loss: 0.0699\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0793 - val_loss: 0.0715\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0871 - val_loss: 0.0702\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0811 - val_loss: 0.0705\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0773 - val_loss: 0.0704\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0750 - val_loss: 0.0718\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0839 - val_loss: 0.0703\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0844 - val_loss: 0.0711\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0829 - val_loss: 0.0706\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0763 - val_loss: 0.0702\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0774 - val_loss: 0.0705\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0794 - val_loss: 0.0706\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0800 - val_loss: 0.0705\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0879 - val_loss: 0.0707\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0789 - val_loss: 0.0703\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0808 - val_loss: 0.0717\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0806 - val_loss: 0.0704\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0779 - val_loss: 0.0703\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0826 - val_loss: 0.0710\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0836 - val_loss: 0.0705\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0833 - val_loss: 0.0701\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0890 - val_loss: 0.0701\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0788 - val_loss: 0.0703\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0787 - val_loss: 0.0706\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0853 - val_loss: 0.0702\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0814 - val_loss: 0.0707\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0791 - val_loss: 0.0707\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0818 - val_loss: 0.0707\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0833 - val_loss: 0.0711\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0810 - val_loss: 0.0716\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0791 - val_loss: 0.0705\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0753 - val_loss: 0.0718\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0814 - val_loss: 0.0708\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0839 - val_loss: 0.0708\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0786 - val_loss: 0.0702\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0815 - val_loss: 0.0712\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0834 - val_loss: 0.0740\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0774 - val_loss: 0.0709\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0796 - val_loss: 0.0708\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0857 - val_loss: 0.0705\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0790 - val_loss: 0.0711\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0757 - val_loss: 0.0713\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0809 - val_loss: 0.0709\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0931 - val_loss: 0.0707\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0813 - val_loss: 0.0709\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0863 - val_loss: 0.0708\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0925 - val_loss: 0.0709\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0781 - val_loss: 0.0709\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0857 - val_loss: 0.0717\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0749 - val_loss: 0.0714\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0812 - val_loss: 0.0707\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0777 - val_loss: 0.0710\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0804 - val_loss: 0.0704\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0811 - val_loss: 0.0704\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0807 - val_loss: 0.0705\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0827 - val_loss: 0.0701\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0801 - val_loss: 0.0700\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0809 - val_loss: 0.0700\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0812 - val_loss: 0.0705\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0805 - val_loss: 0.0701\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0803 - val_loss: 0.0707\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0804 - val_loss: 0.0703\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0805 - val_loss: 0.0702\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0754 - val_loss: 0.0712\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0785 - val_loss: 0.0701\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0799 - val_loss: 0.0710\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0867 - val_loss: 0.0707\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0826 - val_loss: 0.0697\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0805 - val_loss: 0.0710\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0782 - val_loss: 0.0702\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0907 - val_loss: 0.0715\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0807 - val_loss: 0.0705\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0770 - val_loss: 0.0703\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0771 - val_loss: 0.0698\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0812 - val_loss: 0.0699\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0855 - val_loss: 0.0722\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0777 - val_loss: 0.0710\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0853 - val_loss: 0.0701\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0810 - val_loss: 0.0701\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0823 - val_loss: 0.0703\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0917 - val_loss: 0.0697\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0720 - val_loss: 0.0700\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0786 - val_loss: 0.0718\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0765 - val_loss: 0.0701\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0827 - val_loss: 0.0702\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0847 - val_loss: 0.0703\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0868 - val_loss: 0.0697\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0796 - val_loss: 0.0702\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0814 - val_loss: 0.0708\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0845 - val_loss: 0.0699\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0799 - val_loss: 0.0701\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0859 - val_loss: 0.0701\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0861 - val_loss: 0.0696\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0774 - val_loss: 0.0697\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0802 - val_loss: 0.0696\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0849 - val_loss: 0.0697\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0775 - val_loss: 0.0703\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      " \n",
      "1 Capa oculta: \n",
      " - Entrenamiento: 0.07961366054210435 \n",
      " - Testeo: 0.07047705061984447\n",
      " \n",
      "2 Capa oculta: \n",
      " - Entrenamiento: 0.07940494636250846 \n",
      " - Testeo: 0.07097191459499676\n",
      " \n",
      "3 Capa oculta: \n",
      " - Entrenamiento: 0.08242565613458541 \n",
      " - Testeo: 0.07299358352177468\n",
      " \n",
      "4 Capa oculta: \n",
      " - Entrenamiento: 0.08232353401699569 \n",
      " - Testeo: 0.07198473835759787\n",
      " \n",
      "5 Capa oculta: \n",
      " - Entrenamiento: 0.0814214177199162 \n",
      " - Testeo: 0.07170212828066119\n",
      " \n",
      "5 Capa oculta: \n",
      " - Entrenamiento: 0.08049677351902927 \n",
      " - Testeo: 0.07026007612501076\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='linear'))\n",
    "\n",
    "model1.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model1.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model1.predict(X_train)\n",
    "y_pred_test = model1.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train1 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train1 = np.sqrt(mse_train1)\n",
    "mse_test1 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test1 = np.sqrt(mse_test1)\n",
    "\n",
    "# Crear el modelo\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "\n",
    "model2.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model2.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model2.predict(X_train)\n",
    "y_pred_test = model2.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train2 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train2 = np.sqrt(mse_train2)\n",
    "mse_test2 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test2 = np.sqrt(mse_test2)\n",
    "\n",
    "# Crear el modelo\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation='linear'))\n",
    "\n",
    "model3.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model3.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model3.predict(X_train)\n",
    "y_pred_test = model3.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train3 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train3 = np.sqrt(mse_train3)\n",
    "mse_test3 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test3 = np.sqrt(mse_test3)\n",
    "\n",
    "# Crear el modelo\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(1, activation='linear'))\n",
    "\n",
    "model4.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model4.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model4.predict(X_train)\n",
    "y_pred_test = model4.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train4 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train4 = np.sqrt(mse_train4)\n",
    "mse_test4 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test4 = np.sqrt(mse_test4)\n",
    "\n",
    "# Crear el modelo\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(256, activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(1, activation='linear'))\n",
    "\n",
    "model5.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model5.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model5.predict(X_train)\n",
    "y_pred_test = model5.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train5 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train5 = np.sqrt(mse_train5)\n",
    "mse_test5 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test5 = np.sqrt(mse_test5)\n",
    "\n",
    "# Crear el modelo\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model6.add(Dense(256, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(256, activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(1, activation='linear'))\n",
    "\n",
    "model6.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model6.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model6.predict(X_train)\n",
    "y_pred_test = model6.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train6 = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train6 = np.sqrt(mse_train6)\n",
    "mse_test6 = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test6 = np.sqrt(mse_test6)\n",
    "\n",
    "print(' ')\n",
    "print(\"1 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train1}\",'\\n',\n",
    "      f\"- Testeo: {mse_test1}\")\n",
    "print(' ')\n",
    "print(\"2 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train2}\",'\\n',\n",
    "      f\"- Testeo: {mse_test2}\")\n",
    "print(' ')\n",
    "print(\"3 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train3}\",'\\n',\n",
    "      f\"- Testeo: {mse_test3}\")\n",
    "print(' ')\n",
    "print(\"4 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train4}\",'\\n',\n",
    "      f\"- Testeo: {mse_test4}\")\n",
    "print(' ')\n",
    "print(\"5 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train5}\",'\\n',\n",
    "      f\"- Testeo: {mse_test5}\")\n",
    "print(' ')\n",
    "print(\"6 Capa oculta:\",'\\n',\n",
    "      f\"- Entrenamiento: {mse_train6}\",'\\n',\n",
    "      f\"- Testeo: {mse_test6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo con 4 capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\Documents\\Ezequiel\\Eze\\HENRY\\ENTORNO_VIRTUAL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 14.9978 - val_loss: 0.5177\n",
      "Epoch 2/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.6318 - val_loss: 0.5057\n",
      "Epoch 3/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5472 - val_loss: 0.4715\n",
      "Epoch 4/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4957 - val_loss: 0.4514\n",
      "Epoch 5/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4602 - val_loss: 0.4472\n",
      "Epoch 6/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.5196 - val_loss: 0.4320\n",
      "Epoch 7/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4805 - val_loss: 0.4251\n",
      "Epoch 8/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4960 - val_loss: 0.4203\n",
      "Epoch 9/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4928 - val_loss: 0.4182\n",
      "Epoch 10/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4726 - val_loss: 0.4221\n",
      "Epoch 11/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4917 - val_loss: 0.4222\n",
      "Epoch 12/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4360 - val_loss: 0.4217\n",
      "Epoch 13/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4523 - val_loss: 0.4193\n",
      "Epoch 14/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4549 - val_loss: 0.4185\n",
      "Epoch 15/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4420 - val_loss: 0.4205\n",
      "Epoch 16/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4759 - val_loss: 0.4188\n",
      "Epoch 17/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4432 - val_loss: 0.4189\n",
      "Epoch 18/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4801 - val_loss: 0.4165\n",
      "Epoch 19/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3994 - val_loss: 0.4287\n",
      "Epoch 20/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4230 - val_loss: 0.4214\n",
      "Epoch 21/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4814 - val_loss: 0.4182\n",
      "Epoch 22/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4385 - val_loss: 0.4172\n",
      "Epoch 23/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4446 - val_loss: 0.4174\n",
      "Epoch 24/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4289 - val_loss: 0.4185\n",
      "Epoch 25/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4419 - val_loss: 0.4178\n",
      "Epoch 26/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4188 - val_loss: 0.4204\n",
      "Epoch 27/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4247 - val_loss: 0.4183\n",
      "Epoch 28/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4157 - val_loss: 0.4194\n",
      "Epoch 29/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4845 - val_loss: 0.4164\n",
      "Epoch 30/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4817 - val_loss: 0.4173\n",
      "Epoch 31/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4336 - val_loss: 0.4188\n",
      "Epoch 32/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4028 - val_loss: 0.4200\n",
      "Epoch 33/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4231 - val_loss: 0.4184\n",
      "Epoch 34/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4493 - val_loss: 0.4186\n",
      "Epoch 35/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4212 - val_loss: 0.4199\n",
      "Epoch 36/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4251 - val_loss: 0.4204\n",
      "Epoch 37/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4452 - val_loss: 0.4176\n",
      "Epoch 38/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4314 - val_loss: 0.4163\n",
      "Epoch 39/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4519 - val_loss: 0.4172\n",
      "Epoch 40/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4226 - val_loss: 0.4197\n",
      "Epoch 41/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4163 - val_loss: 0.4183\n",
      "Epoch 42/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4474 - val_loss: 0.4196\n",
      "Epoch 43/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4521 - val_loss: 0.4214\n",
      "Epoch 44/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4016 - val_loss: 0.4201\n",
      "Epoch 45/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4439 - val_loss: 0.4183\n",
      "Epoch 46/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4292 - val_loss: 0.4164\n",
      "Epoch 47/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4207 - val_loss: 0.4170\n",
      "Epoch 48/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4370 - val_loss: 0.4188\n",
      "Epoch 49/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4456 - val_loss: 0.4163\n",
      "Epoch 50/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4445 - val_loss: 0.4163\n",
      "Epoch 51/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4382 - val_loss: 0.4174\n",
      "Epoch 52/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4753 - val_loss: 0.4170\n",
      "Epoch 53/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4433 - val_loss: 0.4163\n",
      "Epoch 54/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4768 - val_loss: 0.4185\n",
      "Epoch 55/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4476 - val_loss: 0.4200\n",
      "Epoch 56/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4503 - val_loss: 0.4180\n",
      "Epoch 57/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4532 - val_loss: 0.4188\n",
      "Epoch 58/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4711 - val_loss: 0.4163\n",
      "Epoch 59/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4595 - val_loss: 0.4181\n",
      "Epoch 60/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4458 - val_loss: 0.4197\n",
      "Epoch 61/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4436 - val_loss: 0.4178\n",
      "Epoch 62/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4149 - val_loss: 0.4187\n",
      "Epoch 63/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4465 - val_loss: 0.4174\n",
      "Epoch 64/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4715 - val_loss: 0.4181\n",
      "Epoch 65/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3931 - val_loss: 0.4236\n",
      "Epoch 66/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4336 - val_loss: 0.4170\n",
      "Epoch 67/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4430 - val_loss: 0.4180\n",
      "Epoch 68/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4359 - val_loss: 0.4165\n",
      "Epoch 69/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4623 - val_loss: 0.4137\n",
      "Epoch 70/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4580 - val_loss: 0.4160\n",
      "Epoch 71/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4364 - val_loss: 0.4150\n",
      "Epoch 72/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4341 - val_loss: 0.4167\n",
      "Epoch 73/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4911 - val_loss: 0.4153\n",
      "Epoch 74/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4547 - val_loss: 0.4140\n",
      "Epoch 75/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4140 - val_loss: 0.4130\n",
      "Epoch 76/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4645 - val_loss: 0.4126\n",
      "Epoch 77/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4653 - val_loss: 0.4186\n",
      "Epoch 78/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4567 - val_loss: 0.4131\n",
      "Epoch 79/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4546 - val_loss: 0.4228\n",
      "Epoch 80/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4631 - val_loss: 0.4211\n",
      "Epoch 81/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4179 - val_loss: 0.4158\n",
      "Epoch 82/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4423 - val_loss: 0.4147\n",
      "Epoch 83/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4462 - val_loss: 0.4131\n",
      "Epoch 84/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4257 - val_loss: 0.4121\n",
      "Epoch 85/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4381 - val_loss: 0.4253\n",
      "Epoch 86/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4578 - val_loss: 0.4269\n",
      "Epoch 87/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4563 - val_loss: 0.4163\n",
      "Epoch 88/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4672 - val_loss: 0.4215\n",
      "Epoch 89/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4473 - val_loss: 0.4204\n",
      "Epoch 90/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4510 - val_loss: 0.4187\n",
      "Epoch 91/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4378 - val_loss: 0.4166\n",
      "Epoch 92/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4569 - val_loss: 0.4139\n",
      "Epoch 93/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4637 - val_loss: 0.4232\n",
      "Epoch 94/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4485 - val_loss: 0.4188\n",
      "Epoch 95/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4712 - val_loss: 0.4214\n",
      "Epoch 96/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4235 - val_loss: 0.4167\n",
      "Epoch 97/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4855 - val_loss: 0.4191\n",
      "Epoch 98/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4294 - val_loss: 0.4203\n",
      "Epoch 99/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4797 - val_loss: 0.4180\n",
      "Epoch 100/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4424 - val_loss: 0.4175\n",
      "Epoch 101/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4558 - val_loss: 0.4186\n",
      "Epoch 102/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4076 - val_loss: 0.4200\n",
      "Epoch 103/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4519 - val_loss: 0.4183\n",
      "Epoch 104/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4201 - val_loss: 0.4192\n",
      "Epoch 105/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4489 - val_loss: 0.4171\n",
      "Epoch 106/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4414 - val_loss: 0.4200\n",
      "Epoch 107/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4412 - val_loss: 0.4212\n",
      "Epoch 108/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4343 - val_loss: 0.4150\n",
      "Epoch 109/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4028 - val_loss: 0.4176\n",
      "Epoch 110/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4526 - val_loss: 0.4145\n",
      "Epoch 111/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4427 - val_loss: 0.4198\n",
      "Epoch 112/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4273 - val_loss: 0.4168\n",
      "Epoch 113/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4156 - val_loss: 0.4147\n",
      "Epoch 114/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4414 - val_loss: 0.4190\n",
      "Epoch 115/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5018 - val_loss: 0.4170\n",
      "Epoch 116/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4368 - val_loss: 0.4183\n",
      "Epoch 117/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4461 - val_loss: 0.4186\n",
      "Epoch 118/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4395 - val_loss: 0.4161\n",
      "Epoch 119/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4362 - val_loss: 0.4225\n",
      "Epoch 120/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4470 - val_loss: 0.4237\n",
      "Epoch 121/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4287 - val_loss: 0.4187\n",
      "Epoch 122/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4409 - val_loss: 0.4157\n",
      "Epoch 123/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4248 - val_loss: 0.4160\n",
      "Epoch 124/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4228 - val_loss: 0.4234\n",
      "Epoch 125/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4774 - val_loss: 0.4169\n",
      "Epoch 126/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4118 - val_loss: 0.4211\n",
      "Epoch 127/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4665 - val_loss: 0.4249\n",
      "Epoch 128/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4528 - val_loss: 0.4198\n",
      "Epoch 129/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4484 - val_loss: 0.4226\n",
      "Epoch 130/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4333 - val_loss: 0.4154\n",
      "Epoch 131/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4696 - val_loss: 0.4211\n",
      "Epoch 132/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4627 - val_loss: 0.4188\n",
      "Epoch 133/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4392 - val_loss: 0.4191\n",
      "Epoch 134/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4351 - val_loss: 0.4199\n",
      "Epoch 135/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4098 - val_loss: 0.4178\n",
      "Epoch 136/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4548 - val_loss: 0.4116\n",
      "Epoch 137/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4344 - val_loss: 0.4174\n",
      "Epoch 138/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4581 - val_loss: 0.4169\n",
      "Epoch 139/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4113 - val_loss: 0.4160\n",
      "Epoch 140/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5000 - val_loss: 0.4141\n",
      "Epoch 141/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4263 - val_loss: 0.4183\n",
      "Epoch 142/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4439 - val_loss: 0.4168\n",
      "Epoch 143/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4747 - val_loss: 0.4193\n",
      "Epoch 144/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4123 - val_loss: 0.4166\n",
      "Epoch 145/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4410 - val_loss: 0.4206\n",
      "Epoch 146/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4324 - val_loss: 0.4129\n",
      "Epoch 147/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4707 - val_loss: 0.4140\n",
      "Epoch 148/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4057 - val_loss: 0.4154\n",
      "Epoch 149/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4334 - val_loss: 0.4156\n",
      "Epoch 150/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4361 - val_loss: 0.4147\n",
      "Epoch 151/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4473 - val_loss: 0.4225\n",
      "Epoch 152/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4129 - val_loss: 0.4174\n",
      "Epoch 153/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4123 - val_loss: 0.4179\n",
      "Epoch 154/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4239 - val_loss: 0.4144\n",
      "Epoch 155/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4256 - val_loss: 0.4140\n",
      "Epoch 156/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4740 - val_loss: 0.4162\n",
      "Epoch 157/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4436 - val_loss: 0.4163\n",
      "Epoch 158/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4619 - val_loss: 0.4116\n",
      "Epoch 159/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4438 - val_loss: 0.4136\n",
      "Epoch 160/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4469 - val_loss: 0.4167\n",
      "Epoch 161/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4431 - val_loss: 0.4170\n",
      "Epoch 162/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4938 - val_loss: 0.4186\n",
      "Epoch 163/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4186 - val_loss: 0.4174\n",
      "Epoch 164/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4397 - val_loss: 0.4172\n",
      "Epoch 165/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4370 - val_loss: 0.4189\n",
      "Epoch 166/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4326 - val_loss: 0.4208\n",
      "Epoch 167/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4953 - val_loss: 0.4196\n",
      "Epoch 168/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4144 - val_loss: 0.4141\n",
      "Epoch 169/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4463 - val_loss: 0.4189\n",
      "Epoch 170/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4598 - val_loss: 0.4164\n",
      "Epoch 171/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4777 - val_loss: 0.4176\n",
      "Epoch 172/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.3900 - val_loss: 0.4167\n",
      "Epoch 173/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4596 - val_loss: 0.4163\n",
      "Epoch 174/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4389 - val_loss: 0.4134\n",
      "Epoch 175/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4486 - val_loss: 0.4171\n",
      "Epoch 176/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4205 - val_loss: 0.4181\n",
      "Epoch 177/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4324 - val_loss: 0.4174\n",
      "Epoch 178/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4540 - val_loss: 0.4157\n",
      "Epoch 179/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4452 - val_loss: 0.4180\n",
      "Epoch 180/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4424 - val_loss: 0.4169\n",
      "Epoch 181/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4260 - val_loss: 0.4249\n",
      "Epoch 182/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4504 - val_loss: 0.4156\n",
      "Epoch 183/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4310 - val_loss: 0.4159\n",
      "Epoch 184/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4309 - val_loss: 0.4156\n",
      "Epoch 185/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4583 - val_loss: 0.4171\n",
      "Epoch 186/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4680 - val_loss: 0.4177\n",
      "Epoch 187/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4326 - val_loss: 0.4162\n",
      "Epoch 188/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.4047 - val_loss: 0.4178\n",
      "Epoch 189/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4135 - val_loss: 0.4250\n",
      "Epoch 190/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4350 - val_loss: 0.4160\n",
      "Epoch 191/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4790 - val_loss: 0.4156\n",
      "Epoch 192/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4131 - val_loss: 0.4185\n",
      "Epoch 193/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4447 - val_loss: 0.4216\n",
      "Epoch 194/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4634 - val_loss: 0.4136\n",
      "Epoch 195/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4259 - val_loss: 0.4145\n",
      "Epoch 196/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4339 - val_loss: 0.4138\n",
      "Epoch 197/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4190 - val_loss: 0.4149\n",
      "Epoch 198/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4503 - val_loss: 0.4161\n",
      "Epoch 199/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4518 - val_loss: 0.4182\n",
      "Epoch 200/200\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4527 - val_loss: 0.4181\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "- Entrenamiento: 0.6638024547483853 \n",
      " - Testeo: 0.646642575867654- Error relativo respecto al promedio de y_test: 0.6973549771159332\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model_final = Sequential()\n",
    "model_final.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(256, activation='relu'))\n",
    "model_final.add(Dropout(0.2))\n",
    "model_final.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_final.compile(optimizer='Nadam', loss='mean_squared_error')\n",
    "history = model_final.fit(X_train, y_train, epochs=200, batch_size=150, validation_data=(X_test, y_test))\n",
    "y_pred_train = model_final.predict(X_train)\n",
    "y_pred_test = model_final.predict(X_test)\n",
    "\n",
    "if len(y_pred_train.shape) > 1:\n",
    "     y_pred_train = y_pred_train.flatten()\n",
    "if len(y_train.shape) > 1:\n",
    "    y_train = y_train.flatten()\n",
    "if len(y_pred_train.shape) > 1:\n",
    "    y_pred_train = y_pred_test.flatten()\n",
    "if len(y_test.shape) > 1:\n",
    "    y_test = y_test.flatten()\n",
    "\n",
    "mse_train_final = mean_squared_error(y_train, y_pred_train)\n",
    "rmse_train_final = np.sqrt(mse_train_final)\n",
    "mse_test_final = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test_final = np.sqrt(mse_test_final)\n",
    "\n",
    "print(f\"- Entrenamiento: {rmse_train_final}\",'\\n',\n",
    "      f\"- Testeo: {rmse_test_final}\",'\\n',\n",
    "      f\"- Error relativo respecto al promedio de y_test: {y_test.mean()/rmse_test_final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HAY QUE MEJORARLO MUCHSIMO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo completo\n",
    "model.save('Modelo_entrenado.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENTORNO_VIRTUAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
