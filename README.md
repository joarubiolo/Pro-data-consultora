<p align="center">
  <img src="Imagenes-readme/Pro-data banner.png" alt="banner" width="500">
</p>

# Consultora Pro-Data

## ğŸ“‹ Ãndice

- [Integrantes](#integrantes)
- [Entendimiento de la SituaciÃ³n Actual](#entendimiento-de-la-situacion-actual)
- [Objetivo General](#objetivo-general)
- [Objetivos EspecÃ­ficos](#objetivos-especificos)
- [Alcance del Proyecto](#alcance-del-proyecto)
- [KPIs](#kpis)
- [MetodologÃ­a de Trabajo](#metodologia-de-trabajo)

## **Integrantes**

- [Argenis Alexis Bolivar ](https://github.com/Argeboliv05) - *Proyect Manager*
- [Ezequiel Lizio](https://github.com/Ezecordoba) - *ML Engineer*
- [Paula Irazoqui](https://github.com/paulairazoqui) - *Data Engineer*
- [JoaquÃ­n Rubiolo](https://github.com/joarubiolo) - *DevOps*
- [Sebastian Prats](https://github.com/sebaprats) - *Data Analyst*

## **Entendimiento de la SituaciÃ³n Actual**

ğŸ“ **Contexto:** El sector gastronÃ³mico en Florida es altamente competitivo y diverso, con una gran cantidad de negocios en constante apertura y cierre. Sin embargo, no siempre existe una distribuciÃ³n equitativa de los diferentes tipos de restaurantes en cada zona, lo que puede generar oportunidades de mercado sin explotar.

ğŸ“‰ **Problema:** La calidad de los negocios existentes varÃ­a significativamente, con algunos establecimientos acumulando malas calificaciones y reviews negativas. Esto representa una oportunidad para nuevos emprendedores que deseen establecer negocios con mejores estÃ¡ndares de servicio y calidad.

ğŸ’¡ **SoluciÃ³n:** Mediante el anÃ¡lisis de datos y tÃ©cnicas de machine learning, es posible identificar Ã¡reas con deficiencia en oferta gastronÃ³mica y baja calidad de servicio, proporcionando recomendaciones estratÃ©gicas para maximizar el Ã©xito de nuevos negocios.

## **Objetivo General**

Desarrollar un sistema de recomendaciÃ³n que, basado en datos de negocios gastronÃ³micos en el estado de  Florida - EEUU, sugiera la mejor ubicaciÃ³n para abrir un nuevo establecimiento.

## **Objetivos EspecÃ­ficos**

1ï¸âƒ£ Analizar la distribuciÃ³n geogrÃ¡fica de los negocios gastronÃ³micos en Florida para identificar zonas con baja oferta.`<br>`
2ï¸âƒ£ Evaluar la calidad de los negocios existentes mediante anÃ¡lisis de reviews y ratings.`<br>`
3ï¸âƒ£ Determinar caracterÃ­sticas clave de los negocios exitosos.`<br>`
4ï¸âƒ£ Desarrollar un modelo de recomendaciÃ³n basado en carencias del mercado y calidad de la competencia.`<br>`
5ï¸âƒ£ Validar la efectividad del sistema con datos histÃ³ricos.`<br>`

## **Alcance del Proyecto**

### **Â¿QuÃ© vamos a hacer?**

ğŸ“¢ Desarrollar un modelo de Machine Learning que prediga si un negocio tendrÃ¡ Ã©xito. La recomendaciÃ³n se basarÃ¡ en la carencia de cierto tipo de negocio en una zona y la baja calidad de los existentes segÃºn reviews. AdemÃ¡s, se proporcionarÃ¡n caracterÃ­sticas clave de los negocios exitosos.

ğŸ”¹ **Esto incluye:**

âœ… Un **EDA (Exploratory Data Analysis)** completo para entender los datos.`<br>`
âœ… ImplementaciÃ³n de un  **Data Warehouse** para almacenar y gestionar la base de datos de manera eficiente.`<br>`
âœ… CreaciÃ³n de **features clave** que impactan el Ã©xito de un negocio.`<br>`
âœ… Entrenamiento de un **modelo de clasificaciÃ³n** para predecir Ã©xito o fracaso.`<br>`
âœ… ImplementaciÃ³n de un **dashboard interactivo** para visualizar los resultados.`<br>`
âœ… **Despliegue del modelo en la nube** para uso en tiempo real.`<br>`

### **ğŸ† Base de RecomendaciÃ³n**

ğŸ“¢ **Nuestro sistema recomendarÃ¡ ubicaciones para nuevos negocios basÃ¡ndose en los siguientes criterios:**

âœ… Se ubica en una **zona con baja oferta gastronÃ³mica** o con **competencia de baja calidad** segÃºn calificaciones y reviews.`<br>`
âœ… Se alinea con las **caracterÃ­sticas clave de los negocios exitosos**, identificadas en el anÃ¡lisis de datos.`<br>`
âœ… Se encuentra en un Ã¡rea con **potencial de demanda insatisfecha**, determinada por la evaluaciÃ³n de check-ins y reviews.`<br>`

### **ğŸŒ Alcance GeogrÃ¡fico**

ğŸ“¢ **Limitamos el anÃ¡lisis a negocios en el Estado Florida de EE.UU.**`<br>`
ğŸ”¹ Esto permite trabajar con un dataset mÃ¡s limpio y evitar sesgos por diferencias culturales en reseÃ±as.`<br>`

### **ğŸ•’ LimitaciÃ³n en el Tiempo**

ğŸ“¢ **Nuestro modelo solo se entrenarÃ¡ con datos de los Ãºltimos 5 aÃ±os (2017-2022).**`<br>`
ğŸ”¹ Evita incluir negocios antiguos cuyo comportamiento puede no ser representativo.`<br>`
ğŸ”¹ Nos aseguramos de que los datos sean recientes y relevantes.`<br>`

### ğŸ› ï¸ **Stack Tecnologico**

ğŸ“¢ **Usaremos herramientas estÃ¡ndar para garantizar reproducibilidad:**

âœ… **Almacenamiento de Datos**

ğŸ”¹ Local (CSV, Parquet)`<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ FÃ¡cil de manejar y compartir.`<br>`
  âœ”ï¸ Compatible con la mayorÃ­a de herramientas de anÃ¡lisis de datos.`<br>`
  âœ”ï¸ Parquet ofrece mayor eficiencia en almacenamiento y rendimiento para grandes volÃºmenes de datos.`<br>`

ğŸ”¹ **Google Cloud Storage** `<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ Escalabilidad y alta disponibilidad.`<br>`
  âœ”ï¸ IntegraciÃ³n con Google BigQuery, Spark y otras herramientas.`<br>`
  âœ”ï¸ Seguridad avanzada con control de acceso y encriptaciÃ³n.`<br>`

âœ… **Procesamiento y AnÃ¡lisis** `<br>`
ğŸ”¹ **Python (Pandas, NumPy, Scikit-learn)**`<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ Comunidad activa y bien documentada.`<br>`
  âœ”ï¸ Alto rendimiento en procesamiento de datos.`<br>`
  âœ”ï¸ Amplia compatibilidad con otros frameworks de ML y visualizaciÃ³n.`<br>`

ğŸ”¹ **EDA y VisualizaciÃ³n:** Seaborn, Matplotlib `<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ ExploraciÃ³n rÃ¡pida de patrones en los datos.`<br>`
  âœ”ï¸ PersonalizaciÃ³n avanzada de grÃ¡ficos.`<br>`
  âœ”ï¸ IntegraciÃ³n con Pandas para visualizaciÃ³n directa de DataFrames.`<br>`

ğŸ”¹ **ML Models:** Random Forest, XGBoost, RegresiÃ³n LogÃ­stica `<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ Modelos interpretables y eficientes.`<br>`
  âœ”ï¸ Adaptabilidad a distintos tipos de datos.`<br>`
  âœ”ï¸ XGBoost ofrece gran rendimiento en grandes volÃºmenes de datos.`<br>`

âœ… **Despliegue** `<br>`
ğŸ”¹ Dashboard en **PowerBI** `<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ Visualizaciones dinÃ¡micas y personalizables.`<br>`
  âœ”ï¸ IntegraciÃ³n con diversas fuentes de datos.`<br>`
  âœ”ï¸ Facilidad de uso para usuarios sin conocimientos tÃ©cnicos avanzados.`<br>`

ğŸ”¹  API en **FastAPI** para consultas en tiempo real `<br>`
  **Ventajas:**`<br>`
  âœ”ï¸ RÃ¡pido y eficiente gracias a su compatibilidad con ASGI.`<br>`
  âœ”ï¸ DocumentaciÃ³n automÃ¡tica con Swagger UI.`<br>`
  âœ”ï¸ FÃ¡cil integraciÃ³n con bases de datos y modelos de machine learning.`<br>`

## **KPIs**

### 1ï¸âƒ£ **Tasa de Crecimiento de Calificaciones (CalificaciÃ³n promedio mensual)**

ğŸ“¢ **Objetivo:** Incrementar en un 0,1 % la calificaciÃ³n promedio del negocio por trimestre.

Este KPI medirÃ¡ la evoluciÃ³n en la calificaciÃ³n promedio del negociogastronÃ³mico en el Ãºltimo trimestre respecto al trimestre anterior

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./Imagenes-readme/KPI_2.jpg)

ğŸ“Œ **Leyenda:**

* **TCC**: Tasa de Crecimiento de Calificaciones.`<br>`
* **CP_T**: CalificaciÃ³n promedio en el Ãºltimo trimestre.`<br>`
* **CP_T-1**: CalificaciÃ³n promedio en el trimestre anterior.`<br>`

### 2ï¸âƒ£ **Tasa de Crecimiento de Reviews**

ğŸ“¢ **Objetivo:** Incrementar la cantidad de reseÃ±as del nuevo negocio en un 5% por trimestre

Este KPI medirÃ¡ la evoluciÃ³n de la popularidad del nuevo negocio gastronÃ³mico respecto del trimestre anterior, entendiendo que un indicador de esa popularidad es que aumente la cantidad de reseÃ±as.

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./Imagenes-readme/KPI_1.png)

ğŸ“Œ **Leyenda:**

* **TCR**: Tasa de Crecimiento de Reviews ajustada al objetivo del 5%.`<br>`
* **R_t**: Cantidad de reseÃ±as en el trimestre actual.`<br>`
* **R_t-1**: Cantidad de reseÃ±as en el trimestre anterior.`<br>`

### 3ï¸âƒ£ **Indice de repeticion de clientes**

ğŸ“¢ **Objetivo:** incrementar el Ã­ndice de repeticiÃ³n de clientes en un 10 % por trimestre

Este KPI medirÃ¡ la satisfacciÃ³n de los clientes a partir de si regresan o no al local en el Ãºltimo trimestre en relaciÃ³n al trimestre anterior.

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./Imagenes-readme/KPI_3.jpg)

ğŸ“Œ **Leyenda:**

* **ICR**: Ãndice de RepeticiÃ³n de Clientes ajustado al objetivo del 10%.`<br>`
* **C_r**: NÃºmero de clientes que repiten en el trimestre actual.`<br>`
* **C_t**: NÃºmero total de clientes en el trimestre actual.`<br>`

## **MetodologÃ­a de Trabajo**

ğŸ“¢ Para garantizar una gestiÃ³n eficiente del proyecto, se aplicarÃ¡ la metodologÃ­a **Scrum**, organizando el trabajo en sprints con entregables claros.

### **ğŸ‘¥ Roles del Equipo**

âœ… **Proyect Manager:** Argenis Bolivar `<br>`
âœ… **Data Engineer:** Paula Irazoqui `<br>`
âœ… **Data Analyst:** SebastiÃ¡n Prat `<br>`
âœ… **ML Engineer:** Ezequiel Lizio `<br>`
âœ… **DevOps:** Joaquin Rubiolo `<br>`

### **ğŸ“Œ Roles en cada Sprint**

Para distribuir responsabilidades, los roles clave en cada sprint son:

| **Sprint**   | **Product Owner**                                 | **Scrum Master**                                | **Data Engineer**           | **Data Analyst**             | **ML Engineer**                        | **DevOps**                               |
| ------------------ | ------------------------------------------------------- | ----------------------------------------------------- | --------------------------------- | ---------------------------------- | -------------------------------------------- | ---------------------------------------------- |
| **Sprint 1** | Definir objetivos y<br />alcance                        | Gestionar<br />backlog y <br />reuniones              | Extraer y<br />limpiar datos      | Explorar datos<br />y definir KPIs | Extraer y<br />limpiar datos                 | Configurar<br />repositorio Git                |
| **Sprint 2** | Priorizar<br />implementaciÃ³n <br />del ETL            | Asegurar<br />que los <br />procesos se <br />cumplan | Implementar<br />y validar el ETL | Analizar calidad<br />de datos     | MVP Proof of Concept<br /> de producto de ML | Configurar<br />infraestructura <br />de datos |
| **Sprint 3** | Priorizar desarrollo<br /> del modelo <br />y dashboard | Coordinar la<br />entrega final                       | Optimizar<br />datos para ML      | Visualizar KPIs<br />y resultados  | Entrenar modelo<br />de ML                   | Desplegar API<br />y dashboard                 |

#### **1ï¸âƒ£ Ã‰picas Principales**

1. **DefiniciÃ³n del Proyecto y ExploraciÃ³n de Datos** `<br>`
2. **ImplementaciÃ³n del Pipeline ETL y Almacenamiento** `<br>`
3. **Desarrollo del Modelo de Machine Learning** `<br>`
4. **ImplementaciÃ³n del Dashboard Interactivo** `<br>`
5. **OptimizaciÃ³n y ValidaciÃ³n del Sistema** `<br>`

#### **2ï¸âƒ£ Historias de Usuario por Sprint**

##### **ğŸ“Œ Sprint 1: DefiniciÃ³n y ExploraciÃ³n de Datos (03 Feb - 14 Feb)**

**HU1:** *Como analista de datos, quiero realizar un anÃ¡lisis exploratorio (EDA) para entender la calidad y caracterÃ­sticas de los datos disponibles.*

* **Tareas:**
  âœ… Recopilar datasets de negocios gastronÃ³micos y reviews.
  âœ… Identificar valores nulos, duplicados y outliers.
  âœ… Generar reportes visuales sobre la distribuciÃ³n de datos.

**HU2:** *Como equipo de desarrollo, quiero definir los KPIs para medir el Ã©xito del sistema.*

* **Tareas:**
  âœ… Identificar mÃ©tricas clave para evaluar recomendaciones del modelo.
  âœ… Documentar fÃ³rmulas y criterios de mediciÃ³n.

**HU3:** *Como desarrollador, quiero establecer un repositorio en GitHub para el control de versiones.*

* **Tareas:**
  âœ… Crear la estructura del repositorio.
  âœ… Configurar branches y flujos de trabajo Git.
  âœ… Documentar estÃ¡ndares de codificaciÃ³n y colaboraciÃ³n.

##### **ğŸ“Œ Sprint 2: Data Engineering (17 Feb - 28 Feb)**

**HU4:** *Como ingeniero de datos, quiero implementar un pipeline ETL automatizado para garantizar la limpieza y transformaciÃ³n de los datos.*

* **Tareas:**
  âœ… DiseÃ±ar el flujo de extracciÃ³n, transformaciÃ³n y carga (ETL).`<br>`
  âœ… Configurar un Data Warehouse / Data Lake.`<br>`
  âœ… Implementar una carga incremental para nuevos datos.`<br>`

**HU5:** *Como arquitecto de datos, quiero diseÃ±ar un modelo relacional para almacenar la informaciÃ³n de manera eficiente.*

* **Tareas:**
  âœ… Crear un modelo de base de datos (ERD).`<br>`
  âœ… Implementar PostgreSQL o BigQuery para almacenamiento.`<br>`
  âœ… Validar la integridad de los datos mediante consultas SQL.`<br>`

**HU6:** *Como ingeniero de datos, quiero realizar pruebas de calidad para asegurar que los datos son confiables.*

* **Tareas:**
  âœ… Implementar validaciones de datos en Airflow o Prefect.`<br>`
  âœ… Generar reportes de calidad de datos.`<br>`
  âœ… Resolver problemas de datos faltantes o inconsistentes.`<br>`

##### **ğŸ“Œ Sprint 3: Data Analytics + ML (3 Mar - 15 Mar)**

**HU7:** *Como analista de datos, quiero visualizar las recomendaciones del modelo en un dashboard interactivo.*

* **Tareas:**
  âœ… Implementar grÃ¡ficos de visualizaciÃ³n de KPIs.`<br>`
  âœ… Integrar el dashboard con la base de datos.`<br>`
  âœ… Generar filtros interactivos para el anÃ¡lisis de datos.`<br>`

**HU8:** *Como desarrollador de machine learning, quiero entrenar un modelo de recomendaciÃ³n basado en datos histÃ³ricos.*

* **Tareas:**
  âœ… Seleccionar el algoritmo de ML mÃ¡s adecuado (clustering, regresiÃ³n, etc.).`<br>`
  âœ… Optimizar el modelo con hiperparÃ¡metros.`<br>`
  âœ… Evaluar su rendimiento con mÃ©tricas de precisiÃ³n y recall.`<br>`

**HU9:** *Como DevOps, quiero desplegar el modelo en producciÃ³n para que pueda ser utilizado en tiempo real.*

* **Tareas:**
  âœ… Crear API con **FastAPI** para consumir el modelo.`<br>`
  âœ… Integrar el modelo con el dashboard para visualizaciÃ³n en tiempo real.`<br>`
  âœ… Probar la API con datos de prueba y optimizar tiempos de respuesta.`<br>`

---

#### **3ï¸âƒ£ Backlog TÃ©cnico (Tareas Prioritarias)**

âœ… **Sprint 1: DefiniciÃ³n y ExploraciÃ³n de Datos** `<br>`

* Configurar repositorio en **GitHub** con estructura de carpetas.`<br>`
* Realizar EDA.`<br>`
* Documentar las fuentes de datos y su confiabilidad.`<br>`

ğŸ† **Hitos:**

* DocumentaciÃ³n del EDA y calidad de datos.`<br>`
* DefiniciÃ³n de KPIs.`<br>`
* CreaciÃ³n del repositorio en GitHub.`<br>`

âœ… **Sprint 2: Data Engineering**

* Configurar **Airflow** o **Prefect** para orquestaciÃ³n del ETL.`<br>`
* Implementar almacenamiento en  **Google BigQuery**.`<br>`
* Generar logs de procesamiento y validaciÃ³n de datos.`<br>`

ğŸ† **Hitos:**

* ImplementaciÃ³n del Data Lake y Data Warehouse.`<br>`
* Pipeline ETL en funcionamiento.`<br>`
* ValidaciÃ³n de datos y reportes de calidad.`<br>`

âœ… **Sprint 3: Data Analytics + ML**

* Conectar el dashboard con la base de datos.`<br>`
* Entrenar y desplegar el modelo de Machine Learning.`<br>`
* Evaluar el sistema con datos en tiempo real.`<br>`

ğŸ† **Hitos:**

* Dashboard funcional con visualizaciÃ³n de KPIs.`<br>`
* Modelo de ML entrenado y optimizado.`<br>`
* Despliegue del modelo en la nube.`<br>`

#### 4ï¸âƒ£ Diagrama de Gantt

![Texto alternativo](./Imagenes-readme/Gantt_Proyecto.png)

---

## **Pipeline ETL**

El proceso de **ExtracciÃ³n, TransformaciÃ³n y Carga (ETL)** se llevÃ³ a cabo para garantizar que los datos utilizados en el anÃ¡lisis y modelado sean limpios, estructurados y almacenados de manera eficiente.

### **1ï¸âƒ£ ExtracciÃ³n de Datos**

Los datos utilizados en este proyecto provienen de diversas fuentes, incluyendo plataformas de reseÃ±as gastronÃ³micas como **Google Maps** y **Yelp**, ademÃ¡s de informaciÃ³n demogrÃ¡fica extraÃ­da mediante **web scraping** de fuentes pÃºblicas.

### **2ï¸âƒ£ TransformaciÃ³n de Datos**

Para asegurar la calidad de los datos y facilitar su anÃ¡lisis, se llevaron a cabo los siguientes procesos de transformaciÃ³n:

âœ… **Limpieza de Datos**

- Se verificÃ³ la presencia de valores nulos y duplicados en las columnas clave.
- No se detectaron problemas significativos en este aspecto.

âœ… **GeneraciÃ³n de Features**

- Se realizÃ³ un **anÃ¡lisis de sentimiento** sobre los comentarios de los usuarios para capturar la percepciÃ³n del pÃºblico respecto a cada establecimiento.
- Se realizÃ³ un **desglose de atributos y categorÃ­as**, separando informaciÃ³n relevante en columnas independientes para facilitar su anÃ¡lisis.

âœ… **Modelo de Datos**

- Se diseÃ±Ã³ un **modelo en estrella**, con una tabla central que contiene la informaciÃ³n de los negocios y tablas auxiliares que almacenan detalles especÃ­ficos.
- La estructura del modelo de datos estÃ¡ documentada en el repositorio dentro de la carpeta **documentaciÃ³n**.

### **3ï¸âƒ£ Carga de Datos**

Los datos procesados fueron almacenados en **buckets de Google Cloud** y tambiÃ©n se encuentran disponibles en el repositorio del proyecto para su consulta y anÃ¡lisis.

---

### **4ï¸âƒ£ OrquestaciÃ³n y AutomatizaciÃ³n**

La orquestaciÃ³n del proceso ETL se realiza mediante una  **funciÃ³n en Cloud Run** , que es activada automÃ¡ticamente por un **trigger** cuando un nuevo archivo JSON es detectado en el bucket `rawdata_1` de  **Cloud Storage** .

#### ğŸ“Œ Flujo del Proceso:

1ï¸âƒ£ **DetecciÃ³n de eventos en GCS**

* Un archivo JSON es cargado en el bucket `rawdata_1`.
* Se activa la funciÃ³n en Cloud Run mediante un evento de actualizaciÃ³n.

2ï¸âƒ£ **EjecuciÃ³n de la funciÃ³n en Cloud Run**

* La funciÃ³n obtiene el archivo desde Cloud Storage.
* Se verifica si el archivo ya ha sido procesado utilizando Firestore.
* Se transforma y normaliza la data.

3ï¸âƒ£ **Almacenamiento en GCS**

* Los datos transformados son guardados en formato CSV en otro bucket de Cloud Storage (`procdata_1`).

4ï¸âƒ£ **Carga en BigQuery**

* Los datos procesados se insertan en la tabla **metadatos** de BigQuery.
* Se aplica carga incremental para evitar duplicaciones.
* Se registra la transacciÃ³n en Firestore.

---

### **5ï¸âƒ£ Carga Incremental**

Para optimizar la inserciÃ³n de datos en BigQuery y evitar duplicaciones, se implementa un proceso de  **carga incremental** .

#### ğŸ”¹ Proceso de Carga Incremental:

1ï¸âƒ£ **VerificaciÃ³n de datos en Firestore**

* Se consulta Firestore para determinar si un archivo ya ha sido procesado.
* Si el evento ya existe, se omite la carga para evitar duplicaciones.

2ï¸âƒ£ **TransformaciÃ³n y Almacenamiento en Cloud Storage**

* Se convierte el JSON en un formato estructurado.
* Se guarda un archivo **CSV** en el bucket `procdata_1` para su posterior carga.

3ï¸âƒ£ **Carga de datos en BigQuery**

* Se inserta la nueva informaciÃ³n en la tabla  **metadatos** .
* Se utiliza `WRITE_APPEND` para agregar solo los nuevos registros sin sobrescribir los existentes.

4ï¸âƒ£ **Registro del evento en Firestore**

* Se almacena en Firestore el `event_id` del archivo para evitar que se vuelva a procesar en el futuro.

---

### **6ï¸âƒ£ DesafÃ­os y OptimizaciÃ³n**

Algunos de los principales desafÃ­os y optimizaciones implementadas fueron:

âœ… Manejo y limpieza de datos de mÃºltiples fuentes.
âœ… ImplementaciÃ³n del modelo de datos en estrella para estructurar la informaciÃ³n de forma eficiente.
âœ… Desglose de atributos y categorÃ­as para mejorar la organizaciÃ³n y anÃ¡lisis de los datos.

---

## **Modelos de Machine Learning**

### **Modelo 1**

Sistema de recomendaciÃ³n con que tiene como input una categorÃ­a de restaurantes y devuelve las tres mejores ciudades en las que se recomienda poner uno nuevo (mostrÃ¡ndolas en un mapa) y los 10 atributos que deberÃ­a presentar para tener Ã©xito dentro de esta categorÃ­a. Para mas informaciÃ³n de como esta armado ir a ...

https://github.com/joarubiolo/Pro-data-consultora/blob/main/Modelo_ML/info.md

### **Modelo 2**

Este proyecto implementa un sistema de recomendaciÃ³n de negocios basado en Machine Learning utilizando Streamlit como interfaz de usuario. El modelo de aprendizaje automÃ¡tico analiza datos de diferentes ciudades y categorÃ­as de negocios, evaluando factores como competencia y puntuaciones de reseÃ±as para sugerir las mejores opciones de negocio. Para mas informacion, debajo esta el link a la documentacion

https://github.com/joarubiolo/Pro-data-consultora/blob/main/Modelo_ML2/info.md
