<p align="center">
  <img src="Imagenes-readme/Pro-data banner.png" alt="banner" width="500">
</p>

# Consultora Pro-Data

## ğŸ“‹ Ãndice

- [Integrantes](#integrantes)
- [Entendimiento de la SituaciÃ³n Actual](#entendimiento-de-la-situacion-actual)
- [Objetivo General](#objetivo-general)
- [Objetivos EspecÃ­ficos](#objetivos-especificos)
- [Alcance del Proyecto](#alcance-del-proyecto)
- [KPIs](#kpis)
- [MetodologÃ­a de Trabajo](#metodologia-de-trabajo)


## **Integrantes**

- [Argenis Alexis Bolivar ](https://github.com/Argeboliv05) - *Scrum Master*
- [Ezequiel Lizio](https://github.com/Ezecordoba) - *ML Engineer*
- [Paula Irazoqui](https://github.com/paulairazoqui) - *Data Engineer*
- [JoaquÃ­n Rubiolo](https://github.com/joarubiolo) - *DevOps*
- [Sebastian Prats](https://github.com/sebaprats) - *Data Analyst*


## **Entendimiento de la SituaciÃ³n Actual**

ğŸ“ **Contexto:** El sector gastronÃ³mico en Florida es altamente competitivo y diverso, con una gran cantidad de negocios en constante apertura y cierre. Sin embargo, no siempre existe una distribuciÃ³n equitativa de los diferentes tipos de restaurantes en cada zona, lo que puede generar oportunidades de mercado sin explotar.

ğŸ“‰ **Problema:** La calidad de los negocios existentes varÃ­a significativamente, con algunos establecimientos acumulando malas calificaciones y reviews negativas. Esto representa una oportunidad para nuevos emprendedores que deseen establecer negocios con mejores estÃ¡ndares de servicio y calidad.

ğŸ’¡ **SoluciÃ³n:** Mediante el anÃ¡lisis de datos y tÃ©cnicas de machine learning, es posible identificar Ã¡reas con deficiencia en oferta gastronÃ³mica y baja calidad de servicio, proporcionando recomendaciones estratÃ©gicas para maximizar el Ã©xito de nuevos negocios.

## **Objetivo General**

Desarrollar un sistema de recomendaciÃ³n que, basado en datos de negocios gastronÃ³micos en el estado de  Florida - EEUU, sugiera la mejor ubicaciÃ³n para abrir un nuevo establecimiento.

## **Objetivos EspecÃ­ficos**

1ï¸âƒ£ Analizar la distribuciÃ³n geogrÃ¡fica de los negocios gastronÃ³micos en Florida para identificar zonas con baja oferta.
2ï¸âƒ£ Evaluar la calidad de los negocios existentes mediante anÃ¡lisis de reviews y ratings.
3ï¸âƒ£ Determinar caracterÃ­sticas clave de los negocios exitosos.
4ï¸âƒ£ Desarrollar un modelo de recomendaciÃ³n basado en carencias del mercado y calidad de la competencia.
5ï¸âƒ£ Validar la efectividad del sistema con datos histÃ³ricos.

## **Alcance del Proyecto**

### **Â¿QuÃ© vamos a hacer?**

ğŸ“¢ Desarrollar un modelo de Machine Learning que prediga si un negocio tendrÃ¡ Ã©xito. La recomendaciÃ³n se basarÃ¡ en la carencia de cierto tipo de negocio en una zona y la baja calidad de los existentes segÃºn reviews. AdemÃ¡s, se proporcionarÃ¡n caracterÃ­sticas clave de los negocios exitosos.

ğŸ”¹ **Esto incluye:**

âœ… Un **EDA (Exploratory Data Analysis)** completo para entender los datos.
âœ… ImplementaciÃ³n de un **Data Lake / Data Warehouse** para almacenar y gestionar la base de datos de manera eficiente.
âœ… CreaciÃ³n de **features clave** que impactan el Ã©xito de un negocio.
âœ… Entrenamiento de un **modelo de clasificaciÃ³n** para predecir Ã©xito o fracaso.
âœ… ImplementaciÃ³n de un **dashboard interactivo** para visualizar los resultados.
âœ… **Despliegue del modelo en la nube** para uso en tiempo real.

### **ğŸ† Base de RecomendaciÃ³n** 

ğŸ“¢ **Nuestro sistema recomendarÃ¡ ubicaciones para nuevos negocios basÃ¡ndose en los siguientes criterios:**

âœ… Se ubica en una **zona con baja oferta gastronÃ³mica** o con **competencia de baja calidad** segÃºn calificaciones y reviews.
âœ… Se alinea con las **caracterÃ­sticas clave de los negocios exitosos**, identificadas en el anÃ¡lisis de datos.
âœ… Se encuentra en un Ã¡rea con **potencial de demanda insatisfecha**, determinada por la evaluaciÃ³n de check-ins y reviews.

### **ğŸŒ Alcance GeogrÃ¡fico** 

ğŸ“¢ **Limitamos el anÃ¡lisis a negocios en el Estado Florida de EE.UU.**
ğŸ”¹ Esto permite trabajar con un dataset mÃ¡s limpio y evitar sesgos por diferencias culturales en reseÃ±as.

### **ğŸ•’ LimitaciÃ³n en el Tiempo**

ğŸ“¢ **Nuestro modelo solo se entrenarÃ¡ con datos de los Ãºltimos 5 aÃ±os (2018-2023).**
ğŸ”¹ Evita incluir negocios antiguos cuyo comportamiento puede no ser representativo.
ğŸ”¹ Nos aseguramos de que los datos sean recientes y relevantes.

### ğŸ› ï¸ **Stack Tecnologico**

ğŸ“¢ **Usaremos herramientas estÃ¡ndar para garantizar reproducibilidad:**

âœ… **Almacenamiento de Datos**

ğŸ”¹ Local (CSV, Parquet)
ğŸ”¹ **Google Cloud Storage** como Data Lake
ğŸ”¹ **PostgreSQL** como Data Warehouse

âœ… **Procesamiento y AnÃ¡lisis**
ğŸ”¹ **Python (Pandas, NumPy, Scikit-learn)**
ğŸ”¹ **EDA y VisualizaciÃ³n:** Seaborn, Matplotlib
ğŸ”¹ **ML Models:** Random Forest, XGBoost, RegresiÃ³n LogÃ­stica

âœ… **Despliegue**
ğŸ”¹ Dashboard en **PowerBI**
ğŸ”¹  API en **FastAPI** para consultas en tiempo real

## **KPIs**

### 1ï¸âƒ£ **Tasa de Crecimiento de Calificaciones (CalificaciÃ³n promedio mensual)**

ğŸ“¢ **Objetivo:** Evaluar la evoluciÃ³n en la satisfacciÃ³n del pÃºblico con el rubro elegido.

Este KPI mide el cambio en la calificaciÃ³n promedio de los negocios gastronÃ³micos o de una categorÃ­a especÃ­fica en el Ãºltimo trimestre respecto al anterior.

Calculamos cuÃ¡nto aumentÃ³ o disminuyÃ³ la calificaciÃ³n promedio en el Ãºltimo trimestre respecto del anterior, entendiendo que una caÃ­da puede ser beneficiosa para un nuevo emprendimiento.

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./imagen/KPI_2.png)

ğŸ“Œ **Leyenda:**

* **TCC**: Tasa de Crecimiento de Calificaciones.
* **CP_T**: CalificaciÃ³n promedio en el Ãºltimo trimestre.
* **CP_T-1**: CalificaciÃ³n promedio en el trimestre anterior.

### 2ï¸âƒ£ **Porcentaje de Negocios Exitosos**

ğŸ“¢ **Objetivo:** Evaluar la probabilidad de Ã©xito de un negocio en determinada zona.

Este KPI mide la cantidad de negocios exitosos, medidos por calificaciones recibidas, en relaciÃ³n con la cantidad de negocios abiertos en el Ãºltimo trimestre.

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./imagen/KPI_1.png)

ğŸ“Œ **Leyenda:**

* **PNE**: Porcentaje de Negocios Exitosos.
* **NE**: NÃºmero de negocios exitosos.
* **TN**: Total de negocios abiertos en el Ãºltimo trimestre.

### 3ï¸âƒ£ **Tasa de SaturaciÃ³n del Mercado (Ratio de negocios por habitantes)**

ğŸ“¢ **Objetivo:** Evaluar la cantidad de negocios de determinado rubro en relaciÃ³n con la cantidad de hipotÃ©ticos consumidores.

Este KPI mide la cantidad de negocios en una categorÃ­a especÃ­fica en relaciÃ³n con la poblaciÃ³n de la ubicaciÃ³n en el Ãºltimo trimestre en relaciÃ³n con el anterior,a fin de determinar si hay margen para un nuevo local en la zona.

ğŸ“¢ **FÃ³rmula:**

![Texto alternativo](./imagen/KPI_3.png)

ğŸ“Œ **Leyenda:**

* **RNH**: Ratio de Negocios por Habitante.
* **N**: NÃºmero de negocios en una categorÃ­a y ciudad.
* **P**: PoblaciÃ³n total de la ciudad.

## **MetodologÃ­a de Trabajo**

ğŸ“¢ Para garantizar una gestiÃ³n eficiente del proyecto, se aplicarÃ¡ la metodologÃ­a **Scrum**, organizando el trabajo en sprints con entregables claros.

### **ğŸ‘¥ Roles del Equipo**

âœ… **Scrum Master:** Argenis Bolivar
âœ… **Data Engineer:** Paula Irazoqui
âœ… **Data Analyst:** SebastiÃ¡n Prat
âœ… **ML Engineer:** Ezequiel Lizio
âœ… **DevOps:** Joaquin Rubiolo

### **ğŸ“Œ Roles en cada Sprint**

Para distribuir responsabilidades, los roles clave en cada sprint son:

| **Sprint**   | **Product Owner**                                 | **Scrum Master**                                | **Data Engineer**           | **Data Analyst**             | **ML Engineer**      | **DevOps**                               |
| ------------------ | ------------------------------------------------------- | ----------------------------------------------------- | --------------------------------- | ---------------------------------- | -------------------------- | ---------------------------------------------- |
| **Sprint 1** | Definir objetivos y<br />alcance                        | Gestionar<br />backlog y <br />reuniones              | Extraer y<br />limpiar datos      | Explorar datos<br />y definir KPIs | No aplica aÃºn             | Configurar<br />repositorio Git                |
| **Sprint 2** | Priorizar<br />implementaciÃ³n <br />del ETL            | Asegurar<br />que los <br />procesos se <br />cumplan | Implementar<br />y validar el ETL | Analizar calidad<br />de datos     | No aplica aÃºn             | Configurar<br />infraestructura <br />de datos |
| **Sprint 3** | Priorizar desarrollo<br /> del modelo <br />y dashboard | Coordinar la<br />entrega final                       | Optimizar<br />datos para ML      | Visualizar KPIs<br />y resultados  | Entrenar modelo<br />de ML | Desplegar API<br />y dashboard                 |

#### **1ï¸âƒ£ Ã‰picas Principales**

1. **DefiniciÃ³n del Proyecto y ExploraciÃ³n de Datos**
2. **ImplementaciÃ³n del Pipeline ETL y Almacenamiento**
3. **Desarrollo del Modelo de Machine Learning**
4. **ImplementaciÃ³n del Dashboard Interactivo**
5. **OptimizaciÃ³n y ValidaciÃ³n del Sistema**

#### **2ï¸âƒ£ Historias de Usuario por Sprint**

##### **ğŸ“Œ Sprint 1: DefiniciÃ³n y ExploraciÃ³n de Datos (03 Feb - 14 Feb)**

**HU1:** *Como analista de datos, quiero realizar un anÃ¡lisis exploratorio (EDA) para entender la calidad y caracterÃ­sticas de los datos disponibles.*

* **Tareas:**
  âœ… Recopilar datasets de negocios gastronÃ³micos y reviews.
  âœ… Identificar valores nulos, duplicados y outliers.
  âœ… Generar reportes visuales sobre la distribuciÃ³n de datos.

**HU2:** *Como equipo de desarrollo, quiero definir los KPIs para medir el Ã©xito del sistema.*

* **Tareas:**
  âœ… Identificar mÃ©tricas clave para evaluar recomendaciones del modelo.
  âœ… Documentar fÃ³rmulas y criterios de mediciÃ³n.

**HU3:** *Como desarrollador, quiero establecer un repositorio en GitHub para el control de versiones.*

* **Tareas:**
  âœ… Crear la estructura del repositorio.
  âœ… Configurar branches y flujos de trabajo Git.
  âœ… Documentar estÃ¡ndares de codificaciÃ³n y colaboraciÃ³n.

##### **ğŸ“Œ Sprint 2: Data Engineering (17 Feb - 28 Feb)**

**HU4:** *Como ingeniero de datos, quiero implementar un pipeline ETL automatizado para garantizar la limpieza y transformaciÃ³n de los datos.*

* **Tareas:**
  âœ… DiseÃ±ar el flujo de extracciÃ³n, transformaciÃ³n y carga (ETL).
  âœ… Configurar un Data Warehouse / Data Lake.
  âœ… Implementar una carga incremental para nuevos datos.

**HU5:** *Como arquitecto de datos, quiero diseÃ±ar un modelo relacional para almacenar la informaciÃ³n de manera eficiente.*

* **Tareas:**
  âœ… Crear un modelo de base de datos (ERD).
  âœ… Implementar PostgreSQL o BigQuery para almacenamiento.
  âœ… Validar la integridad de los datos mediante consultas SQL.

**HU6:** *Como ingeniero de datos, quiero realizar pruebas de calidad para asegurar que los datos son confiables.*

* **Tareas:**
  âœ… Implementar validaciones de datos en Airflow o Prefect.
  âœ… Generar reportes de calidad de datos.
  âœ… Resolver problemas de datos faltantes o inconsistentes.

##### **ğŸ“Œ Sprint 3: Data Analytics + ML (3 Mar - 15 Mar)**

**HU7:** *Como analista de datos, quiero visualizar las recomendaciones del modelo en un dashboard interactivo.*

* **Tareas:**
  âœ… Implementar grÃ¡ficos de visualizaciÃ³n de KPIs.
  âœ… Integrar el dashboard con la base de datos.
  âœ… Generar filtros interactivos para el anÃ¡lisis de datos.

**HU8:** *Como desarrollador de machine learning, quiero entrenar un modelo de recomendaciÃ³n basado en datos histÃ³ricos.*

* **Tareas:**
  âœ… Seleccionar el algoritmo de ML mÃ¡s adecuado (clustering, regresiÃ³n, etc.).
  âœ… Optimizar el modelo con hiperparÃ¡metros.
  âœ… Evaluar su rendimiento con mÃ©tricas de precisiÃ³n y recall.

**HU9:** *Como DevOps, quiero desplegar el modelo en producciÃ³n para que pueda ser utilizado en tiempo real.*

* **Tareas:**
  âœ… Crear API con **FastAPI** para consumir el modelo.
  âœ… Integrar el modelo con el dashboard para visualizaciÃ³n en tiempo real.
  âœ… Probar la API con datos de prueba y optimizar tiempos de respuesta.

---

#### **3ï¸âƒ£ Backlog TÃ©cnico (Tareas Prioritarias)**

âœ… **Sprint 1: DefiniciÃ³n y ExploraciÃ³n de Datos**

* Configurar repositorio en **GitHub** con estructura de carpetas.
* Realizar EDA.
* Documentar las fuentes de datos y su confiabilidad.

ğŸ† **Hitos:**

* DocumentaciÃ³n del EDA y calidad de datos.
* DefiniciÃ³n de KPIs.
* CreaciÃ³n del repositorio en GitHub.

âœ… **Sprint 2: Data Engineering**

* Configurar **Airflow** o **Prefect** para orquestaciÃ³n del ETL.
* Implementar almacenamiento en  **Google BigQuery** .
* Generar logs de procesamiento y validaciÃ³n de datos.

ğŸ† **Hitos:**

* ImplementaciÃ³n del Data Lake y Data Warehouse.
* Pipeline ETL en funcionamiento.
* ValidaciÃ³n de datos y reportes de calidad.

âœ… **Sprint 3: Data Analytics + ML**

* Conectar el dashboard con la base de datos.
* Entrenar y desplegar el modelo de Machine Learning.
* Evaluar el sistema con datos en tiempo real.

ğŸ† **Hitos:**

* Dashboard funcional con visualizaciÃ³n de KPIs.
* Modelo de ML entrenado y optimizado.
* Despliegue del modelo en la nube.

#### 4ï¸âƒ£ Diagrama de Gantt

![Texto alternativo](./imagen/GanttProyecto.png)










## **Stack Tecnologico**

ğŸ“Œ Librerias para el ETL y EDACarga el dataset y elimina valores nulos usando Pandas y Numpy

1ï¸âƒ£ Antes de entrenar cualquier modelo, es fundamental asegurarse de que los datos no contengan valores faltantes. Si hay valores nulos en las reseÃ±as o calificaciones, estos pueden generar errores o sesgos en el modelo.

2ï¸âƒ£ Convierte texto en caracterÃ­sticas numÃ©ricas usando TF-IDF, Word2Vec o BERT
    ğŸ“Œ Â¿Por quÃ© es importante?
    Los modelos de Machine Learning no pueden procesar texto directamente. TF-IDF (Term Frequency - Inverse Document Frequency) transforma las palabras en valores numÃ©ricos, asignando mÃ¡s peso a tÃ©rminos importantes y reduciendo el peso de palabras comunes.

  ğŸ”¹ Ejemplo de salida de TF-IDF:
  Si la reseÃ±a es "La comida es excelente", el vector numÃ©rico podrÃ­a verse asÃ­: [0.12, 0.34, 0.05, ..., 0.67]

3ï¸âƒ£ Escala los datos numÃ©ricos usando StandardScaler
  Â¿Por quÃ© es importante?
  Los modelos de Machine Learning funcionan mejor cuando las caracterÃ­sticas numÃ©ricas estÃ¡n en la misma escala. StandardScaler convierte todas las variables en valores con media 0 y desviaciÃ³n estÃ¡ndar 1, evitando que una variable con valores grandes domine a otras.

ğŸ”¹ Ejemplo antes y despuÃ©s de la escala:

CalificaciÃ³n Original	CalificaciÃ³n Escalada
    4.5	                    0.82
    3.0	                    -1.25
    5.0	                    1.35
    ğŸ”¹ RazÃ³n para usar escalado:
    Si tenemos variables en distintas escalas (ej. calificaciÃ³n de 1 a 5 y valores TF-IDF de 0 a 1), el modelo podrÃ­a dar mÃ¡s peso a las caracterÃ­sticas con valores mÃ¡s grandes.

4ï¸âƒ£ Entrena y evalÃºa 4 modelos distintos
  ğŸ“Œ Â¿Por quÃ© es importante?
  Cada modelo tiene sus ventajas y desventajas. Probamos 4 enfoques distintos para comparar cuÃ¡l funciona mejor.

  ğŸ“Œ LogisticRegression:
  Modelo simple basado en probabilidad.
  Ãštil si los datos son linealmente separables.
  Bueno para interpretabilidad.
  
  ğŸ“Œ DecisionTreeClassifier:
  Divide los datos en ramas de decisiones.
  Bueno para entender la importancia de las caracterÃ­sticas.
  Puede sobreajustarse con datos pequeÃ±os.
  
  ğŸ“Œ Random Forest:
  Usa mÃºltiples Ãrboles de DecisiÃ³n y hace votaciÃ³n de resultados.
  Reduce el sobreajuste.
  Funciona bien con muchos datos.
  
  ğŸ“Œ XGBoost:
  Algoritmo avanzado basado en boosting (aprendizaje secuencial).
  Optimiza la precisiÃ³n y reduce errores.
  Es el modelo mÃ¡s poderoso para datos tabulares.

  5ï¸âƒ£ Compara su rendimiento con accuracy_score y classification_report
  ğŸ“Œ Â¿Por quÃ© es importante?
  Nos permite medir quÃ© modelo hace mejores predicciones. Usamos accuracy_score para comparar la precisiÃ³n general y classification_report para ver mÃ©tricas mÃ¡s detalladas.

ğŸ“Œ Google Cloud para el despliegue del modelo:

  1ï¸âƒ£ Costos y comparaciÃ³n con otras plataformas  
  Google Cloud ofrece precios competitivos en comparaciÃ³n con AWS y Azure, especialmente en:  
  - Compute Engine: MÃ¡quinas virtuales escalables con precios bajos.  
  - Cloud Run: Para desplegar FastAPI en un entorno sin servidor, con pago solo por uso.  
  - AI Platform: Servicios optimizados para entrenar y servir modelos de ML.   

  2ï¸âƒ£ Servicios especÃ­ficos que ofrece Google Cloud para ML
  Google Cloud tiene varias opciones para desplegar el modelo de predicciÃ³n:  

  | Requerimiento               | Servicio recomendado    | JustificaciÃ³n                                                 |
  |-----------------------------|-------------------------|---------------------------------------------------------------|
  | 'Entrenar el modelo'        | Vertex AI / AI Platform | Plataforma optimizada para ML, con soporte para TensorFlow, Scikit-Learn, XGBoost. |
  | 'Preprocesar datos (ETL)'   | Dataflow / BigQuery     | Manejo eficiente de grandes volÃºmenes de datos.               |
  | 'Almacenar datos de reviews'| Cloud SQL (PostgreSQL)  | Base de datos gestionada, escalable y compatible con FastAPI. |
  | 'Desplegar API (FastAPI)'   | Cloud Run               | Escalabilidad sin servidor, bajo costo.                       |
  | 'MonitorizaciÃ³n del modelo' | AI Platform Predictions | MÃ©tricas en tiempo real, detecciÃ³n de degradaciÃ³n del modelo. |

  3ï¸âƒ£ Rendimiento y escalabilidad
  ğŸ”¹ Ventajas tÃ©cnicas de Google Cloud
  - Mejor costo-beneficio en GPUs: Soporte nativo para NVIDIA T4 y A100 con optimizaciÃ³n para TensorFlow y PyTorch.  
  - IntegraciÃ³n con BigQuery: Permite consultas rÃ¡pidas sobre grandes volÃºmenes de datos sin necesidad de ETL manual.  
  - Cloud Run vs AWS Lambda: AWS tiene tiempos de arranque frÃ­os mÃ¡s largos, mientras que Cloud Run mantiene mejor disponibilidad.  
  - Autoescalado nativo: Google Cloud ajusta los recursos dinÃ¡micamente segÃºn la demanda, reduciendo costos.  

  4ï¸âƒ£ Seguridad y cumplimiento
  Google Cloud cumple con estÃ¡ndares globales:  
  âœ… ISO 27001, SOC 1/2/3, GDPR, HIPAA, lo que garantiza que los datos de clientes y negocios estÃ¡n protegidos.  

  AdemÃ¡s, ofrece:  
  - Cloud Identity & Access Management (IAM) para controlar accesos.  
  - Cifrado de datos en trÃ¡nsito y en reposo.  
  - Cloud Audit Logs para rastrear actividad y detectar anomalÃ­as.  

  ğŸ“Œ ConclusiÃ³n Final
  ğŸ”¹ Google Cloud es la opciÃ³n mÃ¡s econÃ³mica y ofrece beneficios adicionales:  
  âœ… Menor costo en computaciÃ³n y almacenamiento.  
  âœ… Mejor integraciÃ³n con herramientas de Machine Learning (Vertex AI, BigQuery).  
  âœ… Mayor escalabilidad con Cloud Run y AI Platform.  
  âœ… Alto nivel de seguridad y cumplimiento normativo.  

  ğŸ“Œ RecomendaciÃ³n: Utilizar Cloud Run para la API, AI Platform para el modelo y BigQuery para almacenar datos. Esto reducirÃ¡ costos y mejorarÃ¡ el rendimiento del sistema. ğŸš€







CreaciÃ³n de un sistema de analisis de rentabilidad para la instalaciÃ³n de locales gastronÃ³micos en el estado de Florida, Estados Unidos


